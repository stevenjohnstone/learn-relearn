[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "learn-relearn",
    "section": "",
    "text": "A First Course in Stochastic Calculus\n\n\nChapter Three Exercises\n\n\nSolutions to exercises and computer experiments\n\n\n\n\n \n\n\n\n\n\n\nA First Course in Stochastic Calculus\n\n\nChapter Two Exercises\n\n\nSolutions to exercises and computer experiments\n\n\n\n\n \n\n\n\n\n\n\nA First Course in Stochastic Calculus\n\n\nChapter One Exercises\n\n\nSolutions to exercises and computer experiments\n\n\n\n\n \n\n\n\n\n\n\nProbabilistic Machine Learning\n\n\nChapter Two Exercises\n\n\nSolutions to starred exercises\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "FCSC/ch3.html",
    "href": "FCSC/ch3.html",
    "title": "A First Course in Stochastic Calculus",
    "section": "",
    "text": "\\[\n\\newcommand{\\Cov}{\\operatorname{Cov}}\n\\newcommand{\\Var}{\\operatorname{Var}}\n\\newcommand{\\E}{\\operatorname{E}}\n\\newcommand{\\P}{\\operatorname{P}}\n\\newcommand{\\rank}{\\operatorname{rank}}\n\\newcommand{\\trace}{\\operatorname{trace}}\n\\def\\iddots{{\\kern3mu\\raise1mu{.}\\kern3mu\\raise6mu{.}\\kern3mu\n\\raise12mu{.}}}\n\\]"
  },
  {
    "objectID": "FCSC/ch3.html#simulating-brownian-motion-using-increments",
    "href": "FCSC/ch3.html#simulating-brownian-motion-using-increments",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.1 Simulating Brownian Motion Using Increments",
    "text": "3.1 Simulating Brownian Motion Using Increments\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef brownian(steps, time_interval):\n    normal_samples = np.random.default_rng().normal(0, np.sqrt((time_interval[1] - time_interval[0])/steps), steps)\n    return np.r_[0, np.cumsum(normal_samples)]\n    \n\ndef plot_brownian(steps, time_interval):\n    for _ in range(10):\n        plt.plot(brownian(steps, time_interval))\n    plt.title('Brownian Motion')\n    plt.show()\n    \nplot_brownian(100, [0, 1])\nplot_brownian(1000, [0, 1])"
  },
  {
    "objectID": "FCSC/ch3.html#simulating-the-poisson-process",
    "href": "FCSC/ch3.html#simulating-the-poisson-process",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.2 Simulating the Poisson Process",
    "text": "3.2 Simulating the Poisson Process\n\ndef poisson(rate, steps, time_interval):\n    poisson_samples = np.random.default_rng().poisson(rate*(time_interval[1] - time_interval[0])/steps, steps)\n    return np.cumsum(poisson_samples)\n    \ndef plot_poisson(samples, rate, steps, time_interval):\n    for _ in range(samples):\n        plt.plot(np.linspace(time_interval[0], time_interval[1], steps), poisson(rate, steps, time_interval))\n    plt.title(f'Poisson Process, rate = {rate}')\n    plt.show()\n\nplot_poisson(10, 1, 100, [0,10])"
  },
  {
    "objectID": "FCSC/ch3.html#arcsine-law",
    "href": "FCSC/ch3.html#arcsine-law",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.3 Arcsine Law",
    "text": "3.3 Arcsine Law\n\ndef proportion_positive(samples):\n    positive = 0\n    for s in samples:\n        if s >= 0:\n            positive+=1\n    return positive/len(samples)\n            \n\nbrownian_samples = [ proportion_positive(brownian(100, [0,1])) for _ in range(1000) ]\n\ndef pdf(x):\n    return (1/np.pi) * 1 /(np.sqrt(x*(1-x)))\n\nfig, ax = plt.subplots()\nax.hist(brownian_samples, label='histogram', density=True, bins=50)\nx = np.linspace(0, 1, 1000)\nax.plot(x, pdf(x), label='pdf')\nax.legend(loc='upper right')\n\n/tmp/ipykernel_234465/2567682607.py:12: RuntimeWarning: divide by zero encountered in divide\n  return (1/np.pi) * 1 /(np.sqrt(x*(1-x)))\n\n\n<matplotlib.legend.Legend at 0x7fc4f8899300>"
  },
  {
    "objectID": "FCSC/ch3.html#arcsine-law-for-ornstein-uhlenbeck",
    "href": "FCSC/ch3.html#arcsine-law-for-ornstein-uhlenbeck",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.4 Arcsine Law for Ornstein-Uhlenbeck",
    "text": "3.4 Arcsine Law for Ornstein-Uhlenbeck\n\nclass OU:\n    def __init__(self, samples):\n        covariance = [ [ (1/2)*np.exp(-(1/samples) * np.abs(i -j))*(1 - np.exp(-(2/samples)*min(i, j))) for i in range(1, samples)] for j in range(1, samples)]\n        self.__A = np.linalg.cholesky(covariance)\n        self.__samples = samples\n        return\n\n    def path(self, rg = np.random.default_rng()):\n        return np.r_[0, self.__A.dot(rg.normal(0, 1, self.__samples-1))]\n\nou = OU(100)\n\nrg = np.random.default_rng()\n\nou_samples = [ proportion_positive(ou.path(rg)) for _ in range(10000)]\n\nfig, ax = plt.subplots()\nax.hist(ou_samples, label='histogram', density=True, bins=100)\nax.legend(loc='upper right')\n\n<matplotlib.legend.Legend at 0x7fc4c44a0d90>"
  },
  {
    "objectID": "FCSC/ch3.html#brownian-variations",
    "href": "FCSC/ch3.html#brownian-variations",
    "title": "A First Course in Stochastic Calculus",
    "section": "Brownian Variations",
    "text": "Brownian Variations\n\ndef variation(samples):\n    return np.sum([ np.abs(samples[i+1] - samples[i]) for i in range(len(samples) - 1)])\n\n\ndef quadratic_variation(samples):\n    return np.sum([ (samples[i+1] - samples[i])**2 for i in range(len(samples) - 1)])\n\nbrownian_samples = brownian(2**20, [0,1])\nplt.plot(brownian_samples)\nplt.show()\n\nquadratic_variations = [ quadratic_variation(brownian_samples[::2**i]) for i in range(20, 0, -1) ]\n\nplt.plot(quadratic_variations)\nplt.title('Quadratic Variation')\nplt.show()\n\nvariations = [ variation(brownian_samples[::2**i]) for i in range(20, 0, -1) ]\n\nplt.plot(variations)\nplt.title('Variation')\nplt.show()"
  },
  {
    "objectID": "FCSC/ch3.html#simulating-brownian-motion-using-lévys-construction",
    "href": "FCSC/ch3.html#simulating-brownian-motion-using-lévys-construction",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.6 Simulating Brownian Motion Using Lévy’s Construction",
    "text": "3.6 Simulating Brownian Motion Using Lévy’s Construction\n\ndef levy(N, sample_points):\n    def counter(N):\n        n = 1 \n        j = 0\n        while True:\n            for k in range(2**j):\n                n = 2**j + k\n                if n >= N:\n                    return\n                yield j, k, n\n            j+=1\n\n    def Lambda(t):\n        if 0 <= t <= 1/2:\n            return t\n        elif 1/2 <= t <= 1:\n            return 1 - t\n        return 0\n    \n    normal_samples = np.random.default_rng().normal(0, 1, N)\n    \n    def B(t):\n        b = normal_samples[0] * t\n        for j, k, n in counter(N):\n            b+= 2**(-j/2) * Lambda((2**j) * t - k) * normal_samples[n]\n        return b\n        \n    return [B(p) for p in sample_points]\n    \n\"\"\"\ndef test_levy(N):\n    sum_t_1, sum_t_2 = 0, 0\n    time_values = np.linspace(0, 1, 3)\n    samples = 10000\n    for _ in range(samples):\n        _, t_1, t_2 = levy(N, time_values)\n        sum_t_1 += t_1**2\n        sum_t_2 += t_2**2\n    return sum_t_1/samples, sum_t_2/samples\n    \nt_1_av, t_2_av = test_levy(100)\nprint(t_1_av, t_2_av) # we expect somewhere close to 0.5 and 1\n\"\"\"\n    \n    \ntime_values = np.linspace(0, 1, 100)\nfor N in [5, 20, 100]:\n    for _ in range(10):\n        plt.plot(levy(N, time_values))\n    plt.title(f'N={N}')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nI think \\(\\Lambda\\) is incorrectly defined on page 61. Should read\n\\[\n\\Lambda(t) = \\begin{cases}\nt & \\text{if } 0 \\leq t \\leq 1/2, \\\\\n1 - t & \\text{if } 1/2 < t \\leq 1, \\\\\n0 & \\text{otherwise}.\n\\end{cases}\n\\]\nThe text is also inconsistent about the \\(2^{-j/2}\\) factor."
  },
  {
    "objectID": "FCSC/ch3.html#brownian-moments",
    "href": "FCSC/ch3.html#brownian-moments",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.1 Brownian Moments",
    "text": "3.1 Brownian Moments\n\n\\(\\E(B_t^6)\\)\n\nWe can use Wick’s/Isserlis’ formula to calculate this: there are \\((6 -1)!! = 15\\) different pairings of the \\(6\\)-tuple \\(\\{B_t, \\ldots, B_t\\}\\) and so\n\\[\n\\begin{align}\n\\E(B_t^6) &= 15 \\E(B_t^2)^3 \\\\\n&= 15 t^3.\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\n\nIn general, for a zero mean Gaussian variable \\(X\\) and \\(n >= 1\\)\n\\[\n\\E(X^{2n}) = (2n -1)!!\\E(X^2)^n.\n\\]\nThis can be seen with Wick’s formula:\nthere are \\((2n - 1)!!\\) different pairings of the set of \\(2n\\) elements \\((X,\\ldots, X)\\) and each pairing results in \\(n\\) pairs.\n\n\n\n\\(\\E((B_{t_2} - B_{t_1})(B_{t_3} - B_{t_2}))\\) if \\(t_1 < t_2 < t_3\\)\n\n\\[\n\\begin{align}\n\\E((B_{t_2} - B_{t_1})(B_{t_3} - B_{t_2})) &= \\E(B_{t_2} B_{t_3}) - \\E(B_{t_2}^2) - \\E(B_{t_1} B_{t_3}) + \\E(B_{t_1}B_{t_2}) \\\\\n&= t_2 - t_2 - t_1 + t_1 \\\\\n&= 0.\n\\end{align}\n\\]\n\n\\(\\E(B_s^2 B_t^2)\\) if \\(s < t\\).\n\nThe pairings of \\((B_s, B_s, B_t, B_t)\\) are\n\\(((B_s, B_s),(B_t, B_t)), ((B_s, B_t), (B_s, B_t)), ((B_s, B_t),(B_s, B_t))\\) and so by Wick’s formula\n\\[\n\\begin{align}\n\\E(B_s^2B_t^2) &= \\E(B_s^2)\\E(B_t^2) + 2 \\E(B_sB_t)^2 \\\\\n&= st + 2 s^2.\n\\end{align}\n\\]\n\n\\(\\E(B_s B_t^3)\\) if \\(s < t\\).\n\nThe pairings of \\((B_s, B_t, B_t, B_t)\\) are \\(((B_s, B_t),(B_t, B_t)), ((B_s, B_t), (B_t, B_t)), ((B_s, B_t),(B_t, B_t))\\) and so by Wick’s formula\n\\[\n\\begin{align}\n\\E(B_s B_t^3)  &= 3 \\E(B_sB_t)\\E(B_t^2) \\\\\n&= 3st.\n\\end{align}\n\\]\n\n\\(\\E(B_s^{100} B_t^{101})\\).\n\n\\(\\E(B_s^{100} B_t^{101}) = 0\\) because there are an odd number of multiplicands."
  },
  {
    "objectID": "FCSC/ch3.html#brownian-probabilities",
    "href": "FCSC/ch3.html#brownian-probabilities",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.2 Brownian Probabilities",
    "text": "3.2 Brownian Probabilities\n\n\\(\\P(B_1 > 1, B_2 > 1)\\)\n\nThe integral is given by\n\n\nCode\nimport sympy as sp\nfrom fractions import Fraction\nfrom sympy.abc import x,y\n\nsp.init_printing()\nC=sp.Matrix([[1, 1], [1, 2]])\n\n\nCinv = C.inv()\nxy = sp.Matrix([x, y])\n\n\nf = sp.exp(Fraction(-1, 2) * sp.MatMul(xy.transpose(), Cinv, xy))/(2 *sp.pi * sp.sqrt(C.det(), evaluate=False))\npdf = f[0]\nintegral = sp.Integral(pdf, (x, 1, sp.oo), (y, 1, sp.oo))\nintegral\n\n\n\\(\\displaystyle \\int\\limits_{1}^{\\infty}\\int\\limits_{1}^{\\infty} \\frac{e^{- x^{2} + x y - \\frac{y^{2}}{2}}}{2 \\pi}\\, dx\\, dy\\)\n\n\nA change of variables gives a finite domain of integration:\n\n\nCode\npdf = pdf.subs({x: 1/x, y: 1/y})*sp.diff(1/x, x)*sp.diff(1/y, y)\n\nsp.Integral(pdf , (x, 0, 1), (y, 0, 1))\n\n\n\\(\\displaystyle \\int\\limits_{0}^{1}\\int\\limits_{0}^{1} \\frac{e^{- \\frac{1}{2 y^{2}} + \\frac{1}{x y} - \\frac{1}{x^{2}}}}{2 \\pi x^{2} y^{2}}\\, dx\\, dy\\)\n\n\nThis can be calculated using a monte-carlo approximation:\n\nimport numpy as np\n\ndef monte_carlo(integrand):\n    samples = 10000\n    sum = 0\n    for _ in range(samples):\n        x, y = np.random.default_rng().uniform(0, 1, 2)\n        sum +=integrand(x, y)\n    return sum/samples\n\nprobability = monte_carlo(sp.lambdify([x, y], pdf))\nprobability\n\n\\(\\displaystyle 0.108779260061586\\)\n\n\nAlternatively, we can evaluate the integral with Simpson’s rule:\n\nfrom scipy.integrate import simps\n\ndef simpsons(integrand):\n    x = np.linspace(0.01, 1, 1000)\n    y=  np.linspace(0.01, 1, 1000)\n\n    zz = integrand(x.reshape(-1, 1), y.reshape(1, -1))\n    return simps([simps(zz_r, x) for zz_r in zz], y)\n    \nsimpsons(sp.lambdify([x, y], pdf))\n\n\\(\\displaystyle 0.108067672895208\\)\n\n\nWe can check this makes sense by simulating a number of Brownian motion paths and checking the ratio of the samples satisfying \\(B_1 >1, B_2>1\\) to the total number of samples.\n\nclass Brownian:\n    def __init__(self, C):\n        self.__A = np.linalg.cholesky(C)\n        return\n    def path(self):\n        n = len(self.__A[0])\n        return self.__A.dot(np.random.default_rng().normal(0, 1, n))\n        \nbrownian = Brownian(np.array(C.tolist()).astype(np.float64))\n\n\nsamples=10000\ncount = 0\nfor _ in range(samples):\n    b_1, b_2 = brownian.path()\n    if b_1 > 1 and b_2 > 1:\n        count+=1\n\ncount/samples\n\n\\(\\displaystyle 0.1081\\)\n\n\nWe can also use the fact that \\((B_1, B_2 - B_1)\\) are independent:\n\\[\n\\begin{align}\n\\P(B_1 > 1, B_2> 1) &= \\int \\int_{\\{x > 1, x + y > 1\\}} \\frac{e^{\\frac{-1}{2}(x^2 + y^2)}}{2 \\pi} dx \\, dy.\n\\end{align}\n\\]\nThe domain of integration is:\n\n\nCode\nfrom matplotlib.patches import Polygon\n \nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nplt.xlim(-1, 3)\nplt.ylim(-1, 3)\n\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\n\nax.spines['left'].set_position('zero')\nax.spines['bottom'].set_position('zero')\n\naxis = plt.gca()\naxis.add_patch(Polygon([[1, 0], [1,3], [3, 3], [3,-2]], label='domain of integration'))\ndef f(x):\n    return 1 - x\n    \nx = np.linspace(-1, 3, 1000)\n\nplt.plot(x, f(x), 'k--', label='y= 1 - x')\nplt.axvline(1, color='b', linestyle='--', label = 'x=1')\nplt.legend(loc='upper left')\n\n\n<matplotlib.legend.Legend at 0x7fc4bd35caf0>\n\n\n\n\n\nWe can calculate in chunks.\n\n\nCode\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\n \nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nplt.xlim(-3, 3)\nplt.ylim(-3, 3)\n\nfor spine in ['top', 'right']:\n    ax.spines[spine].set_visible(False)\n\nax.spines['left'].set_position('zero')\nax.spines['bottom'].set_position('zero')\n\naxis = plt.gca()\naxis.add_patch(Polygon([[1, 0], [1,3], [3, 3], [3,0]], label='A'))\naxis.add_patch(Polygon([[1, 0], [3,0], [3, -3]], label='B', color='red'))\nplt.legend(loc='upper left')\n\n\n<matplotlib.legend.Legend at 0x7fc4bb3a9ff0>\n\n\n\n\n\n\nimport sympy as sp\nfrom fractions import Fraction\nfrom sympy.abc import x,y\n\npdf = sp.exp(Fraction(-1, 2) *(x**2 + y**2))/(2*sp.pi)\n\nA = sp.integrate(pdf, (x, 1, sp.oo), (y, 0, sp.oo));A\n\n\\(\\displaystyle \\frac{\\sqrt{2} \\left(- \\sqrt{2} \\sqrt{\\pi} \\operatorname{erf}{\\left(\\frac{\\sqrt{2}}{2} \\right)} + \\sqrt{2} \\sqrt{\\pi}\\right)}{8 \\sqrt{\\pi}}\\)\n\n\n\nB = sp.integrate(pdf, (x, 1-y, sp.oo), (y, -sp.oo, 0)); B\n\n\\(\\displaystyle \\frac{\\sqrt{2} \\left(\\int\\limits_{-\\infty}^{0} e^{- \\frac{y^{2}}{2}} \\operatorname{erf}{\\left(\\frac{\\sqrt{2} y}{2} - \\frac{\\sqrt{2}}{2} \\right)}\\, dy + \\int\\limits_{-\\infty}^{0} e^{- \\frac{y^{2}}{2}}\\, dy\\right)}{4 \\sqrt{\\pi}}\\)\n\n\n\nprob = (A+B).simplify(); prob\n\n\\(\\displaystyle \\frac{\\sqrt{2} \\left(\\int\\limits_{-\\infty}^{0} e^{- \\frac{y^{2}}{2}} \\operatorname{erf}{\\left(\\frac{\\sqrt{2} y}{2} - \\frac{\\sqrt{2}}{2} \\right)}\\, dy + \\frac{\\sqrt{2} \\sqrt{\\pi}}{2}\\right) + \\sqrt{\\pi} \\left(1 - \\operatorname{erf}{\\left(\\frac{\\sqrt{2}}{2} \\right)}\\right)}{4 \\sqrt{\\pi}}\\)\n\n\n\nprob.evalf()\n\n\\(\\displaystyle 0.108067672862891\\)\n\n\n\n\\(\\P(B_1 > 1, B_2 > 1, B_3 > 1)\\)\n\n\n\nCode\nimport sympy as sp\nfrom fractions import Fraction\nfrom sympy.abc import x,y,z\n\nsp.init_printing()\nC=sp.Matrix([[1, 1, 1], [1, 2, 2], [1, 2, 3]])\n\n\nCinv = C.inv()\nxy = sp.Matrix([x, y, z])\n\n\nf = sp.exp(Fraction(-1, 2) * sp.MatMul(xy.transpose(), Cinv, xy))/((2 *sp.pi)**Fraction(3,2) * sp.sqrt(C.det(), evaluate=False))\npdf = f[0]\nintegral = sp.Integral(pdf, (x, 1, sp.oo), (y, 1, sp.oo), (z, 1, sp.oo))\nintegral\n\n\n\\(\\displaystyle \\int\\limits_{1}^{\\infty}\\int\\limits_{1}^{\\infty}\\int\\limits_{1}^{\\infty} \\frac{\\sqrt{2} e^{- x^{2} + x y - y^{2} + y z - \\frac{z^{2}}{2}}}{4 \\pi^{\\frac{3}{2}}}\\, dx\\, dy\\, dz\\)\n\n\nA change of variables gives a finite domain of integration:\n\n\nCode\npdf = pdf.subs({x: -1/x, y: -1/y, z: -1/z})*sp.diff(-1/x, x)*sp.diff(-1/y, y)*sp.diff(-1/z, z)\n\nsp.Integral(pdf , (x, -1, 0), (y, -1, 0), (z, -1, 0))\n\n\n\\(\\displaystyle \\int\\limits_{-1}^{0}\\int\\limits_{-1}^{0}\\int\\limits_{-1}^{0} \\frac{\\sqrt{2} e^{- \\frac{1}{2 z^{2}} + \\frac{1}{y z} - \\frac{1}{y^{2}} + \\frac{1}{x y} - \\frac{1}{x^{2}}}}{4 \\pi^{\\frac{3}{2}} x^{2} y^{2} z^{2}}\\, dx\\, dy\\, dz\\)\n\n\n\nfrom scipy.integrate import tplquad\n\ndef integrate(integrand):\n    return tplquad(integrand, -1, 0, -1, 0, -1, 0)\n    \nintegrate(sp.lambdify([x, y, z], pdf))\n\n\\(\\displaystyle \\left( 0.087052233285984, \\  1.48956711000826 \\cdot 10^{-8}\\right)\\)\n\n\n\ndef monte_carlo(integrand):\n    samples = 10000\n    sum = 0\n    for _ in range(samples):\n        x, y, z = np.random.default_rng().uniform(-1, 0, 3)\n        sum +=integrand(x, y, z)\n    return sum/samples\n\nprobability = monte_carlo(sp.lambdify([x, y, z], pdf))\nprobability\n\n\\(\\displaystyle 0.0892905458247034\\)\n\n\n\ndef decomposition():\n    brownian = Brownian(np.array(C.tolist()).astype(np.float64))\n\n    samples=10000\n    count = 0\n    for _ in range(samples):\n        b_1 , b_2, b_3 = brownian.path()\n        if b_1 > 1 and b_2 > 1 and b_3 > 1:\n            count+=1\n    return count/samples\n    \ndecomposition()\n\n\\(\\displaystyle 0.0907\\)"
  },
  {
    "objectID": "FCSC/ch3.html#equivalence-of-definition-of-brownian-motion",
    "href": "FCSC/ch3.html#equivalence-of-definition-of-brownian-motion",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.3 Equivalence of Definition of Brownian Motion",
    "text": "3.3 Equivalence of Definition of Brownian Motion\nIf \\(X = (X_i)_{i=1}^n = (B_{t_1} - 0, B_{t_2} - B_{t_1}, \\ldots, B_{t_n} - B_{t_{n-1}})\\) are independent Gaussians with mean zero and variance \\(t_{j+1} -t_j\\) for \\(j \\leq n-1\\), then the vector \\(Y = (Y_i)_{i=1}^n = (B_{t_1}, \\ldots, B_{t_n} )\\) is Gaussian with mean zero and covariance \\(\\E(B_tB_s) = t \\wedge s\\).\nProof:\nThe linear transformation \\(A\\) maps \\(X\\) to \\(Y\\):\n\\[\nA = \\begin{bmatrix}\n1  &  0    &  \\ldots  &  0 \\\\\n-1 &  1    &  \\ldots  &  0 \\\\\n\\vdots    & \\ddots & &  \\vdots \\\\\n0  &     \\ldots  &  -1      &  1\n\\end{bmatrix}\n\\]\nor\n\\[\nA_{ij} = \\begin{cases}\n1 & \\text{if } i=j, \\\\\n-1 & \\text{if } i = j-1, \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nThe mean vector of \\(Y\\) is \\(A\\textbf{0} = \\textbf{0}\\). The covariance of \\(Y\\), \\(C_Y\\), is related to the covariance of \\(X\\), \\(C_X\\) by\n\\[\nA C_X A^T = C_Y.\n\\]\nThis linear relationship can be expressed using cancellation of the telescopic sum: \\[\nY_i = \\sum_{k=1}^i X_k.\n\\]\nFor \\(i < j\\),\n\\[\nY_j = Y_i + \\sum_{k=i+1}^j X_k.\n\\]\nSo,\n\\[\nY_j Y_i = Y_i^2 + Y_i \\sum_{k=i+1}^j X_k.\n\\]\nThen, using the independence of \\(X\\): \\[\n\\begin{align}\n\\E(Y_j Y_i) &= \\E(Y_i^2) + \\sum_{k=i+1}^j \\E(Y_i X_k) \\\\\n&= \\E(Y_i^2) + \\sum_{k=i+1}^j \\E(\\sum_{l=1}^i X_l X_k) \\\\\n&= \\E(Y_i^2).\n\\end{align}\n\\]\nWe can calculate the variance of \\(Y_j\\):\n\\[\n\\begin{align}\n\\E(Y_j^2) & = \\E((\\sum_{k=1}^j X_k)^2) \\\\\n&=  \\E(\\sum_{k=1}^j X_k^2 + 2 \\sum_{k,l = 1}^j X_k X_l) \\\\\n&= \\sum_{k=1}^j \\E(X_k^2) \\\\\n&= \\sum_{k=2}^j (t_{i_{k}} -t_{i_{k-1}}) + t_{i_1} \\\\\n&= t_{i_j}\n\\end{align}\n\\]\nThis proves that\n\\(\\E(B_{t_i} B_{t_j}) = t_i \\wedge t_j\\)."
  },
  {
    "objectID": "FCSC/ch3.html#reflection-at-time-s",
    "href": "FCSC/ch3.html#reflection-at-time-s",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.4 Reflection at time \\(s\\)",
    "text": "3.4 Reflection at time \\(s\\)\nFor any \\(s \\geq 0\\), the process \\((\\tilde{B}_t, t\\geq 0)\\) defined by\n\\[\n\\tilde{B}_t = \\begin{cases}\nB_t & \\text{if } t \\leq s, \\\\\nB_s - (B_t - B_s) & \\text{otherwise}\n\\end{cases}\n\\] is a Brownian motion.\nProof:\nClearly, \\(\\tilde{B}_0 = 0\\). For each continuous path, \\(B_t(\\omega)\\) we can have a continuous path \\(\\tilde{B}(\\omega)\\):\n\\(\\tilde{B}_t(\\omega)\\) is piecewise two obviously continuous functions \\(B_t(\\omega)\\) and \\(2B_s(\\omega) - B_t(\\omega)\\) which are equal at \\(t = s\\). Therefore, for a set of \\(\\omega\\) of probability one, \\(\\tilde{B}_t(\\omega)\\) is continuous.\nFor any \\(t_1 < t_2 < \\ldots < t_n\\), the vector \\((\\tilde{B}_{t_i})_{i=1}^n\\) is Gaussian of mean zero because it is a transformation of \\((B_{t_i})_{i=1}^n\\):\n\\[\n\\tilde{B} = A B + C\n\\]\nwhere\n\\[\nA_{ij} = \\begin{cases}\n1 & \\text{if } i=j \\text{ and } t_i \\leq s, \\\\\n-1& \\text{if } i=j \\text{ and } t_i > s, \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nand \\(C\\) is the Gaussian vector defined \\[\nC_i = \\begin{cases}\n2 B_s & \\text{if } t_i > s, \\\\\n0 & \\text{otherwise.}\n\\end{cases}\n\\] The linear transformation \\(AB\\) results in a Gaussian vector; adding \\(C\\) results in another Gaussian vector because the components of \\(C\\) are in the span of the components of \\(B\\). The mean of the result is zero.\nIf \\(t_1, t_2 \\leq s\\), then \\[\n\\begin{align}\n\\E(\\tilde{B}_{t_1} \\tilde{B}_{t_2}) &= \\E(B_{t_1} B_{t_2}) \\\\\n&= t_1 \\wedge t_2.\n\\end{align}\n\\]\nIf \\(t_1 \\leq s\\) and \\(t_2 > s\\), then \\[\n\\begin{align}\n\\E(\\tilde{B}_{t_1} \\tilde{B}_{t_2}) &= \\E(B_{t_1} (2B_s - B_{t_2})) \\\\\n&= 2 \\E(B_{t_1} B_s) - \\E(B_{t_1} B_{t_2}) \\\\\n&= 2 t_1 - t_1 \\\\\n&= t_1 \\\\\n&= t_1 \\wedge t_2.\n\\end{align}\n\\]\nIf \\(t_1, t_2 > s\\), then \\[\n\\begin{align}\n\\E(\\tilde{B}_{t_1} \\tilde{B}_{t_2}) &= \\E((2B_{s} - B_{t_1})(2B_s - B_{t_2})) \\\\\n&= 4 \\E(B_s^2) -2 \\E(B_s B_{t_2}) -2 \\E(B_s B_{t_1}) + \\E(B_{t_1}B_{t_2}) \\\\\n&= 4 s - 2 s - 2s  + t_1 \\wedge t_2 \\\\\n&= t_1 \\wedge t_2.\n\\end{align}\n\\]\nTherefore, for any \\(s, t\\)\n\\[\n\\E(\\tilde{B}_s \\tilde{B}_t) = s \\wedge t.\n\\]"
  },
  {
    "objectID": "FCSC/ch3.html#time-reversal",
    "href": "FCSC/ch3.html#time-reversal",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.5 Time Reversal",
    "text": "3.5 Time Reversal\nLet \\((B_t, t \\geq 0)\\) be a Brownian motion. The process \\((B_1 - B_{1-t}, t \\in [0,1])\\) has the distribution of a standard Brownian motion on \\([0, 1]\\).\nProof:\n\\(B_1 - B_{1-t} = 0\\) when \\(t = 0\\). If \\(\\omega\\) is such that \\(B_t(\\omega)\\) is continuous, then \\(B_{1-t}(\\omega)\\) is continuous since \\(t \\mapsto 1-t\\) is continuous. It follows that \\(B_1(\\omega) - B_{1-t}(\\omega)\\) is continuous. Therefore, for \\(\\omega\\) in a set of probability one, \\(B_1(\\omega) - B_{1-t}(\\omega)\\) is continuous.\nLet \\(0 \\leq t_1 < t_2 < \\ldots < t_n \\leq 1\\). The vector \\((B_1 -B_{1-t_i})_{i=1}^n\\) is Gaussian: it is simply a Brownian Gaussian vector written in reverse with \\(B_1\\) added, which results in a Gaussian vector. It is easy to see that the mean is zero by linearity of expectation.\nThe covariance reveals the distribution:\n\\[\n\\begin{align}\n\\Cov((B_1 - B_{1-t_i}), (B_1 - B_{1-t_j})) &= \\E((B_1 - B_{1-t_i})(B_1 - B_{1-t_j})) \\\\\n&= \\E(B_1^2) - \\E(B_{1-t_i}B_1) - \\E(B_{1 -t_j}B_1) + \\E(B_{1-t_i} B_{1-t_j}) \\\\\n&= 1 - (1-t_i) - (1-t_j) + (1-t_i) \\wedge (1-t_j) \\\\\n&= t_i + t_j -1 + 1 - t_i \\vee t_j \\\\\n&= t_i + t_j - t_i \\vee t_j \\\\\n& = t_i \\wedge t_j.\n\\end{align}\n\\]"
  },
  {
    "objectID": "FCSC/ch3.html#time-inversion",
    "href": "FCSC/ch3.html#time-inversion",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.6 Time Inversion",
    "text": "3.6 Time Inversion\n\nLet \\((B_t, t \\geq 0)\\) be a standard Brownian motion. The process\n\n\\[\nX_t = t B_{1/t} \\text{ for } t > 0,\n\\]\nhas the distribution of a Brownian motion on \\(t > 0\\).\nProof:\nLet \\(0 < t_1 < \\ldots < t_n\\) and define \\(s_{n-i} = 1/t_i\\), so that \\(0 < s_1 < \\ldots < s_n\\). The vector \\(T=(B_{t_i})_{i=1}^n\\) is Gaussian by assumption. \\(S=(\\frac{1}{s_i} B_{s_i})_{i=1}^{n}\\) is a linear transformation of \\(T\\) and so is also Gaussian with mean zero:\n\\[\nS = \\begin{bmatrix}\n0 & \\ldots & 0 & \\frac{1}{s_1} \\\\\n0 & \\ldots & \\frac{1}{s_2} & 0 \\\\\n\\vdots & \\iddots & 0 & 0 \\\\\n\\frac{1}{s_n} & 0 & \\ldots & 0\n\\end{bmatrix}\\,T.\n\\]\nThe covariance, and hence the distribution, of \\(S\\) can be found by simple calculation:\n\\[\n\\begin{align}\n\\E(t_i B_{1/t_i} t_jB_{1/t_j}) &= t_it_j \\frac{1}{t_i} \\wedge \\frac{1}{t_j} \\\\\n&= \\frac{t_it_j}{t_i \\vee t_j} \\\\\n&= t_i \\wedge t_j.\n\\end{align}\n\\]\n\n\\(X_t \\to 0\\) in \\(L^2\\) as \\(t \\to 0\\).\n\nProof:\n\\[\n\\begin{align}\n\\| X_t \\|_2 &= \\| t B_{1/t} \\|_2 \\\\\n&= \\E(t^2 B_{1/t}^2) \\\\\n&= t^2 1/t \\\\\n&= t \\to 0\n\\end{align}\n\\] as \\(t \\to 0\\).\n\n\\[\n\\lim_{t \\to \\infty} \\frac{B_t}{t} = 0\n\\] almost surely.\n\nProof:\nWe are allowed to use\n\\[\nX_t \\to 0\n\\] as \\(t \\to 0\\) almost surely. Note: we didn’t show this above.\n\\[\n\\lim_{t\\to \\infty} \\frac{B_t}{t} = X_{1/t} \\to 0\n\\] as \\(t \\to \\infty\\), almost surely."
  },
  {
    "objectID": "FCSC/ch3.html#convergence-in-mean-or-in-l1",
    "href": "FCSC/ch3.html#convergence-in-mean-or-in-l1",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.8 Convergence in mean or in \\(L^1\\)",
    "text": "3.8 Convergence in mean or in \\(L^1\\)\nIf \\(X_n \\to X\\) in \\(L^1(\\Omega, \\mathcal{F}, \\P)\\), then \\(X_n \\to X\\) in probability.\nProof:\n\\(X_n \\to X\\) in \\(L^1\\) iff \\(\\E(|X_n - X|) \\to 0\\) as \\(n \\to \\infty\\).\nBy Markov’s inequality, for any \\(\\delta > 0\\)\n\\[\n\\begin{align}\n\\P(|X_n - X| > \\delta) &\\leq \\frac{1}{\\delta} \\E(|X_n - X|).\n\\end{align}\n\\] The RHS tends to zero as \\(n \\to \\infty\\) so the LHS must also. That is, \\(X_n \\to X\\) in probability as \\(n \\to \\infty\\)."
  },
  {
    "objectID": "FCSC/ch3.html#fractional-brownian-motion",
    "href": "FCSC/ch3.html#fractional-brownian-motion",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.9 Fractional Brownian Motion",
    "text": "3.9 Fractional Brownian Motion\nFractional Brownian motion \\((Y_t, t\\geq 0)\\) with index \\(0 < H < 1\\), is the Gaussian process with mean zero and covariance \\[\n\\Cov(Y_s, Y_t) = \\frac{1}{2}(t^{2H} + s^{2H} - \\left | t - s \\right |^{2H}).\n\\]\n\nThe standard Brownian motion corresponds to \\(H= 1/2\\).\n\nProof:\nWhen \\(H=1/2\\), \\[\n\\begin{align}\n\\Cov(Y_s, Y_t) &= \\frac{1}{2}(t + s - \\left | t - s\\right |) \\\\\n&= s \\wedge t.\n\\end{align}\n\\]\n\n\\(Y_{at}\\) has the same distribution as \\(a^{2H} Y_t\\) for \\(a > 0\\).\n\nProof:\n\\[\n\\begin{align}\n\\Cov(Y_{as}, Y_{at}) &= \\frac{1}{2}(a^{2H}t^{2H} + a^{2H}s^{2H} - \\left | at - as\\right |^{2H}) \\\\\n&= a^{2H} \\frac{1}{2}(t^{2H} + s^{2H} - \\left | t - s \\right |^{2H}) \\\\\n&= a^{2H} \\Cov(Y_s, Y_t) \\\\\n&= \\Cov(a^H Y_s, a^H Y_t).\n\\end{align}\n\\]\n\nThe increment \\(Y_t - Y_s\\) has a Gaussian distribution and is stationary.\n\nProof:\nBy definition, \\((Y_t, Y_s)\\) is a Gaussian vector so \\(Y_t - Y_s\\) is Gaussian. The covariance depends only on \\(t - s\\) so \\(Y_t - Y_s\\) is stationary:\n\\[\n\\begin{align}\n\\Var(Y_t - Y_s) &= \\E((Y_t - Y_s)^2) \\\\\n&= \\E(Y_t^2 - 2 Y_tY_s + Y_s^2) \\\\\n&= \\E(Y_t^2) -2 \\E(Y_tY_s) + \\E(Y_s^2) \\\\\n&= t^{2H} + s^{2H} -(t^{2H} + s^{2H} - \\left| t - s \\right|^{2H}) \\\\\n&= \\left| t - s \\right|^{2H}.\n\\end{align}\n\\]\n\nThe increments \\(Y_t - Y_s\\) are independent if and only if \\(H=1/2\\). The increments are negatively correlated if \\(H < 1/2\\) and positively correlated if \\(H > 1/2\\).\n\nProof:\nIf \\(H=1/2\\), then the process is the standard Brownian motion and so the increments are independent.\nSuppose that the increments are independent. Since they are Gaussian, this is equivalent to the covariance of the increments being zero:\nfor all \\(a \\leq b \\leq c \\leq d\\) \\[\n\\begin{align}\n\\E((Y_a - Y_b)(Y_c - Y_d)) &= \\E(Y_aY_c) - \\E(Y_a Y_d) - \\E(Y_b Y_c) + \\E(Y_b Y_d) \\\\\n&= \\frac{1}{2}\\left ( a^{2H} + c^{2H} - |a - c|^{2H} - a^{2H} - d^{2H} + |a - d|^{2H} - b^{2H} - c^{2H} + |b - c|^{2H} + b^{2H} +d^{2H} - |b -d |^{2H}\\right) \\\\\n&= \\frac{1}{2} \\left ( (d -a)^{2H} - (c -a )^{2H} + (c -b)^{2H} - (d -b )^{2H}\\right) \\\\\n&= 0.\n\\end{align}\n\\]\nIn particular, If we set \\(a=0, b=1, c=1, d=2\\), then the condition becomes\n\\[\n\\begin{align}\n(d -a)^{2H} - (c -a )^{2H} + (c -b)^{2H} - (d -b )^{2H} \\\\\n= 2^{2H} - 1^{2H} + 0^{2H} - 1^{2H} \\\\\n= 2^{2H} - 2 = 0\n\\end{align}\n\\]\nand so \\(H=1/2\\).\nLet \\(0 \\leq s_1 \\leq t_1 \\leq s_2 \\leq t_2\\). Set\n\\(a_1 = t_2 - s_1\\), \\(a_2 = t_2 - t_1\\), \\(b_1 = s_2 - s_1\\) and \\(b_2 = s_2 - t_1\\).\n\\[\n\\E((Y_{t_1} - Y_{s_1})(Y_{t_2}-Y_{s_2})) = \\frac{1}{2} \\left ( f(a_1) - f(a_2) - (f(b_1) - f(b_2)) \\right )\n\\]\nwhere \\(f=x^{2H}\\). \\(a_1 - a_2 = b_1 - b_2 = t_1 - s_1\\) and so using convexity of \\(f\\) when \\(H > 1/2\\), the covariance is positive; when \\(H < 1/2\\), the covariance is negative because f is concave.\n\n\n\n\n\n\nNote\n\n\n\n\n\nCode\ndef f(x, H):\n    return np.power(x,2*H)\n\nH = 99/100\n\nplt.xlim(0.5, 4)\n\n\nax = [3.5, 2]\nfor i,x in enumerate(ax):\n    plt.axvline(x, color='r', linestyle='--', label = f'a_{i}')\n\nplt.plot(ax, f(ax, H))\n\nbx = [2.5, 1]\nfor i,x in enumerate(bx):\n    plt.axvline(x, color='r', linestyle='-', label = f'b_{i}')\n    \nplt.plot(bx, f(bx, H))\n\nx = np.linspace(0,4, 1000)\nplt.plot(x, f(x, H))\nplt.legend(loc='upper left')\nplt.show()\n\n\n\n\n\n\\[\nf(a_1) - f(a_2) \\geq f(a_1) -f(b_2) \\geq f'(b_2) (a_1 - a_2) = f'(b_2) (t_1 -s_1)\n\\]\n\\[\nf(b_1) - f(b_2) \\leq f'(b_1) (b_1 - b_2) = f'(b_1) (t_1 - s_1)\n\\]\n\\[\nf(a_1) - f(a_2) -(f(b_1) - f(b_2)) \\geq 0.\n\\]"
  },
  {
    "objectID": "FCSC/ch3.html#the-arcsine-law-on-0-t",
    "href": "FCSC/ch3.html#the-arcsine-law-on-0-t",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.10 The Arcsine Law on \\([0, T]\\)",
    "text": "3.10 The Arcsine Law on \\([0, T]\\)\nBy the scaling property of Brownian motions, \\((B_t, t \\in [0,T])\\) has the same distribution as \\((\\frac{1}{\\sqrt{T}} B_{Tt}, t \\in [0, 1])\\). The multiplicative factor does not change the proportion of time the path is positive: the CDF is the same as for motion on \\([0,1]\\)."
  },
  {
    "objectID": "FCSC/ch3.html#an-application-of-the-monotone-convergence-theorem",
    "href": "FCSC/ch3.html#an-application-of-the-monotone-convergence-theorem",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.11 An Application of the Monotone Convergence Theorem",
    "text": "3.11 An Application of the Monotone Convergence Theorem\nLet \\(X_n \\geq 0\\) be a sequence of random variables on \\((\\Omega, \\mathcal{F}, \\P)\\). Then\n\\[\n\\E(\\sum_{n\\geq 1} X_n) = \\sum_{n \\geq n} \\E(X_n).\n\\]\nProof:\nDefine\n\\[\nY_k = \\sum_{n=1}^k X_n.\n\\] Then \\(Y_k\\) is a sequence of random variables such that \\(0 \\leq Y_k \\leq Y_{k+1}\\) for all \\(k\\).\nBy the monotone convergence theorem,\n\\[\n\\lim_{k \\to \\infty} \\E(Y_k) = \\E(\\lim_{k \\to \\infty} Y_k).\n\\] That is,\n\\[\n\\sum_{n \\geq 1} \\E(X_n) = \\E(\\sum_{n \\geq 1} X_n).\n\\]"
  },
  {
    "objectID": "FCSC/ch3.html#borel-contelli-lemma-i",
    "href": "FCSC/ch3.html#borel-contelli-lemma-i",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.12 Borel-Contelli Lemma I",
    "text": "3.12 Borel-Contelli Lemma I\nLet \\((A_n)\\) be a sequence of events in \\((\\Omega, \\mathcal{F}, \\P)\\) such that\n\\[\n\\sum_n \\P(A_n) < \\infty.\n\\]\nThen \\[\n\\P(\\{ \\omega \\in \\Omega: \\omega \\in A_n \\text{ for infinitely many } n\\}) = 0.\n\\]\nProof:\nImmediately, \\[\n\\begin{align}\n\\sum_n \\P(A_n) = \\sum_n \\E(\\mathbb{1}_{A_n}) < \\infty.\n\\end{align}\n\\]\nBy the monotone convergence theorem\n\\[\n\\sum_n \\E(\\mathbb{1}_{A_n}) = \\E(\\sum_n \\mathbb{1}_{A_n}) < \\infty.\n\\]\nIt follows that \\[\n\\P(\\sum_n \\mathbb{1}_{A_n} < \\infty) = 1.\n\\]\nThe sum of indicator functions is a sum of ones and zeros. For the sum to be finite for any \\(\\omega\\), \\(\\mathbb{1}_{A_n}(\\omega) = 1\\) for only finitely many \\(n\\) with probability 1 i.e. any \\(\\omega \\in A_n\\) for only finitely many \\(n\\). Therefore,\n\\[\n\\P(\\left \\{\\omega \\in \\Omega : \\omega \\in A_n \\text{ for finitely many } n\\right \\}) = 1\n\\] and the result follows by taking the complement."
  },
  {
    "objectID": "FCSC/ch3.html#convergence-in-probability-nrightarrow-convergence-almost-surely",
    "href": "FCSC/ch3.html#convergence-in-probability-nrightarrow-convergence-almost-surely",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.13 Convergence in Probability \\(\\nRightarrow\\) Convergence Almost Surely",
    "text": "3.13 Convergence in Probability \\(\\nRightarrow\\) Convergence Almost Surely\nLet \\(U\\) be a uniform random variable taking values in \\([0, 1]\\).\nExpress each \\(n\\) as\n\\[\nn = 2^j + k\n\\] where \\(k= 0, \\ldots, 2^j-1\\).\nDefine\n\\[\nX_n = \\mathbb{1}_{A_n}\n\\] where \\(A_n = \\{\\omega \\in \\Omega : U(\\omega) \\in [2^{-j}k, 2^{-j}(k+1) ]\\}\\).\n\\(X_n\\) converges to \\(0\\) in probability.\nProof:\n\\[\n\\begin{align}\n\\P( |X_n| > \\delta ) &= \\begin{cases}\n2^{-j} & 0 < \\delta <= 1, \\\\\n0 & \\text{otherwise}\n\\end{cases} \\\\\n&\\to 0\n\\end{align}\n\\]\nas \\(n \\to \\infty\\).\n\\(\\square\\)\n\\(X_n\\) does not converge to \\(0\\) almost surely.\nProof:\nLet \\(\\omega \\in \\Omega\\). Let \\(x = U(\\omega)\\). For \\(n = 2^j + k\\),\n\\(x \\in [2^{-j}k, 2^{-j}(k+1)]\\) for exactly one \\(k\\). Therefore, \\((X_n(\\omega))\\) is an infinite sequence of \\(0\\) and \\(1\\) which never converges.\n\\(\\square\\)"
  },
  {
    "objectID": "FCSC/ch3.html#but-ok-on-a-subsequence",
    "href": "FCSC/ch3.html#but-ok-on-a-subsequence",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.14 But OK on a Subsequence",
    "text": "3.14 But OK on a Subsequence\nLet \\(X_n \\to X\\) in probability as \\(n \\to \\infty\\) and let \\(\\delta > 0\\). For each \\(n\\), there is \\(m(n)\\) such that\n\\[\n\\P(|X_{n_k} - X| > \\delta) < \\frac{1}{2^n}\n\\] for \\(n_k \\geq m(n)\\). Choose one such \\(n_k\\) for each \\(n\\) to create a subsequence for \\((X_{n_k})\\).\n\\[\n\\begin{align}\n\\sum_k \\P(|X_{n_k} - X| > \\delta) &< \\sum_n \\frac{1}{2^n} < \\infty.\n\\end{align}\n\\]\nThis subsequence will converge almost surely."
  },
  {
    "objectID": "FCSC/ch3.html#construction-of-the-poisson-process",
    "href": "FCSC/ch3.html#construction-of-the-poisson-process",
    "title": "A First Course in Stochastic Calculus",
    "section": "3.15 Construction of the Poisson Process",
    "text": "3.15 Construction of the Poisson Process\n\n\n\n\n\n\nWarning\n\n\n\nThe book says that \\(\\tau_k\\) are exponential with parameter \\(1/\\lambda\\). I think the parameter should be \\(\\lambda\\). The mean would then be \\(1/\\lambda\\): maybe there’s some confusion here between the parameter and the mean arrival time?\n\n\nWe know that\n\\[\n\\tau_1 + \\cdots + \\tau_k \\sim \\ \\operatorname{Gamma}\\left (k+1, \\lambda \\right).\n\\]\nThe PDF of \\(\\operatorname{Gamma}\\left (k, \\lambda \\right)\\) is\n\\[\nf(x) = \\frac{\\lambda^k}{(k-1)!} x^{k-1} e^{-\\lambda x}.\n\\]\nTherefore,\n\\[\n\\begin{align}\n\\P(\\tau_1 + \\ldots + \\tau_k \\leq t) &= \\int_0^t \\frac{\\lambda^k}{ (k-1)!} x^{k-1} e^{-\\lambda x}\\, dx \\\\\n&= \\frac{1}{(k-1)!}\\int_0^{\\lambda t} x^{k-1} e^{-x}\\, dx \\\\\n&= 1 - e^{-\\lambda t} \\sum_{n=0}^{k-1} \\frac{t^{n} \\lambda^{n}}{n!}\n\\end{align}\n\\]\nNow \\[\\P(N_t \\geq k) = \\P(\\tau_1 + \\cdots \\tau_k \\leq t)\\] and so\n\\[\n\\begin{align}\n\\P(N_t = k) &= \\P(N_t \\geq k+ 1) - \\P(N_t \\geq k) \\\\\n&= \\frac{e^{-\\lambda t}}{k!} t^k\\lambda^k.\n\\end{align}\n\\]\nThat is, \\(N_t\\) has Poisson distribution with parameter \\(\\lambda t\\).\nDefine \\(J_n = \\sum_{i=1}^n \\tau_i\\). Then using the memory loss property of exponential variables\n\\[\n\\begin{align}\n\\P(\\tau_{l+1} - (s - J_l) > t | N_s = l) &= \\P(\\tau_{l+1} > t + s - J_l | J_l \\leq s, J_{l+1} > s) \\\\\n&= \\P(\\tau_{l+1} > t + s - J_l | J_l \\leq s, \\tau_{l+1} > s - J_l) \\\\\n&= \\int_0^s \\P(\\tau_{l+1} > t + s - x | \\tau_{l+1} > s - x) d\\P_{J_l}(x) \\\\\n&= \\int_0^s \\P(\\tau_{l+1} > t) d\\P_{J_l}(x) \\\\\n&= \\P(\\tau_{l+1} > t) \\\\\n&= \\P(\\tau_1 > t).\n\\end{align}\n\\] Therefore, \\(\\tau_{l+1} - (s - J_l)\\) conditioned on \\(N_s = l\\) is exponential with parameter \\(\\lambda\\).\nFor \\(i > 1\\), \\(\\tau_{l+i}\\) are independent of \\(\\tau_j\\) for \\(j \\leq l\\) and so are independent of \\((N_r)_{r \\leq s}\\). So, conditioned on \\(N_s=l\\), \\(\\tau_{l+i}\\) are exponential with parameter \\(\\lambda\\) for \\(i \\geq 1\\).\nDefine\n\\[\nt_i = \\begin{cases}\n\\tau_{l+1} - (s - J_l) & \\text{ for } i = 0, \\\\\n\\tau_{l+i} & \\text{ otherwise}\n\\end{cases}.\n\\]\nWe have shown so far that \\(t_i\\) are exponentially distributed with parameter \\(\\lambda\\), conditioned on \\(N_s = l\\). They are also independent since\n\\[\n\\P(t_1 > s_1, \\ldots, t_k > s_k | N_s = l) = \\P(\\tau_1 > s_1, \\ldots, \\tau_k > s_k).\n\\]\nIf we use the law of total probability \\[\n\\begin{align}\n\\P(t_1 > s_1, \\ldots, t_k > s_k) &= \\sum_l \\P(t_1 > s_1, \\ldots, t_k > s_k | N_s = l) \\P(N_s = l) \\\\\n&= \\P(\\tau_1 > s_1, \\ldots, \\tau_k > s_k)\n\\end{align}\n\\] we see that \\((t_i)\\) are exponentially distributed with parameter \\(\\lambda\\) without conditioning! They are also independent without conditioning. We can also work backwards to state that \\((t_i)\\) are independent of \\(N_s\\). In fact, \\((t_i)\\) are independent of \\((N_r)_{r \\leq s}\\).\nTherefore, \\(Y_t\\) is the sum of IID exponential variables and has Poisson distribution with parameter \\(\\lambda t\\):\n\\[\n\\begin{align}\n\\P(Y_t \\geq k) &= \\frac{e^{-\\lambda t}}{k!} t^k\\lambda^k.\n\\end{align}\n\\]\nThat is, \\(Y_t = N_{t + s} - N_s\\) is Poisson distributed with parameter \\(\\lambda t\\) or, what is the same, \\(N_t - N_s\\) is Poisson distributed with parameter \\(\\lambda(t - s)\\).\nWe established that \\(N_s\\) and \\((t_i)\\) are independent. Since \\(Y_t\\) is a sum of \\((t_i)\\), it must be independent of \\((N_r)_{r \\leq s}\\). That is, \\(N_t - N_s\\) is independent of \\(N_s = N_s - N_0\\). So, at least two increments, \\(N_t - N_s\\) and \\(N_s - N_0\\), are independent. This can be extended: For any \\(t_3 > t_2 > t_1\\), \\(N_{t_3} - N_{t_2}\\) is independent of \\(N_{t_2}\\) and \\(N_{t_1}\\) so is independent of \\(N_{t_2} - N_{t_1}\\). This establishes pairwise independence of intervals. Suppose that \\(t_1 < t_2 < \\ldots < t_n\\). For \\(n=2\\), we have established that \\((N_{t_{i+1}} - N_{t_i})\\) are independent. Suppose that this is true for \\(n=k\\) and consider the case \\(n=k+1\\). The increments \\((N_{t_{i+1}} - N_{t_i})_{i=1}^{k}\\) (\\(n\\) increments) are independent because these can be considered to be increments of the process \\(N'_t = N_t - N_{t_1}\\). We know that each of these increments is independent of \\(N_{t_1}\\) which completes the proof by induction."
  },
  {
    "objectID": "FCSC/ch2.html",
    "href": "FCSC/ch2.html",
    "title": "A First Course in Stochastic Calculus",
    "section": "",
    "text": "Let \\(U_1 \\sim U(0,1)\\) and \\(U_2 \\sim U(0,1)\\). Define random variables\n\\[\nZ_1 = \\sqrt{-2\\log(U_1)} \\cos(2 \\pi U_2)\n\\] and \\[\nZ_2 = \\sqrt{-2\\log(U_1)} \\sin(2 \\pi U_2).\n\\]\nGenerate \\(10000\\) samples of \\((Z_1, Z_2)\\) and plot the histograms of each random variable.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nrg = np.random.default_rng()\n\nN = 10000\nbins=100\n\nU1 = rg.uniform(0, 1, N)\nU2 = rg.uniform(0, 1, N)\n\nnormal = rg.normal(0, 1, N)\n\nZ1 = [np.sqrt(-2 * np.log(u[0])) * np.cos(2 * np.pi * u[1]) for u in zip(U1, U2)]\nZ2 = [np.sqrt(-2 * np.log(u[0])) * np.sin(2 * np.pi * u[1]) for u in zip(U1, U2)]\n\n\nplt.hist(normal, bins=bins, label='normal', alpha=0.5)\nplt.hist(Z1, bins=bins, label='Z1', alpha=0.5)\nplt.legend(loc='upper right')\nplt.plot()\n\n[]\n\n\n\n\n\n\nplt.hist(normal, bins=bins, label='normal', alpha=0.5)\nplt.hist(Z2, bins=bins, label='Z2', alpha=0.5)\nplt.legend(loc='upper right')\nplt.plot()\n\n[]\n\n\n\n\n\n\nplt.hist2d(Z1, Z2, bins=bins, density=True)\nplt.plot()\n\n[]\n\n\n\n\n\n\n\\[\n\\newcommand{\\Cov}{\\operatorname{Cov}}\n\\newcommand{\\Var}{\\operatorname{Var}}\n\\newcommand{\\E}{\\operatorname{E}}\n\\newcommand{\\P}{\\operatorname{P}}\n\\newcommand{\\rank}{\\operatorname{rank}}\n\\newcommand{\\trace}{\\operatorname{trace}}\n\\def\\iddots{{\\kern3mu\\raise1mu{.}\\kern3mu\\raise6mu{.}\\kern3mu\n\\raise12mu{.}}}\n\\]\n\n\n\n\n\nclass Brownian:\n    def __init__(self, samples):\n        covariance = [[min(i,j) for i in range(1, samples)] for j in range(1, samples)]\n        self.__A = (1/np.sqrt(samples))*np.linalg.cholesky(covariance)\n        return\n    \n    def path(self, rg = np.random.default_rng()):\n        return np.r_[0, self.__A.dot(rg.normal(0, 1, samples -1))]\n\n    \n\nsamples = 100\nx_axis = np.linspace(0, 1, samples)\n\nbrownian = Brownian(samples)\n\nfor _ in range(100):\n    plt.plot(x_axis, brownian.path())\nplt.title('Brownian motion')\nplt.show()\n\n\n\n\n\n\n\n\nclass OU:\n    def __init__(self, samples):\n        covariance = [ [ (1/2)*np.exp(-(1/samples) * np.abs(i -j))*(1 - np.exp(-(2/samples)*min(i, j))) for i in range(1, samples)] for j in range(1, samples)]\n        self.__A = np.linalg.cholesky(covariance)\n        return\n\n    def path(self, rg = np.random.default_rng()):\n        return np.r_[0, self.__A.dot(rg.normal(0, 1, samples-1))]\n        \nou = OU(samples)    \n\nfor _ in range(100):\n    plt.plot(x_axis, ou.path())\nplt.title('Ornstein-Uhlenbeck Process')\nplt.show()\n\n\n\n\n\nclass OUStationary:\n    def __init__(self, samples):\n        covariance = [ [ (1/2)*np.exp(-(1/samples) * np.abs((i -j))) for i in range(samples)] for j in range(samples)]\n        self.__A = np.linalg.cholesky(covariance)\n        return\n\n    def path(self, rg = np.random.default_rng()):\n        return self.__A.dot(rg.normal(0, 1, samples))\n\n\nouStationary = OUStationary(samples)\n\nfor _ in range(100):\n    plt.plot(x_axis, ouStationary.path())\nplt.title('Stationary Ornstein-Uhlenbeck Process')\n\nText(0.5, 1.0, 'Stationary Ornstein-Uhlenbeck Process')\n\n\n\n\n\n\n\n\n\nclass FractionalBrownian:\n    def __init__(self, samples, H):\n        def cov(i,j):\n            scale = 1/samples\n            i, j = scale*i, scale*j\n            return (1/2) *(i**(2*H) + j**(2*H) - np.abs(i -j)**(2*H))\n        covariance = [[cov(i, j) for i in range(1, samples)] for j in range(1, samples)]\n        self.__A = np.linalg.cholesky(covariance)\n        return\n\n    def path(self, rg = np.random.default_rng()):\n        return np.r_[0, self.__A.dot(rg.normal(0, 1, samples-1))]\n\n\n    \n\nfor H in [0.1, 0.5, 0.9]:\n    fractionalBrownian = FractionalBrownian(samples, H)\n    for _ in range(100):\n        plt.plot(x_axis, fractionalBrownian.path())\n    plt.title(f'Fractional Brownian H = {H}')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nclass BrownianBridge:\n    def __init__(self, samples):\n        def cov(i, j):\n            scale = 1/samples\n            s = min(i,j)*scale\n            t = max(i,j)*scale\n            return s*(1 - t)\n        \n        covariance = [[cov(i,j) for i in range(1, samples -1)] for j in range(1, samples -1)]\n        self.__A = np.linalg.cholesky(covariance)\n        return\n\n    def path(self, rg = np.random.default_rng()):\n        return np.r_[np.r_[0, self.__A.dot(rg.normal(0, 1, samples-2))], 0]\n\n    \nbrownianBridge = BrownianBridge(samples)    \nfor _ in range(100):\n    plt.plot(x_axis, brownianBridge.path())\nplt.title('Brownian Bridge')\nplt.show()\n\n\n\n\n\n\n\n\nclass BrownianBridgeAlt:\n    def __init__(self, samples):\n        self.__brownian = Brownian(samples)\n        return\n\n    def path(self, rg = np.random.default_rng()):\n        path = self.__brownian.path(rg)\n        return [ path[i] - (i/samples) * path[-1] for i in range(len(path)) ]\n        \nbrownianBridgeAlt = BrownianBridgeAlt(samples)\n\nfor _ in range(100):\n    plt.plot(x_axis, brownianBridgeAlt.path())\nplt.title('Brownian Bridge Generated from Brownian Motion')\nplt.show()\n\n\n\n\n\n\n\n\nseed = 2\npath_a = brownianBridge.path(rg = np.random.default_rng(seed))\npath_b = brownianBridgeAlt.path(rg = np.random.default_rng(seed))\n\nplt.plot(x_axis, path_a, label='(a)')\nplt.plot(x_axis, path_b, label='(b)')\nplt.legend(loc='upper right')\nplt.show()\n\nplt.plot(x_axis, path_b - path_a)\nplt.plot(x_axis, x_axis)\nplt.title('difference between brownian bridge paths')\nplt.show()"
  },
  {
    "objectID": "FCSC/ch2.html#an-example-of-uncorrelated-random-variables-that-are-not-independent",
    "href": "FCSC/ch2.html#an-example-of-uncorrelated-random-variables-that-are-not-independent",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.1 An Example of Uncorrelated Random Variables that are not Independent",
    "text": "2.1 An Example of Uncorrelated Random Variables that are not Independent\nLet \\(X\\) be a standard Gaussian. Show that \\(\\Cov(X^2, X) = 0\\).\n\\[\n\\Cov(X^2, X) = \\E(X^3) - \\E(X^2)\\E(X)\n\\]\nThe standard Gaussian has odd moments equal to zero so\n\\[\n\\Cov(X^2, X) = 0 - \\E(X^2).0 = 0.\n\\]\nIf you don’t have the knowledge at your fingertips, there’s always direct calculation:\nWe already know that \\(\\E(X) = 0\\) for the standard Gaussian (it has mean \\(0\\)).\nUsing integration by parts: \\[\n\\begin{align}\n\\E(X^3) & = \\frac{1}{\\sqrt{2 \\pi}}\\int_{-\\infty}^{\\infty} x^3 e^{-x^2/2} dx \\\\\n&=  \\frac{1}{\\sqrt{2 \\pi}}\\int_{-\\infty}^{\\infty} x^2 \\frac{d}{dx}(-e^{-x^2/2}) dx \\\\\n&= \\frac{1}{\\sqrt{2 \\pi}} (-x^2 e^{-x^2/2} \\rvert_{-\\infty}^{\\infty} + \\int_{-\\infty}^{\\infty} 2 x e^{-x^2/2} dx) \\\\\n& = 2 \\E(X) = 0.\n\\end{align}\n\\]"
  },
  {
    "objectID": "FCSC/ch2.html#sum-of-exponentials-is-gamma",
    "href": "FCSC/ch2.html#sum-of-exponentials-is-gamma",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.2 Sum of Exponentials is Gamma",
    "text": "2.2 Sum of Exponentials is Gamma\nThe sum of \\(n\\) IID random variables with exponential distribution with parameter \\(\\lambda\\) is gamma with pdf\n\\[\n\\begin{align}\nf(x) = \\frac{\\lambda^n}{(n-1)!}x^{n-1} e^{-\\lambda x} &, x \\geq 0.\n\\end{align}\n\\tag{1}\\]\nProof:\nThe pdf of the sum of two IID random variables is the convolution of the pdfs of the summands.\nTherefore, \\[\n\\begin{align}\nf(x) &= \\int_{0}^{x} \\lambda^2 e^{-\\lambda(x - y)}e^{-\\lambda y} dy \\\\\n&= \\lambda^2 e^{-\\lambda x} \\int_{0}^{x} dy \\\\\n&= \\lambda^2 x e^{-\\lambda x}.\n\\end{align}\n\\]\nSo, it’s at least plausible.\nTo prove the result, we use the MGF of the exponential random variables \\(X\\) with parameter \\(\\lambda\\):\n\\[\n\\begin{align}\n\\E(e^{tX}) &= \\frac{\\lambda}{\\lambda -t} &, t < \\lambda.\n\\end{align}\n\\]\nLet \\(X_i\\) be a collection of IID exponential random variables with parameter \\(\\lambda\\). Then \\(Z = \\sum X_i\\) satisfies\n\\[\n\\E(e^{tZ}) = \\prod_{i=1}^n \\E(e^{tX_i}) = \\frac{\\lambda^n}{(\\lambda -t)^n}.\n\\]\nSuppose that \\(Y\\) has pdf (Equation 1), then for \\(t < \\lambda\\) we see that be repeated integration by parts\n\\[\n\\begin{align}\n\\E(e^{tY}) &= \\int_0^{\\infty} e^{tx} \\frac{\\lambda^n}{(n-1)!}x^{n-1} e^{-\\lambda x} dx \\\\\n&=    \\int_0^{\\infty} \\frac{\\lambda^n}{(n-1)!}x^{n-1} e^{(t -\\lambda) x} dx \\\\\n&= \\int_0^{\\infty} \\frac{\\lambda^n}{(n-1)!} x^{n-1} \\frac{(-1)^n}{(\\lambda -t)^n} \\frac{d^n}{dx^n}e^{(t-\\lambda)x} dx \\\\\n&= \\frac{\\lambda^n}{(n-1)!} \\frac{(-1)^n}{(\\lambda -t)^n} \\int_0^{\\infty} x^{n-1} \\frac{d^n}{dx^n}e^{(t-\\lambda)x} dx \\\\\n&= \\frac{\\lambda^n}{(n-1)!} \\frac{(-1)^n}{(\\lambda -t)^n} (-(n-1)\\int_0^{\\infty} x^{n-2} \\frac{d^{n-1}}{dx^{n-1}}e^{(t-\\lambda)x} dx) \\\\\n&= \\frac{\\lambda^n}{(\\lambda - t)^n} \\frac{(-1)^n}{(n-1)!}(-1)^{n-1} (n-1)!(e^{(t-\\lambda)x}\\rvert_0^{\\infty}) \\\\\n&= \\frac{\\lambda^n}{(\\lambda - t)^n} (-1)^{2n-1} (-1) \\\\\n&= \\frac{\\lambda^n}{(\\lambda -t)^n}.\n\\end{align}\n\\]\nThe MGF characterises the distribution of the random variable so the proof is complete."
  },
  {
    "objectID": "FCSC/ch2.html#why-sqrt2-pi",
    "href": "FCSC/ch2.html#why-sqrt2-pi",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.3 Why \\(\\sqrt{2 \\pi}\\)?",
    "text": "2.3 Why \\(\\sqrt{2 \\pi}\\)?\nUsing polar coordinates\n\\[\n\\begin{align}\n\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} e^{-x^2 - y^2} dx dy &= \\int_0^{2 \\pi} \\int_0^{\\infty} r e^{-r^2} dr d\\theta \\\\\n&=  2 \\pi \\int_0^{\\infty} r e^{-r^2} dr \\\\\n&=  2 \\pi \\int_0^{\\infty} \\frac{-1}{2} \\frac{d}{dr}(e^{-r^2}) dr \\\\\n&=  - \\pi e^{-r^2} \\rvert_0^{\\infty} \\\\\n&= \\pi.\n\\end{align}\n\\]\nNow, \\[\n(\\int_{-\\infty}^{\\infty} e^{-x^2} dx)^2 =\n\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} e^{-x^2 - y^2} dx dy = \\pi.\n\\]\nTherefore \\[\n\\int_{-\\infty}^{\\infty} e^{-x^2} dx = \\sqrt{\\pi}.\n\\]\nI think the author may have meant for us to show that\n\\[\n\\int_{-\\infty}^{\\infty} e^{-x^2/2} dx = \\sqrt{2 \\pi}\n\\]\nwhich follows by a change of variables \\(x = y/\\sqrt{2}\\)\n\\[\n\\begin{align}\n\\int_{-\\infty}^{\\infty} e^{-x^2} dx &= \\int_{-\\infty}^{\\infty} e^{-(y/\\sqrt{2})^2} \\frac{1}{\\sqrt{2}} dy \\\\\n&= \\frac{1}{\\sqrt{2}} \\int_{-\\infty}^{\\infty} e^{-y^2/2} dy = \\sqrt{\\pi}.\n\\end{align}\n\\]"
  },
  {
    "objectID": "FCSC/ch2.html#box-muller",
    "href": "FCSC/ch2.html#box-muller",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.4 Box-Muller",
    "text": "2.4 Box-Muller\nLet \\(U_1 \\sim U(0,1)\\) and \\(U_2 \\sim U(0,1)\\). Define random variables\n\\[\nZ_1 = \\sqrt{-2 \\log(U_1)} \\cos(2 \\pi U_2)\n\\] and \\[\nZ_2 = \\sqrt{-2 \\log(U_1)} \\sin(2 \\pi U_2).\n\\]\nShow that \\(Z_1\\) and \\(Z_2\\) are independent standard Gaussians.\nChange to polar coordinates.\nNote that\n\\[\nR = \\sqrt{Z_1^2 + Z_2^2} = \\sqrt{-2 \\log(U_1)}\n\\]\nand\n\\[\n\\tan(\\Theta) = \\frac{Z_2}{Z_1} = \\tan(2 \\pi U_2).\n\\] so \\[\n\\Theta = 2 \\pi U_2\n\\].\nThe random variable \\(R\\) has CDF\n\\[\n\\begin{align}\nF_R(r) &= P(R \\leq r) \\\\\n&= P(\\sqrt{-2 \\log(U_2)} \\leq r) \\\\\n&= P(U_2 \\geq e^{-r^2/2}) \\\\\n&= 1 - P(U_2 < e^{-r^2/2})\n&= 1 - \\begin{cases}\n0 & \\text{if } e^{-r^2/2} <0, \\\\\ne^{-r^2/2} & \\text{for } 0 \\leq e^{-r^2/2} < 1, \\\\\n1 & \\text{if } e^{-r^2/2} \\geq 1\n\\end{cases} \\\\\n&= 1 - e^{-r^2/2}.\n\\end{align}\n\\]\nObviously, \\(\\Theta \\sim U(0, 2 \\pi)\\). Therefore, \\((Z_1, Z_2)\\) has the same distribution as \\((X, Y)\\) where \\(X, Y\\) are IID standard Gaussians."
  },
  {
    "objectID": "FCSC/ch2.html#marginally-gaussian-but-not-jointly-gaussian.",
    "href": "FCSC/ch2.html#marginally-gaussian-but-not-jointly-gaussian.",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.5 Marginally Gaussian but not Jointly Gaussian.",
    "text": "2.5 Marginally Gaussian but not Jointly Gaussian.\nLet \\(X\\) be a standard Gaussian and define\n\\[\nY = \\begin{cases}\nX & \\text{if } |X| \\leq 1, \\\\\n-X & \\text{otherwise.}\n\\end{cases}\n\\]\n\\(Y\\) is also a standard Gaussian.\nProof:\nLet\n\\[\ng(x) = \\begin{cases}\nx & \\text{if } |x| \\leq 1, \\\\\n-x & \\text{otherwise.}\n\\end{cases}\n\\]\nThen the MGF of \\(Y\\) can be expressed (using LOTUS) as\n\\[\n\\begin{align}\n\\sqrt{2 \\pi} \\E(e^{tY}) &= \\sqrt{2 \\pi} \\E(e^{tg(X)}) \\\\\n&= \\int_{-\\infty}^{\\infty} e^{tg(x)} e^{-x^2/2} dx \\\\\n&= \\int_{-1}^{1} e^{t x} e^{-x^2/2} dx + (\\int_{-\\infty}^{-1} + \\int_1^{\\infty}) e^{-t x} e^{-x^2/2} dx \\\\\n&= \\int_{-1}^{1} e^{t x} e^{-x^2/2} dx + (\\int_{\\infty}^{1} + \\int_{-1}^{-\\infty}) - e^{t x} e^{-x^2/2} dx \\\\\n&= \\int_{-1}^{1} e^{t x} e^{-x^2/2} dx + (\\int_{1}^{\\infty} + \\int_{-\\infty}^{-1} e^{t x} e^{-x^2/2} dx \\\\\n&= \\int_{-\\infty}^{\\infty} e^{tx} e^{-x^2/2} dx \\\\\n&= \\sqrt{2 \\pi} \\E(e^{tX}).\n\\end{align}\n\\]\nTherefore, \\(Y\\) and \\(X\\) are identically distributed. They are definitely not independent as \\(Y\\) is a function of \\(X\\) and so we have no right to expect that \\(X + Y\\) is also Gaussian.\nTo see that \\(X +Y\\) is not Gaussian, note that its range is in \\([-2,2]\\); there are lower bounds on Gaussian tails which are non-zero.\n\nX = rg.normal(0,1, N)\nY = [x if np.abs(x) <=1 else -x for x in X]\nplt.hist(X+Y, bins=bins, label='X + Y', alpha=0.5)\nplt.hist(X, bins, label='X', alpha=0.5)\nplt.hist(Y, bins, label='Y', alpha=0.5)\nplt.legend(loc='upper right')\nplt.plot()\n\n[]\n\n\n\n\n\n\ndata=[X+Y, X, Y]\nax = plt.subplot()\nax.violinplot(data, range(len(data)), vert=False)\nax.set_yticks(range(len(data)))\nax.set_yticklabels(['X+Y', 'X', 'Y'])\nplt.plot()\n\n[]"
  },
  {
    "objectID": "FCSC/ch2.html#pdf-of-brownian-bridge",
    "href": "FCSC/ch2.html#pdf-of-brownian-bridge",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.6 PDF of Brownian Bridge",
    "text": "2.6 PDF of Brownian Bridge\nLet \\((M_t, t \\in [0,1])\\) be a Brownian bridge.\n\nwrite down the PDF of \\((M_{1/4}, M_{3/4})\\)\n\nThe covariance matrix is\n\n\nCode\nimport sympy as sp\nfrom sympy.abc import s,t\n\ndef cov(s, t):\n    return sp.Min(s,t) -s * t\n\na, b = sp.Rational(1, 4), sp.Rational(3/4)\n\nC = sp.Matrix([[cov(a, a), cov(a, b)],[cov(b, a), cov(b, b)]]); C\n\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{3}{16} & \\frac{1}{16}\\\\\\frac{1}{16} & \\frac{3}{16}\\end{matrix}\\right]\\)\n\n\nUsing sympy, we can get the PDF easily:\n\n\nCode\nfrom fractions import Fraction\nfrom sympy.abc import x,y\n\nsp.init_printing()\n\n\nCinv = C.inv()\nxy = sp.Matrix([x, y])\n\n\nf = sp.exp(Fraction(-1, 2) * sp.MatMul(xy.transpose(), Cinv, xy))/(2 *sp.pi * sp.sqrt(C.det(), evaluate=False))\npdf = f[0]\npdf\n\n\n\\(\\displaystyle \\frac{2 \\sqrt{2} e^{- 3 x^{2} + 2 x y - 3 y^{2}}}{\\pi}\\)\n\n\n\nwrite down the probability of the event \\({M_{1/4}^2 + M_{3/4}^2 \\leq 1}\\) as a double integral\n\n\n\nCode\nr = sp.symbols('r', nonegative=True)\ntheta = sp.symbols('theta')\n\npdf = pdf.subs({x: r*sp.cos(theta), y: r*sp.sin(theta)}).simplify()\n\nprob = sp.Integral(pdf * r, (r, 0, 1), (theta, 0, 2 *sp.pi)); prob\n\n\n\\(\\displaystyle \\int\\limits_{0}^{2 \\pi}\\int\\limits_{0}^{1} \\frac{2 \\sqrt{2} r e^{r^{2} \\left(\\sin{\\left(2 \\theta \\right)} - 3\\right)}}{\\pi}\\, dr\\, d\\theta\\)\n\n\nThe integral can be calculated numerically using Simpson’s rule or a Monte Carlo simulation:\n\nfrom scipy.integrate import simps\n\ndef evaluate_integral(integrand):\n    r = np.linspace(0, 1, 1000)\n    theta = np.linspace(0, 2* np.pi, 1000)\n\n    zz = integrand(r.reshape(-1, 1), theta.reshape(1, -1))\n    return simps([simps(zz_r, r) for zz_r in zz], theta)\n\ndef monte_carlo(integrand):\n    samples = 1000\n    sum = 0\n    for _ in range(samples):\n        u = np.random.default_rng().uniform(0, 1, 2)\n        r, theta = u[0], 2*np.pi*u[1]\n        sum +=integrand(r, theta)\n    return 2*np.pi * sum/samples\n\nnumerical_soln = evaluate_integral(sp.lambdify([r, theta], pdf *r)); print(numerical_soln)\n\nmonte_carlo(sp.lambdify([r, theta], pdf*r))\n\n0.926901699267537\n\n\n\\(\\displaystyle 0.91125661349625\\)\n\n\nAlternatively, we can approximate the desired probability by using the Cholesky decomposition:\n\ndef simulate(samples):\n    rg = np.random.default_rng()\n    C = [[3/16, 1/16], [1/16, 3/16]]\n    A = np.linalg.cholesky(C)\n    samples = 1000\n    in_disk = 0\n    for _ in range(samples):\n        sample = A.dot(rg.normal(0,1, 2))\n        if sample[0]**2 + sample[1]**2 <= 1:\n            in_disk += 1\n    return in_disk/samples\n    \nsimulated_result = simulate(1000); simulated_result\n\n\\(\\displaystyle 0.924\\)\n\n\nThe two approaches differ by\n\nabs(simulated_result - numerical_soln)\n\n\\(\\displaystyle 0.00290169926753692\\)"
  },
  {
    "objectID": "FCSC/ch2.html#the-covariance-of-a-random-vector-is-always-positive-semidefinite",
    "href": "FCSC/ch2.html#the-covariance-of-a-random-vector-is-always-positive-semidefinite",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.7 The Covariance of a Random Vector is Always Positive Semidefinite",
    "text": "2.7 The Covariance of a Random Vector is Always Positive Semidefinite\nLet \\(\\mathcal{C}\\) be the covariance matrix of a random vector \\(X = (X_i)\\).\nWe must demonstrate that\n\\[\n\\sum_{i,j} a_i a_j \\mathcal{C}_{ij} \\geq 0\n\\tag{2}\\] for any \\(a \\in \\mathbb{R}^n\\).\nDefine \\[\nY = \\sum_{i=1}^n a_i X_i\n\\]\nand calculate the variance of \\(Y\\) showing that it is equal to the left-hand side of (Equation 2):\n\\[\n\\begin{align}\n\\Var(Y) &= \\E(Y^2) - \\E(Y)^2 \\\\\n      &= \\E(\\sum_{i,j=1} a_i a_j X_i X_j ) - \\sum_{i,j=1}^n a_i a_j \\E(X_i)\\E(X_j) \\\\\n      &= \\sum_{i,j=1}^n a_i a_j (\\E(X_i X_j) - \\E(X_i) \\E(X_j)) \\\\\n      &=  \\sum_{i,j=1}^n a_i a_j \\mathcal{C}_{ij}.\n\\end{align}\n\\]\nThe proof is complete by noting that \\(\\Var(Y) \\geq 0\\).\n\n\n\n\n\n\nNote\n\n\n\nThe variance of a random variable is invariant under translation i.e.\nif \\(X\\) is a random variable and \\(c \\in \\mathbb{R}\\), then\n\\[\n\\Var(X + c) = \\Var(X).\n\\] This follows by a simple book-keeping exercise: \\[\n\\begin{align}\n\\Var(X+c) &= \\E(X^2 + 2cX + c^2) - (\\E(X) + c)^2\\\\\n&= \\E(X^2) +2c\\E(x) +c^2 - \\E(X)^2  - 2x \\E(X) - c^2 \\\\\n&= \\E(X^2) - \\E(X)^2 \\\\\n&= \\Var(X).\n\\end{align}\n\\]\nIt is clear that \\(\\Var(X) \\geq 0\\) when \\(X\\) has mean zero:\n\\[\n\\Var(X) = \\E(X^2) = \\int_{-\\infty}^{\\infty} x^2 dF(x) \\geq 0.\n\\]\nIf \\(m\\) is the mean of \\(X\\), then \\(X -m\\) has mean zero and so using invariance of the variance:\n\\[\n\\Var(X) = \\Var(X - m) \\geq 0.\n\\]\n\n\n\n\n\n\n\n\nNote\n\n\n\n\\(X\\) is a constant with probability 1 \\(\\iff \\Var(X) = 0\\).\nProof:\nIf \\(X = c\\), then \\[\n\\Var(X) = \\E(c^2) - \\E(c)^2 = c^2 - c^2 = 0.\n\\]\nIf \\(\\Var(X) = 0\\), then \\(\\Var(X - \\E(X)) = 0\\), by translation invariance of \\(\\Var\\). Let \\(Y = X - \\E(X)\\). Then\n\\[\n\\Var(Y) = \\int_{-\\infty}^{\\infty} y^2 dF_Y(y)\n\\] and so \\[\nF_Y(y) = \\begin{cases}\n0 & \\text{for } y < 0, \\\\\n1 & \\text{otherwise}.\n\\end{cases}\n\\] Therefore, \\(Y = 0\\) with probability 1 and so \\(X = \\E(X)\\) with probability 1 i.e. \\(X\\) is a constant.\n\n\nSince the LHS of (Equation 2) is the variance of \\(\\sum_i a_i X_i\\), we see that \\(\\mathcal{C}\\) is positive definite if and only if the variance of \\(\\sum_i a_i X_i\\) is non-zero for all non-zero \\(a\\).\nThe covariance matrix of a random vector \\(X = (X_i)\\) is positive-definite if and only if each linear combination of the coordinates is non-constant.\nWhen \\(X_i\\) are jointly Gaussian, then each linear combination is a Gaussian random variable: the only constant a linear combination of Gaussian variables can sum to is zero.\nTherefore, for jointly Gaussian random variables, the covariance matrix is positive-definite if and only if the the variables are linearly independent. See Section 2.12."
  },
  {
    "objectID": "FCSC/ch2.html#a-linear-transformation-of-gaussian-vector-is-also-gaussian",
    "href": "FCSC/ch2.html#a-linear-transformation-of-gaussian-vector-is-also-gaussian",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.8 A Linear Transformation of Gaussian Vector is Also Gaussian",
    "text": "2.8 A Linear Transformation of Gaussian Vector is Also Gaussian\nLet \\(X = (X_i)_{i=1}^n\\) be a Gaussian vector an \\(M\\) be an \\(m \\times n\\) matrix.\n\\(Y = MX\\) is also Gaussian.\nProof:\nWe can write\n\\[\n\\begin{align}\nY &= (\\sum_{i=1}^n M_{ij} X_i)_{j=1}^m\n\\end{align}\n\\] and so express \\(Y\\) as a vector of linear combinations of \\(X_i\\) making its components Gaussian. Moreover, we can express any linear combination of components of \\(MX\\) as a linear combination of \\(X_i\\):\n\\[\n\\begin{align}\n\\sum_{j=1}^m a_j Y_j &= \\sum_{j=1}^m a_j (\\sum_{i=1}^n M_{ji} X_i) \\\\\n&= \\sum_{i,j} a_j M_{ji} X_i \\\\\n&= \\sum_{i} b_i X_i\n\\end{align}\n\\] where \\[\nb_i = \\sum_j a_j M_{ji}.\n\\] Written in a more suggestive manner: \\[\na^T MX = (M^T a)^T X.\n\\] \\(\\square\\)\nLet \\(\\mathcal{C}\\) be the covariance matrix of \\(X\\).\nWe can express the covariance matrix of \\(Y\\) in terms of \\(M\\) and \\(\\mathcal{C}\\):\n\\[\n\\begin{align}\n\\Cov(Y_i, Y_j) &= \\E(Y_i Y_j) - \\E(Y_i) \\E(Y_j) \\\\\n&= \\E( \\sum_\\alpha M_{i \\alpha} X_\\alpha \\sum_\\beta M_{j \\beta} X_\\beta ) - \\sum_\\alpha M_{i \\alpha} \\E(Y_i) \\sum_\\beta M_{j \\beta } \\E(Y_j) \\\\\n&= \\sum_\\alpha \\sum_\\beta M_{i\\alpha }M_{j \\beta} (\\E(X_\\alpha X_\\beta) - \\E(X_\\alpha) \\E(X_\\beta)) \\\\\n&= \\sum_\\alpha \\sum_\\beta M_{i \\alpha}\\mathcal{C}_{\\alpha \\beta} M^T_{\\beta j}. \\\\\n\\end{align}\n\\]\nIn shorter notation:\n\\[\n\\Cov(Y) = M \\mathcal{C}M^T.\n\\]\nSuppose that \\(m =n\\). Then,\n\\[\n\\begin{align}\n\\det(\\Cov(Y)) &= \\det(M)\\det(\\mathcal{C})\\det(M^T) \\\\\n&= \\det(M)^2\\det(\\mathcal{C}).\n\\end{align}\n\\] If follows that \\(Y\\) is non-degenerate (\\(\\det(\\Cov(Y)) \\neq 0\\)) \\(\\iff\\) \\(\\det(M) \\neq 0\\).\nFor general \\(M\\), it is necessary that \\(m \\leq n\\) and \\(M\\) is full-rank \\(m\\) for \\(\\Cov(Y)\\) to be positive definite.\n\n\n\n\n\n\nNote\n\n\n\nThe domain of \\(M^T\\) is \\(m\\)-dimensional. The range of \\(M^T\\), \\(\\mathcal{R}(M^T)\\), has dimension \\(\\rank(M^T\\)). Since \\(\\mathcal{C}\\) is invertible, \\(\\mathcal{C}(\\mathcal{R}(M^T))\\) has dimension \\(\\rank(M^T)\\). Finally, \\(\\dim(M(\\mathcal{C}(\\mathcal{R}(M^T)))) = \\rank(M)\\) by virtue of \\(\\rank(M^T) = \\rank(M)\\). That is, \\(\\rank(\\Cov(Y)) = \\rank(M)\\).\nFor \\(\\Cov(Y)\\) to be invertible (making \\(\\Cov(Y)\\) positive definite), we require \\(\\rank(M) = m\\) i.e \\(M\\) must be full-rank. Given that \\(\\rank(M) \\leq \\min(m, n)\\), when \\(M\\) is full-rank \\(m \\leq n\\)."
  },
  {
    "objectID": "FCSC/ch2.html#iid-decomposition",
    "href": "FCSC/ch2.html#iid-decomposition",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.9 IID Decomposition",
    "text": "2.9 IID Decomposition\nLet \\((X, Y)\\) be a Gaussian vector with mean \\(0\\) and covariance matrix \\[\n\\mathcal{C} = \\begin{bmatrix}\n1 & \\rho \\\\\n\\rho & 1\n\\end{bmatrix},\n\\] for \\(\\rho \\in (-1, 1)\\).\nTake \\(Z_1 = X\\). \\(Z_1\\) is a standard Gaussian: it has mean \\(0\\) by assumption and the covariance matrix tells us that \\(\\Var(X_1) = 1\\).\nWe perform Gram-Schmidt to express \\((X, Y)\\) as a linear combination of IID standard Gaussians. Start with \\[\n\\begin{align}\nZ^{'}_2 &= Y - \\E(YZ_1)Z_1 \\\\\n&= Y - \\rho Z_1.\n\\end{align}\n\\]\nBy linearity of expectation, \\[\n\\begin{align}\n\\Var(Z^{'}_2) &= \\E((Y - \\rho Z_1)^2) \\\\\n&= \\E(Y^2) - 2\\rho \\E(Y Z_1) + \\rho^2 \\E(Z_1^2) \\\\\n&= 1 -  \\rho^2.\n\\end{align}\n\\] We set \\[\nZ_2 = \\frac{1}{\\sqrt{1 - \\rho^2}} Z_2^{'}\n\\] and so \\(Z_2\\) has variance 1: \\(Z_1\\) is a standard Gaussian.\n\n\n\n\n\n\n\\(Z_1\\) and \\(Z_2\\) are independent\n\n\n\n\n\nFor Gaussians, it is sufficient to demonstrate that \\[\n\\E(Z_1 Z_2) = 0.\n\\] We expect this from the Gram-Schmidt process but it doesn’t hurt to check:\n\\[\n\\begin{align}\n\\E(Z_1Z_2) & = \\frac{1}{\\sqrt{1 - \\rho^2}}\\E(X(Y - \\rho X)) \\\\\n&= \\frac{\\E(XY) - \\rho\\E(X^2)}{\\sqrt{1 -\\rho^2}} \\\\\n&= 0.\n\\end{align}\n\\]\n\n\n\nWe can write \\[\n(X, Y) = (Z_1, \\rho Z_1 + \\sqrt{1 - \\rho^2} Z_2)\n\\] to express \\((X, Y)\\) as a linear combination of IID standard Gaussians.\nThe PDF of \\((X, Y)\\) is given by\n\n\nCode\nimport sympy as sp\nfrom sympy.abc import x, y, rho\nfrom fractions import Fraction\n\nsp.init_printing()\n\n\nC = sp.Matrix([[1, rho], [rho, 1]])\nCinv = C.inv()\nfactor = sp.gcd(tuple(Cinv))\nxy = sp.Matrix([x, y])\n\n\nf = sp.exp(Fraction(-1, 2) * sp.MatMul(xy.transpose(), Cinv, xy))/(2 *sp.pi * sp.sqrt(C.det())); f[0]\n\n\n\\(\\displaystyle \\frac{e^{\\frac{- 2 \\rho x y + x^{2} + y^{2}}{2 \\left(\\rho - 1\\right) \\left(\\rho + 1\\right)}}}{2 \\pi \\sqrt{1 - \\rho^{2}}}\\)"
  },
  {
    "objectID": "FCSC/ch2.html#iid-decomposition-1",
    "href": "FCSC/ch2.html#iid-decomposition-1",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.10 IID Decomposition",
    "text": "2.10 IID Decomposition\n\nC = sp.Matrix([[2, 1, 1], [1, 2, 1], [1, 1, 2]])\nA = C.cholesky()\nAinv = A.inv()\n\nz1, z2, z3, x1, x2, x3 = sp.symbols('z_1 z_2 z_3 x_1 x_2 x_3')\n\nx = sp.Matrix([x1, x2, x3])\n\n\nz = sp.MatMul(Ainv, x, evaluate=True); z\n\n\\(\\displaystyle \\left[\\begin{matrix}\\frac{\\sqrt{2} x_{1}}{2}\\\\- \\frac{\\sqrt{6} x_{1}}{6} + \\frac{\\sqrt{6} x_{2}}{3}\\\\- \\frac{\\sqrt{3} x_{1}}{6} - \\frac{\\sqrt{3} x_{2}}{6} + \\frac{\\sqrt{3} x_{3}}{2}\\end{matrix}\\right]\\)"
  },
  {
    "objectID": "FCSC/ch2.html#iid-decomposition-2",
    "href": "FCSC/ch2.html#iid-decomposition-2",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.11 IID Decomposition",
    "text": "2.11 IID Decomposition\n\\[\n\\mathcal{C}= \\begin{bmatrix}\n3 & 1 & 1 \\\\\n1 & 3 & -1 \\\\\n1 & -1 & 3\n\\end{bmatrix}\n\\]\n\\(\\det{\\mathcal{C}}\\) is\n\n\nCode\nC = [[3, 1, 1], [1,3,-1], [1, -1, 3]]\nnp.linalg.det(C)\n\n\n\\(\\displaystyle 16.0\\)\n\n\nand so \\(X\\) is non-degenerate.\n\nclass Sim211:\n    C = [[3, 1, 1], [1,3,-1], [1, -1, 3]]\n    def __init__(self):\n        self.__A = np.linalg.cholesky(C)\n        return\n\n    def path(self, rg = np.random.default_rng()):\n        return self.__A.dot(rg.normal(0, 1, len(C[0])))\n        \nsim = Sim211()\n\nfor _ in range(100):\n    plt.plot(range(1, 4), sim.path())\nplt.show()"
  },
  {
    "objectID": "FCSC/ch2.html#sec-degenerate-is-li",
    "href": "FCSC/ch2.html#sec-degenerate-is-li",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.12 Degenerate Means Linearly Independent",
    "text": "2.12 Degenerate Means Linearly Independent\nLet \\(X = (X_i)_{i=1}^n\\) be a Gaussian vector with covariance \\(\\mathcal{C}\\).\n\\(\\det{\\mathcal{C}} = 0 \\iff\\) there exists \\(c \\in \\mathbb{R}^n\\setminus{0}\\) such that\n\\[\n\\sum_i c_i X_i = 0.\n\\]\nProof:\nBy definition, \\(X\\) is a degenerate Gaussian vector iff \\(\\det{\\mathcal{C}} = 0\\). Since \\(\\mathcal{C}\\) is symmetric semi-positive definite, \\(\\det{\\mathcal{C}} = 0\\) iff there exists \\(c \\in \\mathbb{R}^n\\setminus{0}\\) such that\n\\[\nc^T \\mathcal{C} c = 0.\n\\]\nThis can be written as a statement about the variance of a Gaussian random variable:\n\\[\nc^T \\mathcal{C} c = \\Var(\\sum_i c_i X_i) = 0.\n\\]\nA random variable with variance 0 is a constant; the only constant a Gaussian variable can equal is 0.\nTherefore,\n\\[\nc^T C c = 0 \\iff \\sum_i c_i X_i = 0.\n\\] \\(\\square\\)\nThe textbook hints that we should use \\(\\mathcal{C} = AA^T\\) but I think this needs some care to avoid circularity if we’re using this to fill in proofs in the text. Obviously, we can’t use results where the existence of \\(A\\) is predicated on \\(X\\) being non-degenerate!\nThe approach I take here is to prove the equivalent theorem\n\\(\\det{\\mathcal{C}} \\neq 0 \\iff X_i\\) are linearly independent.\nProof:\nSuppose that \\(X\\) has mean zero without loss of generality.\nSuppose \\((X_i)\\) are linearly independent and so form an \\(n\\)-dimensional vector space \\(V\\) with addition being the usual addition of random variables. The vector space is equipped with the inner product \\(\\E: V \\times V \\mapsto \\mathbb{R}\\). This allows us to can use the Gram-Schmidt process to create \\(n\\) IID (orthogonal wrt \\(\\E\\)) Gaussian standard vectors \\((Z_i)\\) with mean zero. The space \\(V\\) is spanned by both \\((X_i)\\) and \\((Z_i)\\) and so they are related by an invertible change of coordinates \\(A\\) such that \\(X = AZ\\). In addition,\n\\[\n\\mathcal{C} = AA^T\n\\]\nsince\n\\[\n\\mathcal{C}_{ij} = \\E(X_i Xj) = \\E(\\sum_m A_{im} Z_m \\sum_n A_{jn} Z_n) = (AA^T)_{ij}.\n\\]\nSince \\(A\\) is invertible, \\(\\det(A) = \\det(A^T) \\neq 0\\) and so\n\\[\n\\det(\\mathcal{C} ) = \\det(A)^2  > 0.\n\\]\nNow, suppose that \\(\\det{C} \\neq 0\\). Then \\(X\\) is non-degenerate and so there exists an invertible matrix \\(A\\) and \\(n\\) IID standard Gaussian random variables such that \\(X=AZ\\). The variables \\(Z_i\\) are linearly independent and we can leverage this and the invertibility of \\(A^T\\):\n\\[\n\\sum_i c_i X_i = \\sum_i c_i A^T Z_i = A^T (\\sum_i c_i Z_i)\n\\] and so \\(\\sum_i c_i X_i = 0\\) iff \\(\\sum_i c_i Z_i = 0\\) which would be a contradiction if the \\(c_i\\) are not all zero.\nWe have shown that\n\\(\\det{\\mathcal{C}} \\neq 0 \\iff X_i\\) are linearly independent.\nEquivalently, \\[\n\\det{\\mathcal{C}} = 0 \\iff \\exists c \\in \\mathbb{R}^n\\setminus{0} \\text{ such that } \\sum_i c_i X_i = 0.\n\\]\n\\(\\square\\)"
  },
  {
    "objectID": "FCSC/ch2.html#iid-decomposition-for-degenerate-vectors",
    "href": "FCSC/ch2.html#iid-decomposition-for-degenerate-vectors",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.13 IID Decomposition For Degenerate Vectors",
    "text": "2.13 IID Decomposition For Degenerate Vectors\nLet \\(X = (X_i)_{i=1}^{n}\\) be a degenerate Gaussian vector with mean zero.\n\n\n\n\n\n\nWarning\n\n\n\nThe question does not state that the mean of \\(X\\) is zero: this appear to be an error.\n\n\nThe Gaussian variables \\(X_i\\) form a finite-dimensional vector space \\(V\\) under addition of random variables and multiplication by reals. The dimension of \\(V\\) is less than \\(n\\), because the \\(X_i\\) are linearly dependent.\nThe expectation operator is an inner-product on \\(V\\) and we can use this inner-product to to form a basis \\(Z = (Z_i)_{i=1}^m\\) \\(m < n\\) for \\(V\\) of IID standard Gaussian variables. Each \\(X_i\\) can be written in exactly one way as a linear combination of \\(Z\\):\n\\[\nX_i = \\sum_{j=1}^m a_{ij} Z_j.\n\\] That is, there is an \\(m \\times n\\) matrix \\(A\\) such that \\[\nX = A Z.\n\\]\nThe elements of the covariance matrix of \\(X\\) can be expressed in terms of \\(A\\):\n\\[\n\\begin{align}\n\\mathcal{C}_{ij} &= \\E(X_i X_j) \\\\\n&= \\E(\\sum_\\alpha a_{i\\alpha} Z_\\alpha \\sum_\\beta a_{j \\beta} Z_\\beta) \\\\\n&= \\sum_{\\alpha, \\beta} a_{i\\alpha}a_{j\\beta} \\E(Z_\\alpha Z_\\beta) \\\\\n&= \\sum_\\alpha a_{i \\alpha} a_{j \\alpha} \\\\\n&= (A A^T)_{ij}.\n\\end{align}\n\\]"
  },
  {
    "objectID": "FCSC/ch2.html#brownian-bridge-from-brownian-motion",
    "href": "FCSC/ch2.html#brownian-bridge-from-brownian-motion",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.14 Brownian Bridge From Brownian Motion",
    "text": "2.14 Brownian Bridge From Brownian Motion\nLet \\((B_t, t \\in [0, 1])\\) be a Brownian motion.\n\nShow that the process given by \\((M_t = B_t - t B_1, t \\in [0, 1])\\) is a Brownian bridge.\n\nStep 1: show that \\(M_t\\) is a Gaussian process.\nChoose \\(0 = t_1 < t_2 < ... t_n =1\\). The process \\((M_{t_i})\\) is a linear transformation of \\((B_{t_i})\\):\n\\[\nA_{ij} = \\delta_{ij} - t \\delta_{nj}\n\\]\ne.g for a process with three time points\n\\[\nA = \\begin{bmatrix}\n1 & 0 & -t \\\\\n0 & 1 & -t \\\\\n0 & 0 & 1-t\n\\end{bmatrix}.\n\\]\nStep 2: Show that the mean of \\((M_t)\\) is equal to zero\n\\[\n\\E(M_t) = \\E(B_t - t B_1) = \\E(B_t) - t\\E(B_1) = 0.\n\\]\nStep 3: Show that the \\(\\Cov(M_t, M_s) = \\min(s,t) - st\\).\n\\[\n\\begin{align}\n\\Cov(M_t, M_s) &= \\Cov(B_t -t B_1, B_s - t B_1) \\\\\n&= \\E(B_t B_s - t B_t B_1 -t B_s B_1 + t^2 B_1^2) \\\\\n&= \\E(B_t B_s) -t \\E(B_t B_1) -t \\E(B_s B_1) + t^2 \\E(B_1^2) \\\\\n&= \\min(s, t) - st.\n\\end{align}\n\\]\n\nShow that the random variable \\(B_t - t B_1\\) is independent of of \\(B_1\\) for any \\(t \\in [0, 1]\\).\n\nConsider the covariance:\n\\[\n\\begin{align}\n\\Cov(B_t - t B_1, B_1) &= \\E(B_tB_1 -t B_1 B_1) \\\\\n&= \\E(B_tB_1) -t \\E(B_1^2) \\\\\n&= t - t \\\\\n&= 0.\n\\end{align}\n\\]\nSince \\(B_t -t B_1\\) and \\(B_1\\) are Gaussian variables, this is enough to establish independence."
  },
  {
    "objectID": "FCSC/ch2.html#triangle-inequality",
    "href": "FCSC/ch2.html#triangle-inequality",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.15 Triangle Inequality",
    "text": "2.15 Triangle Inequality\nLet \\(X, Y\\) be two random variables in \\(L^2(\\Sigma, \\mathcal{F}, \\P)\\). Prove the triangle inequality\n\\[\n\\sqrt{\\E((X+Y)^2)} \\leq \\sqrt{\\E(X^2) + \\E(Y^2)}.\n\\]\nExpand the square and use Cauchy-Schwarz:\n\\[\n\\begin{align}\n\\E((X+Y)^2) &= \\E(X^2 + 2 X Y + Y^2) \\\\\n&= \\E(X^2) + 2 \\E(XY) + \\E(Y^2) \\\\\n&\\leq \\E(X^2) + 2 \\sqrt{\\E(X^2) \\E(Y^2)} + \\E(Y^2) \\\\\n&= (\\sqrt{\\E(X^2)} + \\sqrt{\\E(Y^2)})^2.\n\\end{align}\n\\]\nLet \\(S_k = \\sum_{i=1}^k X_i\\). Suppose that the triangle inequality holds for \\(S_k\\):\n\\[\n\\sqrt{\\E(S_k^2)} \\leq \\sum_{i=1}^k\\sqrt{\\E(X_i^2)}.\n\\]\nConsider the next case \\(S_{k+1}\\):\n\\[\n\\sqrt{\\E(S_{k+1}^2)}  = \\sqrt{\\E((X_{k+1} + S_k)^2)} \\leq \\sqrt{\\E(X_{k+1}^2)} + \\sqrt{\\E(S_k^2)} = \\sum_{i=1}^{k+1}\\sqrt{\\E(X_k^2)}\n\\] using the two-term triangle inequality. The result follows by induction since the triangle inequality holds for \\(k=2\\)."
  },
  {
    "objectID": "FCSC/ch2.html#the-space-of-integrable-random-variables-is-l1",
    "href": "FCSC/ch2.html#the-space-of-integrable-random-variables-is-l1",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.16 The Space of Integrable Random Variables is \\(L^1\\)",
    "text": "2.16 The Space of Integrable Random Variables is \\(L^1\\)\n\\(L^1(\\Omega, \\mathcal{F}, \\P)\\) is a linear space.\nProof:\nIf \\(X, Y \\in L^1\\) and \\(a, b \\in \\mathbb{R}\\), then\n\\[\naX + bY\n\\]\nis a random variable on the probability space and by the triangle inequality\n\\[\n|aX + bY| \\leq |a| |X| + |b| |Y|.\n\\] The right-hand side is integrable so |aX + BY| is integrable. Therefore, \\(aX + bY \\in L^1\\). The zero vector of \\(L^1\\) is a random variable on the probability space which is zero with probability one.\n\\(\\square\\)\n\\(\\| X \\|_1 \\triangleq \\E(|X|)\\) is a norm for \\(L^1\\).\nProof:\nTo verify that \\(\\| \\cdot \\|_1\\) is a norm for \\(L^1\\) we must verify that\n\n\\(\\| X + Y \\|_1 \\leq \\| X\\|_1 + \\|Y \\|_1\\) for \\(X,Y \\in L^1\\)\nFor all scalars \\(a\\) and \\(X \\in L^1\\), \\(\\| a X\\|_1 = |a| \\| X \\|_1\\)\nFor all \\(X \\in L^1\\), if \\(\\| X\\|_1 = 0\\), then \\(X=0\\).\n\n\nBy the triangle inequality for the reals,\n\n\\[\n| X + Y| \\leq |X| + |Y|\n\\] with probability one for \\(X, Y \\in L^1\\) and so\n\\[\n\\| X + Y \\|_1 = \\E(|X + Y|) \\leq \\E(|X|) + \\E(|Y|) = \\|X\\|_1 + \\|Y\\|_1.\n\\]\n\n\n\nFor scalar \\(a\\) and \\(X \\in L^1\\),\n\\[\n\\| a X \\|_1 = \\E(|a X|) = |a| \\E(|X|) = |a| \\| X \\|_1.\n\\]\n\n\n\nIt is clear that if \\(X = 0\\), then \\(\\|X\\|_1 = 0\\).\nIf \\(X \\in L^1\\) and \\(\\| X \\|_1 = 0\\), then\n\\[\n\\E(|X|) =0.\n\\]\nBy Markov’s inequality\n\\[\n\\P(|X| > x) \\leq \\frac{1}{x} \\E(|X|) = 0\n\\] for \\(x > 0\\) i.e.\n\\[\nP(|X| > x) = 0\n\\] for \\(x> 0\\). It follows that \\(P(|X| \\leq 1/n) = 1\\) for all \\(n=1, 2, \\ldots\\).\nTherefore, we can create a decreasing, nested sequence of events \\(A_n = \\{\\omega \\in \\Omega : \\left |X(\\omega)\\right| \\leq 1/n\\}\\) and by continuity of probability \\[\n\\P(X = 0) = \\lim_{n\\to\\infty} P(X \\leq 1/n) =  1.\n\\]\nTherefore, \\(X = 0\\)."
  },
  {
    "objectID": "FCSC/ch2.html#wicks-formula",
    "href": "FCSC/ch2.html#wicks-formula",
    "title": "A First Course in Stochastic Calculus",
    "section": "2.17 Wick’s Formula",
    "text": "2.17 Wick’s Formula\n\nLet \\(Z=(Z_i)_{i=1}^n\\) be IID standard Gaussians and let \\(G: \\mathbb{R}^n \\mapsto \\mathbb{R}\\) be a smooth function for which \\(\\E(G(Z))\\) and \\(\\E(\\partial_i G(Z))\\) are well-defined for every \\(i \\leq n\\). Prove that\n\n\\[\n\\E(Z_i G(Z)) = \\E(\\partial_iG(Z)).\n\\]\nProof:\nBy integration by parts for the one-dimensional Gaussian and the law of total expectation\n\\[\n\\begin{align}\n\\E(\\E(\\partial_iG(Z)|\\cap_{j\\neq i} Z_j)) &= \\E(\\E(Z_i G(Z)|\\cap_{j \\neq i} Z_j)) \\\\\n&= E(Z_i G(Z)).\n\\end{align}\n\\]\n\nLet \\(X\\) be a non-degenerate Gaussian vector of mean zero, and let \\(F: \\mathbb{R}^n \\mapsto \\mathbb{R}\\) be a smooth function for which \\(\\E(F(X))\\) and \\(\\E(\\partial_iF(X))\\) are well-defined for every \\(i \\leq n\\). Prove that\n\n\\[\n\\E(X_i F(X)) = \\sum_{j \\leq n} \\E(X_i X_j) \\E(\\partial_iF(X))\n\\] for \\(i \\leq n\\).\n\n\n\n\n\n\nWarning\n\n\n\nTypo in the question.\nLHS should read \\(\\E(X_i F(X))\\) instead of \\(\\E(X_i F(Z))\\).\n\n\nProof:\nLet \\(A\\) be the Cholesky decomposition of the covariance matrix of \\(X\\). Then\n\\[\nX = AZ\n\\]\nwhere \\(Z=(Z_i)\\) are IID standard Gaussian variables with mean zero.\nDefine \\(G(Z) = F(AZ)\\). Then\n\\[\n\\begin{align}\n\\E(Z_i G(Z)) &= \\E(\\partial_i G(Z)) \\\\\n&= \\E(\\partial_i F(AZ)) \\\\\n&= \\E(\\sum_j \\partial_j F(X) A_{ji}) \\\\\n&= \\sum_j A_{ji} E(\\partial_j F(X)) \\\\.\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nDefine \\(a(x) = Ax\\). Then by the chain rule \\[\n\\begin{align}\n\\partial_i(F(a_1(x), \\ldots, a_n(x))) &= \\sum_j \\frac{\\partial F}{\\partial a_j}\\frac{\\partial a_j}{\\partial x_i} \\\\\n&= \\sum_j \\partial_j F(a_1(x), \\ldots, a_n(x)) A_{ji}.\n\\end{align}\n\\]\n\n\n\n\\[\n\\begin{align}\n\\E(X_i F(X)) &= \\E(\\sum_k A_{ik} Z_k G(Z)) \\\\\n&= \\sum_k A_{ik} \\E(\\partial_k G(Z)) \\\\\n&= \\sum_k A_{ik} \\sum_j \\E(\\partial_j F(X) A_{kj}) \\\\\n&= \\sum_j \\sum_k A_{ik} A_{kj} \\E(\\partial_j F(X) ) \\\\\n&= \\sum_j  (AA^T)_{ij} \\E(\\partial_j F(X)) \\\\\n&= \\sum_j  \\E(X_i X_j) \\E(\\partial_j F(X)).\n\\end{align}\n\\]\n\nFor any \\(m\\)-tuple \\((i_1, \\ldots , i_m)\\) where \\(i_k \\leq n\\) we have the \\(E(X_{i_1}\\ldots X_{i_m}) = 0\\) if \\(m\\) is odd, and if \\(m\\) is even,\n\n\\[\n\\E(X_{i_1} \\ldots X_{i_m}) = \\sum_{p \\in P_m^2} \\prod_{p = (p_1, p_2)} \\E(X_{p_1} X_{p_2})\n\\]\nwhere \\(P_m^2\\) is the set of all pairing of elements of the \\(m\\)-tuple.\nProof:\nFor \\(m=2\\), the result is trivial.\nSuppose true for \\(m\\) even. Define \\(F(X) = X_{i_1} \\ldots X_{i_m} X_{i_{m+1}}\\)\nThen\n\\[\n\\begin{align}\n\\E(X_{i_1} \\ldots X_{i_{m+2}}) &= \\E(F(X) X_{i_{m+2}}) \\\\\n&= \\sum_{j \\leq m+1} \\E(X_{i_{m+2}} X_j) \\sum_{p\\in P_m} \\prod_{p=(p_1, p2)} E(X_{p_1}X_{p_2}) \\\\\n&= \\sum_{p \\in P_{m+2}^2} \\prod_{p = (p_1, p_2)} \\E(X_{p_1} X_{p_2}).\n\\end{align}\n\\] By induction, the theorem is true for even \\(m\\).\nFor \\(m\\) odd, the base case is \\(m=3\\). Define \\(F(X) = X_{i_2} X_{i_3}\\).\nThen \\[\n\\begin{align}\n\\E(X_{i_1} X_{i_2} X_{i_3}) &= \\E(X_{i_1} X_{i_2})\\E(X_{i_3}) + \\E(X_{i_1} X_{i_3}) \\E(X_{i_4}) \\\\\n&= 0.\n\\end{align}\n\\]\nSuppose that the theorem is true for odd \\(m\\). Then for \\(m+2\\), define \\(F(X) = X_{i_1}\\ldots X_{i_{m+1}}\\).\n\\[\n\\begin{align}\n\\E(X_{i_1} \\ldots X_{i_{m+2}}) &= \\E(F(X) X_{i_{m+2}}) \\\\\n&= \\sum_{j \\leq m+2} \\E(X_{i_{m+2}}X_j) \\E(\\partial_j F(X)) \\\\\n&= 0\n\\end{align}\n\\]\nsince \\(\\partial_j F(X)\\) is the product of an odd number of elements of \\(X\\).\nAnother approach to proving the odd case is to appeal to symmetry:\nfor any \\(i\\), the distribution of \\(-X_i\\) is the same as that of \\(X_i\\). Moreover, any product \\(X_{i_1} \\ldots X_{i_n}\\) will have the same distribution as \\((-1)^n X_{i_1} \\ldots X_{i_n}\\). Therefore,\n\\[\n\\E (X_{i_1} \\ldots X_{i_n}) = (-1)^n\\E(X_{i_1} \\ldots X_{i_n}).\n\\] When \\(n\\) is odd, \\[\n\\E (X_{i_1} \\ldots X_{i_n}) = -\\E(X_{i_1} \\ldots X_{i_n}) = 0.\n\\]\n\\(\\square\\)\n```"
  },
  {
    "objectID": "FCSC/ch1.html",
    "href": "FCSC/ch1.html",
    "title": "A First Course in Stochastic Calculus",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# (a)\nN = 10000\nsamples = np.random.default_rng().uniform(0, 1, N)\n\n# (b)\n\nbins = 50\nplt.hist(samples, bins, label='Unform')\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\nUniform Distribution\n\n\n\n\n\n# (c)\nplt.hist(samples, bins, cumulative=True, label='CDF X ~ U(0,1)')\nplt.legend(loc='upper left')\nplt.show()\n\n\n\n\n\n# Redo (b) and (c) for X^2\n\nsamples_squared = [ x**2 for x in samples]\n\n\nplt.hist(samples_squared, bins, label='PDF X^2')\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\nplt.hist(samples_squared, bins, cumulative=True, label='CDF X^2')\nplt.legend(loc='upper left')\nplt.show()\n\n\n\n\n\n\n\n\n# (a)\nN = 10000\nsamples = np.random.default_rng().exponential(1, N)\naverages = [sample/(idx +1) for idx, sample in enumerate(np.cumsum(samples))]\n\nbins = np.linspace(0, 2, 100)\nplt.hist(averages, bins)\nplt.show()\n\n\n\n\n\nplt.plot(averages)\nplt.ylabel('average of N samples')\nplt.xlabel('N')\nplt.show()\n\n\n\n\n\n# (b)\n\ndef average(n):\n    return np.sum(np.random.default_rng().exponential(1, n))/n\n\nbins = np.linspace(-0, 2, 100)\nplt.hist([average(100) for _ in range(0, 10000)], bins, label='average(100)', alpha=0.5)\nplt.hist([average(10000) for _ in range(0, 10000)], bins, label='average(10000)', alpha=0.5)\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\nNote how the averages of 10000 samples have less variance than the averages of 100 samples.\n\n\n\n\ndef Y(N):\n    sum = np.sum(np.random.default_rng().exponential(1, N))\n    return (sum - N) /np.sqrt(N)\n\nsamples = 10000\n\nbins = np.linspace(-3, 3, 50)\n\n\nplt.hist([ Y(100) for _ in range(0, samples)], bins, label='Y(100)', alpha=0.5)\nplt.hist(np.random.default_rng().normal(0, 1, samples), bins, label='N(0,1)', alpha=0.5)\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\ndef invF(y):\n    return np.tan((y - 0.5)*np.pi)\n\nN = 10000\nsamples = [ invF(u) for u in np.random.default_rng().uniform(0, 1, N) ]\n\n\nbins = np.linspace(-10, 10, 100)\nplt.hist(samples, bins, alpha=0.5, label='Cauchy')\nplt.hist(np.random.default_rng().normal(0, 1, N), bins, alpha=0.5, label='normal')\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\nfor i in range(0,4):\n    samples = [ invF(u) for u in np.random.default_rng().uniform(0, 1, N) ]\n    plt.plot([ s/(idx + 1) for idx, s in enumerate(np.cumsum(samples)) ], label=f'average {i}')\n\nplt.legend(loc='upper right')\nplt.xlabel('N')\nplt.show()\n\n\n\n\n\ndef cauchy_empirical_mean(N):\n    return np.sum([ invF(u) for u in np.random.default_rng().uniform(0, 1, N) ])/N\n\n\nbins = np.linspace(-40, 40, 1000)\nplt.hist([cauchy_empirical_mean(10) for _ in range(0, 10000)], bins, label='N=10', alpha=0.5)\nplt.hist([cauchy_empirical_mean(100) for _ in range(0, 10000)], bins, label='N=100', alpha=0.5)\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\nNote how the emperical means with 10 samples and 100 samples appear to be identically distributed. The Cauchy distribution has no defined mean (even though it is symmetrical about 0) so the Central Limit Theorem does not apply.\nIf we have two iid variables \\(X\\) and \\(Y\\) with Cauchy distribution i.e. with pdf\n\\[\nf(x) = \\frac{1}{\\pi} \\frac{1}{1 + x^2} dx.\n\\]\nWe can get the distribution of \\(\\frac{1}{2}(X + Y)\\) by considering the characteristic function of the distribution, \\(e^{-|t|}\\).\nThe characteristic function of \\(\\frac{1}{2}(X + Y)\\) is\n\\[\nE(e^{it(X + Y)/2}) = E(e^{itX/2}) E(e^{itY/2}) = e^{-2|t/2|} = e^{-|t|}.\n\\]\nThis tells us that \\(\\frac{1}{2}(X + Y)\\) has the same distribution as \\(X\\) and \\(Y\\). So, when we calculate empirical means of Cauchy distribution independent variables, the result does not converge to a constant plus a narrow Gaussian error: instead, we get a random variable with the same distribution the samples, regardless of how many samples we take!"
  },
  {
    "objectID": "FCSC/ch1.html#section",
    "href": "FCSC/ch1.html#section",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.1",
    "text": "1.1\nProve proposition 1.3.\n\nFinite additivity: if two events \\(A\\) and \\(B\\) are disjoint, then \\(P(A \\cup B) = P(A) + P(B)\\)\n\nThis follows from Definition 2.3 (3) with \\(A = A_1\\), \\(B = A_2\\) and \\(A_i = \\emptyset\\) for \\(i > 2\\):\n\\[\n\\begin{align}\nP(A \\cup B) &= P (\\cup_{i} A_i) = P(A_1) + P(A_2) + \\cup_{i > 2} P(A_i) \\\\\n            &= P(A) + P(B) + \\cup_{i > 2} P(\\emptyset) \\\\\n            &= P(A) + P(B).\n\\end{align}\n\\]\n\nFor any event \\(A\\), \\(P(A^c) = 1 - P(A)\\):\n\n\\(\\Omega\\) is the disjoint union of \\(A\\) and \\(A^c\\). By (1) above \\[\n1 = P(\\Omega) = P(A \\cup A^c) = P(A) + P(A^c)\n\\] so \\[\nP(A) = 1 - P(A^c).\n\\]\n\nFor any events \\(A\\), \\(B\\), \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\):\n\nExpress \\(A \\cup B = (A\\setminus B) \\cup B\\) where the union is disjoint. Using (1)\n\\[\nP(A \\cup B) = P(A\\setminus B) + P(B).\n\\] Now, \\[\nP(A\\setminus B) + P(A\\cap B) = P(A)\n\\] and so \\[\nP(A\\setminus B) = P(A) - P(A\\cap B).\n\\]\nIt follows that\n\\[\nP(A \\cup B) = P(A \\setminus B) + P(B) = P(A) + P(B) - P(A \\cap B).\n\\]\n\nMonotonicity: If \\(A \\subseteq B\\), then \\(P(A) \\leq P(B)\\).\n\nIf \\(A \\subseteq B\\), then \\(B = A \\cup (B \\setminus A)\\) where the union is disjoint. It follows that\n\\[\nP(B) = P(A) + P(B \\setminus A) \\geq P(A).\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#equiprobability",
    "href": "FCSC/ch1.html#equiprobability",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.2 Equiprobability",
    "text": "1.2 Equiprobability\nLet \\(\\Omega\\) be a sample space with a finite number of outcomes. We define\n\\[\nP(A) = \\#A/\\#\\Omega\n\\] for \\(A \\subseteq \\Omega\\).\n\\(P\\) is a probability on \\(\\Omega\\).\nProof:\n\nSince counts are positive, \\(P >= 0\\). Since \\(\\#A \\leq \\#\\Omega\\), \\(P \\leq 1\\) and so \\(P(A) \\in [0, 1]\\) for \\(A \\subseteq \\Omega\\).\nThe empty set \\(\\emptyset\\) has no elements, so \\(P(\\emptyset) = 0\\). It is easy to see that \\[\nP(\\Omega) = \\frac{\\# \\Omega}{ \\# \\Omega} =1.\n\\]\nAdditivity: for any infinite, mutually disjoint sequence of events \\(A_1, A_2, \\ldots\\) there exists \\(N\\) such that \\(A_n = \\emptyset\\) for all \\(n \\geq N\\). In fact, \\(N\\) must be less than \\(\\# \\Omega\\).\n\nThen\n\\[\n\\begin{align}\nP(\\cup_{i=1}^{\\infty} A_n) &= P(\\cup_{i=1}^{N} A_n)\\\\\n&= \\frac{\\sum_{i=1}^N \\# A_n}{\\# \\Omega} \\\\\n&= \\sum_{i=1}^N P(A_n) \\\\\n&= \\sum_{i=1}^{\\infty} P(A_n).\n\\end{align}\n\\]."
  },
  {
    "objectID": "FCSC/ch1.html#distribution-as-a-probability-on-mathbbr",
    "href": "FCSC/ch1.html#distribution-as-a-probability-on-mathbbr",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.3 Distribution as a Probability on \\(\\mathbb{R}\\)",
    "text": "1.3 Distribution as a Probability on \\(\\mathbb{R}\\)\nLet \\(\\rho_X\\) be the distribution of random variables \\(X\\) on some probability space \\((\\Omega, \\mathcal{F}, P)\\). \\(\\rho_X\\) has the properties of a probability on \\(\\mathbb{R}\\).\nProof:\nLet \\(\\mathcal{F}_X\\) be the \\(\\sigma\\)-field of set in \\(\\mathbb{R}\\) such that \\(A \\in \\mathcal{F} \\iff \\{\\omega \\in \\Omega: X(\\omega) \\in A\\} \\in \\mathcal{F}\\).\nWe define \\(P_X\\) on \\(\\mathcal{F}_X\\) by\n\\[\nP_X(A) = P(\\{\\omega \\in \\Omega: X(\\omega) \\in A\\}).\n\\]\nWe note that \\(P_X\\) extends \\(\\rho_X\\).\nFor notational simplicity, we write\n\\[\nX^{-1}(A) = \\{\\omega \\in \\Omega: X(\\omega) \\in A\\}.\n\\]\nClearly, for any \\(A \\in \\mathcal{F}_X\\), \\(P_X(A) = P(X^{-1}(A)) \\in [0,1]\\), so satisfies (1) of Definition 1.2.\nThe pre-image of \\(\\emptyset\\), \\(X^{-1}(\\emptyset)\\) must be itself empty. Therefore,\n\\[\nP_X(\\emptyset) = P(\\emptyset) = 0.\n\\]\nSimilarly, the pre-image of \\(\\mathbb{R}\\) must be all of \\(\\Omega\\) and so\n\\[\nP_X(\\mathbb{R}) = P(\\Omega) = 1.\n\\]\nThis shows that \\(P_X\\) satisfies (2) of Definition 2.1.\nLet \\(A_1, A_2, \\ldots\\) be an infinite sequence of events in \\(\\mathcal{F}_X\\) that are mutually disjoint. Note that the sequence of pre-images \\(X^{-1}(A_1), X^{-1}(A_2), \\ldots\\) are also mutually disjoint. Since \\(P\\) is a probability we can use its additivity to prove the additivity of \\(P_X\\):\n\\[\nP_X(\\cup_{i=1}^{\\infty} A_i) = P(\\cup_{i=1}^{\\infty} X^{-1}(A_i)) = \\sum_{i=1}^{\\infty} P(X^{-1}(A_i)) = \\sum_{i=1}^{\\infty} P_X(A_i).\n\\]\nThis shows that \\(P_X\\) satisfies (3) of Definition 2.1."
  },
  {
    "objectID": "FCSC/ch1.html#distribution-of-an-indicator-function",
    "href": "FCSC/ch1.html#distribution-of-an-indicator-function",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.4 Distribution of an Indicator Function",
    "text": "1.4 Distribution of an Indicator Function\nLet \\((\\Omega, \\mathcal{F}, P)\\) and \\(A \\in \\mathcal{F}\\) with \\(0 < P(A) < 1\\). What is the distribution of \\(1_A\\)?\nObserve that \\(P(1_A \\leq x) = 0\\) when \\(x < 0\\) because the indicator is a non-negative function. When \\(0 \\leq x < 1\\), \\(1_A(\\omega) > x\\) for all \\(\\omega \\in A\\) but \\(1_A(\\omega) = 0 <= x\\) for \\(\\omega \\in A^c\\). It follows that \\[P(1_A \\leq x) = P(\\{\\omega \\in \\Omega : 1_A(\\omega) \\leq x\\}) =P(\\{\\omega \\in \\Omega : \\omega \\in A^c\\}) = P(A^c).\\] For \\(x \\geq 1\\), \\(1_A \\leq x\\) is true for all values of \\(\\omega \\in \\Omega\\) because the maximum value of the indicator function is \\(1\\). Therefore, with \\(F\\) denoting the CDF of \\(1_A\\): \\[\nF(x) = P(1_A \\leq x) = \\begin{cases}\n0 & \\text{if } x < 0,\\\\\nP(A^c) & \\text{if } 0 \\leq x < 1,\\\\\n1 & \\text{if } x \\geq 1.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#events-of-probability-one",
    "href": "FCSC/ch1.html#events-of-probability-one",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.5 Events of Probability One",
    "text": "1.5 Events of Probability One\nLet \\((\\Omega, \\mathcal{F}, P)\\) be a probability space and \\(A_1, A_2, \\ldots\\) be a sequence of events in \\(\\mathcal{F}\\) such that \\(P(A_n) = 1\\) for all \\(n \\geq 1\\). We show that\n\\[\nP(\\cap_{i\\geq 1} A_n) = 1.\n\\]\nDefine \\(B_n = A_n^c\\) for all \\(n \\geq 1\\). We note that\n\\[\nP(B_n) = 1 - P(A_n) = 0\n\\] for all \\(n \\geq 0\\).\nDefine a sequence of events \\(C_n = \\cup_{i =1}^n B_i\\) and note that the sequence is increasing. Continuity of probability gives\n\\[\n\\lim_{n \\to \\infty} P(C_n) = P(\\cup_{i=1}^{\\infty} B_i).\n\\]\nUsing \\(P(A \\cup B) \\leq P(A) + P(B)\\), we see that\n\\[\nP(C_n) \\leq \\sum_{i = 1}^n P(B_i) = 0\n\\]\nand so \\(P(C_n) = 0\\) and \\[\\lim_{n \\to \\infty} P(C_n) = P(\\cup_{i=1}^{\\infty} B_i) = 0\\].\nTo finish the proof, we note that\n\\[\\begin{align}\nP(\\cap_{i=1}^{\\infty} A_i) &= 1 - P((\\cap_{i=1}^{\\infty} A_i)^c)\\\\\n                           &= 1 - P( \\cup_{i =1}^{\\infty} A_i^c)\\\\\n                           &= P(\\cup_{i=1}^{\\infty} B_i) = 0.\n\\end{align}\\]"
  },
  {
    "objectID": "FCSC/ch1.html#constructing-a-random-variable-from-another",
    "href": "FCSC/ch1.html#constructing-a-random-variable-from-another",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.6 Constructing a Random Variable from Another",
    "text": "1.6 Constructing a Random Variable from Another\nLet \\(X\\) be a random variable on \\((\\Omega, \\mathcal{F}, P)\\) this is uniformly distributed on \\([-1, 1]\\). Define \\(Y = X^2\\).\n\nFind the CDF of Y and plot its graph.\n\nFirst, the CDF:\nLet \\(F\\) denote the CDF of \\(Y\\) and \\(F_X\\) denote the CDF of X.\nThen \\[\nG(x) = P(Y \\leq x) = P(X^2 \\leq x) = P(X \\leq \\sqrt{x}) = F(\\sqrt{x}).\n\\]\nNow,\n\\[\nF(x) =\n\\begin{cases}\n0 & \\text{if } x \\leq 0, \\\\\nx & \\text{if } 0 < x < 1, \\\\\n1 & \\text{if } x \\geq 1.\n\\end{cases}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nI’ve taken \\(F\\) to be different to that in the book (the first case in the book uses \\(x < 0\\)) so that the resulting \\(G\\) has a well-defined derivative at zero.\n\n\n\nand so\n\\[\nG(x) =\n\\begin{cases}\n0 & \\text{if } x <= 0, \\\\\n\\sqrt{x} & \\text{if } 0 < x < 1, \\\\\n1 & \\text{if } x \\geq 1.\n\\end{cases}\n\\]\nWe plot this below:\n\ndef G(x):\n    if x <= 0:\n        return 0\n    elif x > 0 and x < 1:\n        return np.sqrt(x)\n    return 1\n\nxticks = np.linspace(-1, 1.5, 100)\nplt.plot(xticks, [G(x) for x in xticks])\n\n\n\n\n\nthe PDF of Y is given by\n\n\\[\np(y) = \\frac{dG}{dy}(y) = \\begin{cases}\n0 & \\text{if } x \\leq 0, \\\\\n\\frac{1}{2\\sqrt{x}} & \\text{if } 0 < x < 1, \\\\\n0 & \\text{if } 0 \\geq 1.\n\\end{cases}\n\\]\nThe plot is below\n\n\nCode\ndef p(x):\n    if x <= 0:\n        return 0\n    elif x > 0 and x < 1:\n        return (1/( 2 * np.sqrt(x)))\n    return 1\n\nxticks = np.linspace(-1, 0, 50)\nplt.plot(xticks, [p(x) for x in xticks])\nxticks = np.linspace(0.01, 0.99, 50)\nplt.plot(xticks, [p(x) for x in xticks])\nxticks = np.linspace(1, 2, 50)\nplt.plot(xticks, [p(x) for x in xticks])\nplt.show()"
  },
  {
    "objectID": "FCSC/ch1.html#sum-of-integrable-variables",
    "href": "FCSC/ch1.html#sum-of-integrable-variables",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.7 Sum of Integrable Variables",
    "text": "1.7 Sum of Integrable Variables\n\\(X\\) and \\(Y\\) are two integrable random variables on the same probability space. Then \\(aX + bY\\) is also an integrable random variable for any \\(a, b \\in \\mathbb{R}\\).\nProof:\nWe assert that \\(aX + b Y\\) is a random variable and are left to show that\n\\[\nE(\\left|aX + bY\\right|) < \\infty.\n\\]\nBy the triangle inequality,\n\\[\n\\left| aX + bY \\right| \\leq \\left| a \\right| \\left| X \\right| + \\left| b \\right| \\left| Y \\right|\n\\] and so we can conclude that\n\\[\nE(\\left|aX + bY\\right|) < \\infty.\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#jumps-and-probabilities",
    "href": "FCSC/ch1.html#jumps-and-probabilities",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.8 Jumps and Probabilities",
    "text": "1.8 Jumps and Probabilities\nLet \\(X\\) be a random variable and \\(F_X\\) be its CDF. Then\n\\[\nP(X = a) = F_X(a) - \\lim_{x \\to a-} F_X(x) = F_X(a) - F_X(a-).\n\\]\nProof:\nDefine a decreasing sequence of events \\(A_n = \\{ X \\in (a - 1/n, a]\\}\\) and note that \\(\\cap_{i=1}^{\\infty} A_n = \\{ X = a\\}\\). By continuity of probability\n\\[\n\\lim_{n \\to \\infty} P(A_n) = P(X = a).\n\\]\nNow,\n\\[\\begin{align}\nP(X = a) &= \\lim_{n \\to \\infty} P(A_n)\\\\\n         &= \\lim_{n \\to \\infty} (F_X(a) - F_X(a - 1/n))\\\\\n         &= F_X(a) - \\lim_{n \\to \\infty} (F_X(a - 1/n)) = F_X(a) - F_X(a-).\n\\end{align}\\]"
  },
  {
    "objectID": "FCSC/ch1.html#memory-loss-property",
    "href": "FCSC/ch1.html#memory-loss-property",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.9 Memory Loss Property",
    "text": "1.9 Memory Loss Property\nLet \\(Y\\) be an exponential random variable with parameter \\(\\lambda\\). The for any \\(s, t > 0\\)\n\\[\nP(Y > t + s | Y > s) = P(Y > t).\n\\]\nProof:\nThe CDF of the exponential distribution is\n\\[\nF(t) = 1 - e^{-\\lambda t}.\n\\]\nTherefore,\n\\[\nP(Y > t) = 1 - F(t) = e^{-\\lambda t}.\n\\]\nNow\n\\[\\begin{align}\nP(Y > t + s | Y > s) & =  \\frac{P(Y > t + s \\cap Y > s)}{P(Y > s)} \\\\\n                     & =  \\frac{P(Y > t + s)}{P(Y > s)}  \\\\\n                     & =  \\frac{e^{-\\lambda(t + s)}}{e^{-\\lambda s}} \\\\\n                     & =  e^{-\\lambda t} \\\\\n                     & =  P(Y > t).\n\\end{align}\\]\nNote that \\(P(Y > t + s \\cap Y > s) = P(Y > t + s)\\) because \\(\\{ \\omega \\in \\Omega | Y(\\omega) > t + s \\} \\subseteq \\{ \\omega \\in \\Omega | Y(\\omega) > t \\}\\) and so \\(\\{ \\omega \\in \\Omega | Y(\\omega) > t + s \\} \\cap \\{ \\omega \\in \\Omega | Y(\\omega) > t \\} = \\{ \\omega \\in \\Omega | Y(\\omega) > t + s\\}\\).\n\n\n\n\n\n\nThis property characterises the exponential distribution\n\n\n\nUsing the memory property \\[\n\\begin{align}\nP(X \\leq x + h) - P(X < x) &= 1 - P(X > x + h) -1 + P(X > x) \\\\\n&= P(X > x) - P(X > x + h) \\\\\n&= P(X > x) - P(X > x + h | X > x) P(X > x) \\\\\n&= P(X > x)(1 - P(X > x + h | X > x)) \\\\\n&= P(X > x)(1 - P(X >  h)) \\\\\n&= P(X > x)(P(X \\leq h) - P( X\\leq 0)).\n\\end{align}\n\\]\nSo we can assert that the CDF \\(F\\) satisifies\n\\[\n\\begin{align}\nF'(x) &= \\lim_{h\\to 0} \\frac{P(X \\leq x +h) - P(X \\leq x)}{h} \\\\\n&= P(X > x) \\lim_{h \\to 0} \\frac{P(X \\leq h) - P(X \\leq 0)}{h} \\\\\n&= P(X > x) F'(0) \\\\\n&= (1 - F(x)) F'(0).\n\\end{align}\n\\]\nThe family of solutions to this differential equation is\n\\[\nF(x) = 1 - e^{-\\lambda x}\n\\] for \\(\\lambda > 0\\)."
  },
  {
    "objectID": "FCSC/ch1.html#gaussian-integration-by-parts",
    "href": "FCSC/ch1.html#gaussian-integration-by-parts",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.10 Gaussian Integration by Parts",
    "text": "1.10 Gaussian Integration by Parts\n\nLet \\(Z\\) be a standard Gaussian random variable. Then\n\n\\[\nE(Zg(Z)) = E(g'(Z))\n\\]\nwhen both expectations are well-defined.\nProof:\nWe can use LOTUS and integration by parts:\n\\[\\begin{align}\nE(Z g(Z)) = \\int_{-\\infty}^{\\infty} z g(z) p(z) dz  &=  \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} z g(z) e^{-z^2/2} dz \\\\\n&= \\int_{-\\infty}^{\\infty} g(z) (-\\frac{dp}{dz}) dz \\\\\n&= -g(z) p(z) \\rvert_{-\\infty}^{\\infty} + \\int_{-\\infty}^{\\infty} g'(z) p(z) dz \\\\\n&= E(g'(Z)).\n\\end{align}\\]\nNote that\n\\[\n-g(z) p(z) \\rvert_{-\\infty}^{\\infty} = 0\n\\]\nfollows from \\(zg(z) p(z)\\) being integrable.\n\nIn particular, if \\(g(z) = z^{n + 1}\\), then \\(g'(z) = (n +1) z^{n}\\) so\n\n\\[\nE( Z g(Z)) = E(Z^{n+2}) = E((n + 1) Z^{n}).\n\\]\nWe see that\n\\[\n\\begin{align}\nE(Z^{2n}) &= (2n -1) E(Z^{2n -2})\\\\\n          &= (2n -1) (2n -3) E(Z^{2n - 4})\\\\\n          &= (2n - 1) (2n -3) \\ldots 1 E(Z^2)\\\\\n          &= (2n -1) (2n -3) \\ldots 1.\n\\end{align}\n\\]\nSimilarly,\n\\[\n\\begin{align}\nE(Z^{2n + 1}) &= (2n) E(Z^{2n -1})\\\\\n          &= (2n) (2n -2) E(Z^{2n - 3})\\\\\n          &= (2n) (2n -2) \\ldots 1 E(Z)\\\\\n          &= 0.\n\\end{align}\n\\]\nSetting \\(X = \\sigma Z\\), we find that\n\\[\nE(X^{2n}) = \\sigma^{2n} (2n -1)(2n -3) \\ldots 1.\n\\]\nWe can’t have a mean different from zero: without symmetry about zero the special structure of odd and even functions would be lost."
  },
  {
    "objectID": "FCSC/ch1.html#mgf-of-exponential-random-variables",
    "href": "FCSC/ch1.html#mgf-of-exponential-random-variables",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.11 MGF of Exponential Random Variables",
    "text": "1.11 MGF of Exponential Random Variables\nShow that for a random variable \\(X \\sim exp(\\lambda)\\)\n\\[\nE(e^{t X}) = \\frac{ \\lambda}{\\lambda - t }, t < \\lambda.\n\\]\nUsing LOTUS and choosing \\(t < \\lambda\\)\n\\[\\begin{align}\nE(e^{tX}) &= \\int_{0}^{\\infty} e^{tx} \\lambda e^{-\\lambda x} dx \\\\\n          &= \\int_0^{\\infty} e^{(t - \\lambda) x} dx \\label{exp:integral} \\tag{*} \\\\\n          &= \\frac{1}{t - \\lambda} e^{(t - \\lambda) x} \\rvert_{0}^{\\infty} \\\\\n          &= \\frac{ \\lambda}{\\lambda - t }.\n\\end{align}\\]\nNote that if \\(t \\geq \\lambda\\), then the integral \\(\\eqref{exp:integral}\\) is not well-defined.\nWe can calculate \\(E(X)\\):\n\\[\nE(X) = \\frac{d}{dt} E(e^{tX}) \\rvert_{t=0} = \\frac{\\lambda}{(\\lambda -t)^2}\\rvert_{t=0} = \\frac{1}{\\lambda}.\n\\]\nWe can also calculate \\(Var(X)\\):\n\\[\nE(X^2) = \\frac{d^2}{dt^2} E(e^{tX}) \\rvert_{t=0} = \\frac{2\\lambda}{(\\lambda -t)^3} \\rvert_{t=0} = \\frac{2}{\\lambda^2}.\n\\]\nand so\n\\[\nVar(X) = E(X^2) - E(X)^2 = \\frac{2}{\\lambda^2} - \\frac{1}{\\lambda^2} =\\frac{1}{\\lambda^2}.\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#gaussian-tail",
    "href": "FCSC/ch1.html#gaussian-tail",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.12 Gaussian Tail",
    "text": "1.12 Gaussian Tail\nConsider a random variable \\(X\\) with finite MGF such that\n\\[\\begin{equation}\nE(e^{\\lambda X}) \\leq e^{\\lambda^2/2}\n\\label{gtail} \\tag{1}\n\\end{equation}\\]\nfor all \\(\\lambda \\in \\mathbb{R}\\).\nProve that for \\(a > 0\\)\n\\[\nP(X > a) \\leq e^{-a^2/2}.\n\\]\nFor \\(\\lambda > 0\\) \\[\nP(X > a) = P(e^{\\lambda X} > e^{\\lambda a})\n\\] by the monitonicity of the exponential. By Markov’s inequality and \\(\\eqref{gtail}\\) \\[\nP(e^{\\lambda X} > e^{\\lambda a}) \\leq \\frac{E(e^{\\lambda X})}{e^{\\lambda a}} \\leq e^{\\lambda^2/2 - \\lambda a}.\n\\]\nLet \\(f(\\lambda) = e^{\\lambda^2/2 - \\lambda a}\\). The minimum for \\(f\\) is found by differentiation:\n\\[\nf'(\\lambda) = (\\lambda - a) e^{\\lambda^2/2 - \\lambda a}\n\\]\nand \\(f'(\\lambda) = 0\\) is solved for \\(\\lambda = a\\). Therefore,\n\\[\nP(X > a) \\leq e^{a^2/2 - a^2} = e^{-a^2/2}.\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#expectation-from-cdf",
    "href": "FCSC/ch1.html#expectation-from-cdf",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.13 Expectation from CDF",
    "text": "1.13 Expectation from CDF\nLet \\(X\\) be a random variable such that \\(X >= 0\\). Then\n\\[\nE(X) = \\int_0^{\\infty} P(X > x) dx.\n\\]\nProof:\n\\[\n\\int_0^{\\infty} P(X > x) dx = \\int_0^{\\infty} (1 - F(x)) dx\n\\]\nwhere \\(F(x) = P(X <= x)\\). We can write\n\\[\n1 - F(x) = \\lim_{x \\to \\infty} F(x) - F(x) = \\int_x^{\\infty} dF(t)\n\\]\nwhere the integral is understood in the Lebesgue sense.\nNow,\n\\[\n\\int_0^{\\infty} P(X > x) dx = \\int_0^{\\infty} \\int_x^{\\infty} dF(t) dx\n\\]\nand by changing the order of integration (and appealing to Fubini’s Theorem)\n\\[\n\\int_0^{\\infty} P(X > x) dx = \\int_0^{\\infty} \\int_0^t dx dF(t) = \\int_0^{\\infty} t dF(t) = E(X).\n\\]\nSubtle point: we’re using the fact that X >= 0 to arrive at zero for the lower limit of the inner integral.\n\n\n\n\n\n\nConsequence: LOTUS (Law Of The Unconcious Statistician)\n\n\n\n\n\nLet \\(g: \\mathbb{R} \\mapsto \\mathbb{R}\\) be measurable. Then \\(E(g(X)) = \\int_{-\\infty}^{\\infty} g(x) dF(x)\\).\nFirst suppose that \\(g >= 0\\). Then\n\\[\nE(g(X)) = \\int_0^{\\infty} P(g(X) > x) dx\n\\] by the result above.\nNow,\n\\[\n\\int_0^{\\infty} P(g(X) > x) dx = \\int_0^{\\infty} \\int_{\\{z: g(z) > x\\}} dF(z) dx.\n\\]\nChanging the order of integration, we see get\n\\[\n\\int_{-\\infty}^{\\infty} \\int_0^{g(z)} dx dF(z) = \\int_{-\\infty}^{\\infty} g(x) dF(x).\n\\]\nNow suppose we have general \\(g\\). Split \\(g\\) into the sum of non-negative and negative components\n\\[\ng = g_+ - g_{-}\n\\]\n\\[\n\\begin{align}\nE(g(X)) &= E(g_+(X)) - E(g_{-}(X)) \\\\\n&= \\int_{-\\infty}^{\\infty} g_+(x) dF(x) - \\int_{-\\infty}^{\\infty} g_{-}(x) dF(x) \\\\\n&= \\int_{-\\infty}^{\\infty} g(x) dF(x).\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n\nConsequence: Limit of xP(X>x)\n\n\n\n\n\nIf \\(E(X_+) < \\infty\\), then \\(\\lim_{x \\to \\infty} x P(X > x) = 0\\).\nWe prove this by contradiction. Suppose that there exists \\(c > 0\\) such that \\(lim_{x \\to \\infty} xP(X >x) \\geq c\\). Then for some \\(x(c)\\), \\(xP(X>x) \\geq c\\) for all \\(x > x(c)\\) and so\n\\[\nE(X+) = \\int_0^{\\infty} P(X > x) dx \\geq \\int_{x(c)}^{\\infty} P(X > x) dx \\geq \\int_{x(c)}^{\\infty} \\frac{c}{x} dx = \\infty.\n\\]\nThis contradicts \\(E(X_+) < \\infty\\).\nContrast this with the Markov inequality which states that\n\\[\nP(X > x) <= \\frac{E(X)}{x}\n\\]\nwhich puts a bound on \\(x P(X > x)\\):\n\\[\nx P(X > x) <= E(X).\n\\]\n\n\n\nTake a random variable \\(X\\) such the \\(E(|X|) < \\infty\\). Prove that\n\\[\nE(X) = \\int_0^{\\infty} P(X > x) dx - \\int_{-\\infty}^0 P(X \\leq x) dx.\n\\]\nDefine \\(X_+ = X 1_{X \\geq 0}\\) and \\(X_{-} = X 1_{X < 0}\\) and note that \\(X = X_+ + X_{-}\\). Then\n\\[\nE(X) = E(X_+) + E (X_{-})\n\\] by linearity of expectation. From above,\n\\[\nE(X_+) = \\int_0^{\\infty} P(X_+ > x) dx = \\int_0 ^{\\infty} P(X > x) dx.\n\\]\nSet \\(Y = -X_{-}\\). Then \\(Y > 0\\) and\n\\[\nE(Y) = \\int_0^{\\infty} P(Y > y) dy.\n\\]\nNow,\n\\[\\begin{align}\nE(X 1_{X < 0}) &= - E(- X_{-}) \\\\\n               &= - E(Y) \\\\\n               &= -\\int_0^{\\infty} P(-X_{-} >y) dy \\\\\n               &= \\int_{0}^{-\\infty} P(X_{-} < x) dx \\\\\n               &= \\int_0^{-\\infty} P(X < x) dx\n\\end{align}\\]\nThen\n\\[\nE(X) = \\int_0^{\\infty} P(X > x) dx - \\int_{-\\infty}^0 P(X < x) dx.\n\\]\n\n\n\n\n\n\nThe result we have to prove is not generally true\n\n\n\n\\[\n\\int (P(X <= x) -P(X<x)) dx = \\int P(X = x) dx = 0\n\\]\nwhen \\(X\\) has a PDF (the CDF is at least continuous). In this case, we can state\n\\[\nE(X) = \\int_0^{\\infty} P(X > x) dx - \\int_{-\\infty}^0 P(X \\leq x) dx.\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#characteristic-function",
    "href": "FCSC/ch1.html#characteristic-function",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.14 Characteristic Function",
    "text": "1.14 Characteristic Function\n\nNote that the expectation of a complex-valued random variable (or indeed the complex-valued random variable) is defined in Chapter 1.\n\nA good definition is\n\\[\nE(Z) = E(\\Re(Z)) + i E(\\Im(Z)).\n\\]\nNote that if \\(E(|Z|) < \\infty\\), then the real and imaginary parts of \\(Z\\) are also integrable.\nWe can extend LOTUS to complex valued functions. Suppose that \\(g: \\mathbb{R} \\to \\mathbb{C}\\) and \\(E(|g(X)|) < \\infty\\). We can decompose \\(g\\) as\n\\[\ng = g_1 + i g_2.\n\\]\nNote that \\(g_1(X)\\) and \\(g_2(X)\\) are integrable.\nwhere \\(g_1, g_2 : \\mathbb{R} \\to \\mathbb{R}\\). Then by linearity of expectation\n\\[\\begin{align}\nE(g(X)) &= E(g_1(X)) + i E(g_2(X))\\\\\n        &= \\int_{-\\infty}^{\\infty} g_1(x) dF(x) + i \\int_{-\\infty}^{\\infty} g_2(x) dF(x)\\\\\n        &= \\int_{-\\infty}^{\\infty} (g_1(x) + i g_2(x)) dF(x)\\\\\n        &= \\int_{-\\infty}^{\\infty} g(x) dF(x).\n\\end{align}\\]\nUsing this result, we see that\n\\[\nE(e^{itX}) = E(\\cos(tX)) + i E(\\sin(tX))\n\\]\nfrom the familiar Euler identity \\(e^{itx} = \\cos(tx) + i \\sin(tx)\\).\nThe same result can be argued using the Taylor series:\n\\[\\begin{align}\nE(e^{itX}) &= \\sum_{n=0}^{\\infty} E( \\frac{(itX)^n}{n!})\\\\\n           &= \\sum_{n=0}^{\\infty} E( \\frac{((-1)^{n} t^{2n} X^{2n}}{(2n)!}) + i \\sum_{i=0}^{\\infty} E( \\frac{((-1)^{n} t^{2n +1} X^{2n + 1}}{(2n + 1)!})\\\\\n           &= E(\\cos(tX)) + iE(\\sin(tX).\n\\end{align}\\]\n\nLet \\(X \\sim \\mathcal{N}(0, 1)\\). Then\n\n\\[\nE(e^{itX}) = \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} e^{itx} e^{-\\frac{1}{2}x^2} dx.\n\\]\nDefine \\(g(t) = E(e^{itX})\\) and try to build a differential equation we can solve which is hopefully equal to the desired result.\nUsing the Dominated Convergence Theorem, we can take differentiation inside the expectation integral (the derivative of the integrand is dominated by \\(e^{-\\frac{1}{2}x^2}\\) which is integrable).\nWe get\n\\[\\begin{align}\ng'(t) &= \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} i x e^{itx} e^{-\\frac{1}{2}x^2} dx.\n\\end{align}\\]\nUse integration by parts:\nSet \\(u = ie^{itx}\\) so \\(du = -t e^{itx}\\) and\n\\[\\begin{align}\ndv &= \\frac{1}{\\sqrt{2 \\pi}} x e^{-\\frac{1}{2}x^2}\\\\\n   &= -\\frac{1}{\\sqrt{2 \\pi}} \\frac{d}{dx}(e^{-\\frac{1}{2}x^2}).\n\\end{align}\\]\nPerforming the integration by parts we see that \\[\n\\begin{align}\ng'(t) &= \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} i x e^{itx} e^{-\\frac{1}{2}x^2} dx \\\\\n      &= -\\frac{1}{\\sqrt{2 \\pi}} ie^{itx} e^{-\\frac{1}{2}x^2} \\rvert_{-\\infty}^{\\infty} -  \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} te^{itx}  e^{-\\frac{1}{2}x^2} dx \\\\\n      &= 0 + iE(e^{itX})\\\\\n      &= -t g(t). \\label{characteristic:diffeqn} \\tag{*}\n\\end{align}\n\\] Moreover,\n\\[\ng(0) = E(e^{0}) = E(1) = 1.\n\\]\nThe unique solution to \\(\\eqref{characteristic:diffeqn}\\) is\n\\[\ng(t) = \\frac{1}{2}e^{-t^2/2}\n\\]\nand so\n\\[\nE(e^{itX}) = \\frac{1}{2}e^{-t^2/2}.\n\\]\nLet \\(Z = \\sigma X + \\mu\\) for \\(\\sigma > 0\\) and \\(\\mu \\in \\mathbb{R}\\). Then\n\\[\\begin{align}\nE(e^{itZ}) &= E(e^{it(\\sigma X + \\mu)}) \\\\\n           &= E(e^{\\sigma X} e^{it\\mu}) \\\\\n           &= e^{it\\mu}  E(e^{it\\sigma X})\\\\\n           &= e^{it\\mu}e^{-(t\\sigma)^2/2}\\\\\n           &= e^{it \\mu - \\sigma^2t^2/2}.\n\\end{align}\\]"
  },
  {
    "objectID": "FCSC/ch1.html#when-ex-infty",
    "href": "FCSC/ch1.html#when-ex-infty",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.15 When \\(E(X) < \\infty\\)",
    "text": "1.15 When \\(E(X) < \\infty\\)\nLet \\(X \\geq 0\\) be a random variable on \\((\\Omega, \\mathcal{F}, P)\\). If \\(E(X) < \\infty\\), then \\(P(X = \\infty) = 0\\).\nProof:\nLet \\(A_n = \\{\\omega \\in \\Omega: X(\\omega) > n \\}\\) for \\(n > 0\\).\nWe note that the sequence of events \\(A_n\\) is decreasing and so by continuity of probability\n\\[\n\\lim_{n\\to \\infty} P(A_n) = P(\\cap A_n) = P(X = \\infty).\n\\]\nThe proof is complete with an application of Markov’s inequality: \\[\nP(X = \\infty) = \\lim_{n \\to \\infty} P(A_n) \\leq \\lim_{n\\to\\infty} \\frac{1}{n} E(X) = 0.\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#when-ex-0",
    "href": "FCSC/ch1.html#when-ex-0",
    "title": "A First Course in Stochastic Calculus",
    "section": "1.16 When \\(E(X) = 0\\)",
    "text": "1.16 When \\(E(X) = 0\\)\nLet \\(X \\geq 0\\) be a random variable on \\((\\Omega, \\mathcal{F}, P)\\). If \\(E(X) = 0\\), then \\(P(X = 0) = 1\\).\nProof:\nBy Markov’s inequality\n\\[\nP(X > 1/n) \\leq n E(X) = 0\n\\]\nand so \\(P(X > 1/n) = 0\\) for \\(n = 1, 2, \\ldots\\). It follows that\n\\[\nP(X \\leq 1/n) = 1 - P(X > 1/n) = 1.\n\\]\nThe sequence of events \\(\\{ X \\leq 1/n \\}\\) is decreasing and\n\\[\n\\{ X = 0 \\} = \\cap \\{ X \\leq 1/n \\}.\n\\]\nBy the continuity of probability\n\\[\nP(X = 0) = \\lim_{n \\to \\infty} P(X \\leq 1/n) = 1.\n\\]"
  },
  {
    "objectID": "PML/ch2.html",
    "href": "PML/ch2.html",
    "title": "Probabilistic Machine Learning",
    "section": "",
    "text": "I only cover starred exercises here\n\n\n\nFor solutions to non-starred exercises see https://probml.github.io/pml-book/solns-public.pdf.\n\n\n\nExercise 2.1\nLet \\(H \\in \\{1, \\ldots, K\\}\\) be a discrete random variable, and let \\(e_1\\) and \\(e_2\\) be the observed values of two other random variables \\(E_1\\) and \\(E_2\\).\nWe wish to calculate\n\\[\n\\vec{P}(H | e_1, e_2) = (P(H=1|e_1, e_2), \\ldots, P(H= K)).\n\\]\nFor \\(i \\in \\{1, \\ldots, K\\}\\),\n\\[\n\\begin{align}\nP(H=i|e_1, e_2) &= \\frac{P(H=i,e_1, e_2)}{P(e_1, e_2)} \\\\\n                &= \\frac{P(e_1, e_2 |H=i) P(H=i)}{P(e_1, e_2)}.\n\\end{align}\n\\]\nSo, to perform the caculation, we need y - \\(P(e_1, e_2 |H = i)\\) for all \\(i \\in \\{1, \\ldots K\\}\\) i.e. \\(P(e_1, e_2 |H)\\) - \\(P(H=i)\\) for all \\(i \\in \\{1, \\ldots, K\\}\\) i.e. \\(P(H)\\) - \\(P(e_1, e_2)\\)\nSo the solution to (a) is (ii).\nNow we assume that \\(E_1 \\perp E_2 |H\\). This means that\n\\[\nP(e_1, e_2 |H=i) = P(e_1|H=i) P(e_2|H=i)\n\\] for all \\(i \\in \\{1, \\ldots, K\\}\\). With this assumption \\(\\{P(e_1, e_2), P(H), P(e_1|H), P(e_2|H)\\}\\), set (i), is now sufficient to perform the calculation:\n\\[\n\\begin{align}\nP(H=i|e_1, e_2) &= \\frac{P(e_1, e_2 |H=i) P(H=i)}{P(e_1, e_2)} \\\\\n&= \\frac{P(e_1 |H=i) P(e_2|H=i) P(H=i)}{P(e_1, e_2)}\n\\end{align}\n\\] for all \\(i \\in \\{1, \\ldots, K\\}\\).\n\n\nExercise 2.3\nThe question is unclear about notation. We’ll assume that \\(p\\) will denote probability density functions i.e.\n\n\\(p(x,y|z)\\) denotes the joint distribution of \\(X\\) and \\(Y\\) conditioned on \\(Z\\)\n\\(p(x|z)\\) denotes the conditional distribution of \\(X\\) given \\(Z\\)\n\\(p(y|z)\\) denotes the conditional distribution of \\(Y\\) given \\(Z\\)\n\nSuppose there exists \\(g\\) and \\(h\\) such that\n\\[\np(x, y |z) = g(x, z) h(y, z).\n\\]\nBy definition \\[\n\\begin{align}\np(x | z) &= \\int p(x, y |z) dy \\\\\n         &= \\int g(x, z) h(y, z) dy \\\\\n         &= g(x, z) \\int h(y, z) dy.\n\\end{align}\n\\] Similarly, \\[\n\\begin{align}\np(y | z) &= \\int p(x, y |z) dx \\\\\n         &= \\int g(x, z) h(y, z) dx \\\\\n         &= h(y, z) \\int g(x, z) dx.\n\\end{align}\n\\]\nTherefore,\n\\[\n\\begin{align}\np(x |z)p (y | z) &= g(x, z) h(y, z) \\int \\int g(x, z) h(y,z) dx dy \\\\\n&= p(x, y| z) \\int \\int p(x, y |z) dx dy \\\\\n&= p(x, y | z)\n\\end{align}\n\\]\ni.e. \\(X \\perp Y | Z\\).\nThe other direction is trivial: if \\(X \\perp Y|Z\\) then we can set \\(g(x, z) = p(x | z)\\) and \\(h(y, z) = p(y |z)\\).\n\n\nExercise 2.5\nSuppose that \\(X, Y\\) are two points sampled indpendently and uniformly at random from the interval \\([0, 1]\\). What is the expected location of the leftmost point?\nBy independence, we can express the joint CDF of \\(X\\) and \\(Y\\) as follows: \\[\n\\begin{align}\nF_{X,Y}(x, y) &= P(X \\leq x, Y \\leq y) \\\\\n&= P(X \\leq x) P(Y \\leq y) \\\\\n& = \\begin{cases}\n1  & \\text{for } x, y > 1,\\\\\nx & \\text{for } x  \\in [0,1], y > 1,\\\\\ny & \\text{for } y \\in [0,1], x > 1,\\\\\nxy & \\text{for } x, y \\in [0,1],\\\\\n0  & \\text{otherwise}\n\\end{cases}\n\\end{align}\n\\]\nThe joint probability density is then \\[\n\\begin{align}\np(x, y) &= \\frac{\\partial^2}{\\partial_x \\partial_y}F_{X,Y}(x, y) \\\\\n&= \\begin{cases}\n1 & \\text{for } x,y \\in [0,1], \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\end{align}\n\\]\nUsing LOTUS,\n\\[\n\\begin{align}\nE(\\min(X, Y)) &= \\int_0^1 \\int_0^1 \\min(x, y) dx dy \\\\\n&= \\int_0^1 (\\int_0^y x dx + \\int_y^1 y dx) dy \\\\\n&= \\int_0^1 (y - \\frac{y^2}{2}) dy \\\\\n&= \\frac{y^2}{2} -\\frac{y^3}{6} \\rvert_0^1 \\\\\n&= \\frac{1}{2} - \\frac{1}{6} \\\\\n&=  \\frac{1}{3}.\n\\end{align}\n\\]\nAnother approach is to use the fact that for \\(Z \\geq 0\\)\n\\[\nE(Z) = \\int_0^{\\infty} P(Z > z) dz.\n\\]\nIf we set \\(Z = \\min(X, Y)\\), then\n\\[\n\\begin{align}\nE(Z) &= \\int_0^{\\infty} P(\\min(X,Y) > z) dz \\\\\n&= \\int_0^1 P(\\min(X, Y) > z) dz \\\\\n&= \\int_0^1 P(X > z, Y > z) dz \\\\\n&= \\int_0^1 P(X > z) P(Y > z) dz \\\\\n&= \\int_0^1 (1 - z)^2 dz \\\\\n&= \\frac{-(1 - z)^3}{3} \\rvert_0^1 \\\\\n&= \\frac{1}{3}.\n\\end{align}\n\\]\n\n\nExercise 2.7\nLet \\(X \\sim Ga(a, b)\\) and \\(Y = 1/X\\). Derive the distribution of \\(Y\\).\nBy definition\n\\[\nGa(x | a, b) =  = \\frac{b^a}{\\Gamma(a)} x^{a-1}e^{-xb}.\n\\]\n\\[\nP(Y \\leq y) = P(1/X \\leq y) = P(X \\geq 1/y)\n\\]\n\\[\nP(X \\geq 1/y) = 1 - P( X < 1/y) = 1 - \\int_0^{1/y} Ga(x |a, b) dx\n\\]\nTaking the derivative with respect to \\(y\\)\n\\[\n\\begin{align}\n\\frac{d}{dy} P(Y \\leq y) &=  - \\frac{d}{dy} \\int_0^{1/y} Ga(x |a, b) dx \\\\\n&= -Ga(1/y |a, b) \\frac{d}{dy}(1/y) \\\\\n&= \\frac{1}{y^2} Ga(1/y |a, b).\n\\end{align}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nI’ve used the second fundamental theorem of calculus and chain rule\n\\[\n\\frac{d}{dx} \\int_{g(x)}^{f(x)}  h(t) dt = h(f(x))f'(x) - h(g(x))g'(x).\n\\]\n\n\n\nTherefore, the pdf of \\(Y\\) is \\[\n\\frac{b^a}{\\Gamma(a)} (1/y)^{a-1}(1/y)^2e^{-b/y} = \\frac{b^a}{\\Gamma(a)} y^{-(a+1)}e^{-b/y}\n\\]\n\n\nExercise 2.9\nLet \\(D\\) be the event that you have a disease. Let \\(+\\) be the event that you test positive for this disease and let \\(-\\) be the event that you test negative for the same disease.\nWe are told that \\(P(+|D) = P(- | D^c) = 0.99\\). It follows that\n\\[\nP(+ | D^c) = 1 - P(-| D^C) = 10^{-2}.\n\\] We are also told that \\[\nP(D) = 10^{-4}.\n\\]\nThe probability of having the disease given a positive test can be expressed using Bayes’ Theorem:\n\\[\n\\begin{align}\nP(D | +)  &= \\frac{P(+ | D) P(D)}{P(+)} \\\\\n&= \\frac{P(+ | D) P(D)}{P(+| D)P(D) + P(+|D^c)P(D^c)} \\\\\n&= \\frac{0.99.10^{-4}}{0.99.10^{-4} + 10^{-2}(1 - 10^{-4})}.\n\\end{align}\n\\]\nUsing python as a calculator\n\naccuracy= 99/100 \nprevalance=1/10000\n\nanswer= accuracy*prevalance/(accuracy*prevalance + (1-accuracy)*(1 -prevalance))\nprint(answer)\n\n0.009803921568627442\n\n\nSo, with the test for this disease, a positive test means you have about 1% chance of having the disease.\n\n\nExercise 2.11\nLet’s phrase the problem in terms of a game with coins:\nI toss two fairs coins without showing you the result.\n\nYou ask if any of the coins are heads and I respond, truthfully, “yes”: what is the probability that one coin is a tail?\nI ask you to choose a coin to be revealed: you choose and it is a head. What is the probability that the other coin is a tail?\n\nLet \\(A\\) be the event that there is at least one head and \\(B\\) denote the event that one head has been revealed. When the event \\(B\\) occurs we know that there is at least one head and so \\(B\\) also occurs i.e. \\(B \\subseteq A\\). It follows that\n\\[\nP(B) \\leq P(A).\n\\]\nThe two events do not convey the same information: \\(B\\) tells you that after random sampling, the revealed coin is heads whereas \\(A\\) tells you that after looking at both coins, I reveal that at least one is heads. So before doing any calculation I’d guess that\n\\[\nP(B) < P(A).\n\\]\nLet \\(T\\) be the event of at least one tail, \\(H\\) be the event of at least one head and subscript these to indicate if a specific coin is a head or tail e.g. \\(T_1\\) is the event that coin \\(1\\) is a tail. Denote by \\(C_i\\) the event that coin \\(i\\) is chosen.\nWe can write \\[\n\\begin{align}\nP(A) &= P(T | H) \\\\\n     &= \\frac{P(T \\cap H)}{P(H)} \\\\\n     &= \\frac{P((T_1 \\cup T_2) \\cap (H_1 \\cup H_2))}{P(H_1 \\cup H_2)} \\\\\n     &= \\frac{P((T_1 \\cap H_2) \\cup (T_2 \\cap H_1))}{P(H_1 \\cup H_2)}.\n\\end{align}\n\\]\nNow,\n\\[\nP(H_1 \\cup H_2) = 3/4\n\\] because there are \\(3\\) out of \\(4\\) equally likely outcomes that have at least one head,\nand\n\\[\n\\begin{align}\nP((T_1 \\cap H_2) \\cup (T_2 \\cap H_1)) &= P(T_1 \\cap H_2) + P(T_2 \\cap H_1) \\\\\n&= P(T_1)P(H_2) + P(T_2)P(H_1) \\\\\n&= 1/4 + 1/4 \\\\\n& = 1/2.\n\\end{align}\n\\]\nTherefore, \\[\nP(A) = \\frac{1/2}{3/4} = 2/3.\n\\]\nSimilarly,\n\\[\n\\begin{align}\nP(B) &= P(T | (H_1 \\cap C_1) \\cup (H_2 \\cap C_2)) \\\\\n     &= \\frac{P(T \\cap ((H_1 \\cap C_1) \\cup (H_2 \\cap C_2)))}{P((H_1 \\cap C_1) \\cup (H_2 \\cap C_2))} \\\\\n     &= \\frac{P((H_1 \\cap T_2 \\cap C_1) \\cup (H_2 \\cap T_1 \\cap C_2))}{P((H_1 \\cap C_1) \\cup (H_2 \\cap C_2))}.\n\\end{align}\n\\]\nWe know that the events \\(C_1\\) and \\(C_2\\) are disjoint. So\n\\[\n\\begin{align}\nP((H_1 \\cap T_2 \\cap C_1) \\cup (H_2 \\cap T_1 \\cap C_2)) &= P(H_1 \\cap T_2 \\cap C_1) + P(H_2 \\cap T_1 \\cap C_2) \\\\\n&= P(C_1 | H_1 \\cap T_2)P(H_1 \\cap T_2) + P(C_2 |H_2 \\cap T_1) P(H_2 \\cap T_1) \\\\\n&= \\frac{1}{4}  (P(C_1|H_1 \\cap T_2) + P(C_2| H_2 \\cap T_1))\n\\end{align}\n\\]\nSimilarly,\n\\[\n\\begin{align}\nP((H_1 \\cap C_1) \\cup (H_2 \\cap C_2)) &= P(H_1 \\cap C_1) + P(H_2 \\cap C_2) \\\\\n&= P(C_1 | H_1)P(H_1) + P(C_2| H_2)P(H_2) \\\\\n&= \\frac{1}{2} (P(C_1 |H_1) + P(C_2| H_2)).\n\\end{align}\n\\]\nTherefore, \\[\n\\begin{equation}\nP(B) = \\frac{1}{2} \\frac{P(C_1 | H_1 \\cap T_2) + P(C_2|H_2 \\cap T_1)}{P(C_1|H_1) + P(C_2|H_2))}\n\\end{equation}\n\\tag{1}\\] Since the choice of coin is independent of the results of coin tosses (it must be because you know nothing about the results of the coin tosses)\n\\[\nP(B) = 1/2.\n\\]\n\n\n\n\n\n\nWhat happens if I pick the coins for you?\n\n\n\nThen the choice of coin is not necessarily independent: I could, for example, only show a head if both coin tosses result in a head. Then\n\\[\nP(C_1|H_1 \\cap T_2) = P(C_2|H_2 \\cap T_1) = 0\n\\] and so, by Equation 1, \\(P(B) = 0\\).\nOn the other hand, I could always show a head if it’s available and then \\[\nP(B) = 2/3\n\\] because this is essentially the same as answering the question “are there heads”.\nNow suppose that \\(0 \\leq \\alpha \\leq 1\\) and I adopt the following scheme: with probability \\(\\alpha\\) I show you a head when one is available and with probability \\((1 - \\alpha)\\) I only show you a head if both tosses were heads. Then\n\\[\nP(B) = \\frac{2 \\alpha}{3}.\n\\]\nIn summary, when I’m free to look at the coins and decide which coin to show, I can come up with a process with results in \\(P(B)\\) being any chosen value in \\([0, 2/3]\\).\n\n\nWe can use a simulation to support our conclusion and highlight the difference between the two scenarios:\n\nimport random\n\ndef head(coin):\n    return coin == 0\n\ndef tail(coin):\n    return coin == 1\n\ndef has_heads(coin):\n    return head(coin[0]) or head(coin[1])\n\ndef has_tails(coin):\n    return tail(coin[0]) or tail(coin[1])\n\niterations = 10000\n\ntails = 0\nfor i in range(0, iterations):\n    coins = []\n    while True:\n        # keep trying until we have at least one head\n        coins= [random.randint(0,1), random.randint(0,1)]\n        if has_heads(coins):\n            break\n    if has_tails(coins):\n        tails += 1\n\nprint(tails/iterations)\n\ntails = 0\n\nfor i in range(0, iterations):\n    def head_revealed():\n        while True:\n            # keep trying tosses and random coin picks until\n            # the revealed coin is a head\n            coins= [random.randint(0,1), random.randint(0,1)]\n            coin_choice = random.randint(0,1)\n            revealed_coin = coins[coin_choice]\n            remaining_coin = coins[(coin_choice+1)%2]\n            if head(revealed_coin):\n                return remaining_coin\n    if tail(head_revealed()):\n        tails +=1\n\nprint(tails/iterations)\n\n0.6744\n\n\n0.497"
  }
]