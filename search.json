[
  {
    "objectID": "FCSC/ch1.html",
    "href": "FCSC/ch1.html",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# (a)\nN = 10000\nsamples = np.random.default_rng().uniform(0, 1, N)\n\n# (b)\n\nbins = 50\nplt.hist(samples, bins, label='Unform')\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\nUniform Distribution\n\n\n\n\n\n# (c)\nplt.hist(samples, bins, cumulative=True, label='CDF X ~ U(0,1)')\nplt.legend(loc='upper left')\nplt.show()\n\n\n\n\n\n# Redo (b) and (c) for X^2\n\nsamples_squared = [ x**2 for x in samples]\n\n\nplt.hist(samples_squared, bins, label='PDF X^2')\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\nplt.hist(samples_squared, bins, cumulative=True, label='CDF X^2')\nplt.legend(loc='upper left')\nplt.show()\n\n\n\n\n\n\n\n\n# (a)\nN = 10000\nsamples = np.random.default_rng().exponential(1, N)\naverages = [sample/(idx +1) for idx, sample in enumerate(np.cumsum(samples))]\n\nbins = np.linspace(0, 2, 100)\nplt.hist(averages, bins)\nplt.show()\n\n\n\n\n\nplt.plot(averages)\nplt.ylabel('average of N samples')\nplt.xlabel('N')\nplt.show()\n\n\n\n\n\n# (b)\n\ndef average(n):\n    return np.sum(np.random.default_rng().exponential(1, n))/n\n\nbins = np.linspace(-0, 2, 100)\nplt.hist([average(100) for _ in range(0, 10000)], bins, label='average(100)', alpha=0.5)\nplt.hist([average(10000) for _ in range(0, 10000)], bins, label='average(10000)', alpha=0.5)\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\nNote how the averages of 10000 samples have less variance than the averages of 100 samples.\n\n\n\n\ndef Y(N):\n    sum = np.sum(np.random.default_rng().exponential(1, N))\n    return (sum - N) /np.sqrt(N)\n\nsamples = 10000\n\nbins = np.linspace(-3, 3, 50)\n\n\nplt.hist([ Y(100) for _ in range(0, samples)], bins, label='Y(100)', alpha=0.5)\nplt.hist(np.random.default_rng().normal(0, 1, samples), bins, label='N(0,1)', alpha=0.5)\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\ndef invF(y):\n    return np.tan((y - 0.5)*np.pi)\n\nN = 100000\nsamples = [ invF(u) for u in np.random.default_rng().uniform(0, 1, N) ]\n\n\nbins = np.linspace(-10, 10, 100)\nplt.hist(samples, bins, alpha=0.5, label='Cauchy')\nplt.hist(np.random.default_rng().normal(0, 1, N), bins, alpha=0.5, label='normal')\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\nmean = [ s/(idx + 1) for idx, s in enumerate(np.cumsum(samples)) ]\n\nplt.plot(mean, label='average of N samples')\nplt.legend(loc='upper right')\nplt.xlabel('N')\nplt.show()\n\n\n\n\n\ndef cauchy_empirical_mean(N):\n    return np.sum([ invF(u) for u in np.random.default_rng().uniform(0, 1, N) ])/N\n\n\nbins = np.linspace(-40, 40, 1000)\nplt.hist([cauchy_empirical_mean(10) for _ in range(0, 10000)], bins, label='N=10', alpha=0.5)\nplt.hist([cauchy_empirical_mean(100) for _ in range(0, 10000)], bins, label='N=100', alpha=0.5)\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\nNote how the emperical means with 10 samples and 100 samples appear to be identically distributed. The Cauchy distribution has no defined mean (even though it is symmetrical about 0) so the Central Limit Theorem does not apply.\nIf we have two iid variables \\(X\\) and \\(Y\\) with Cauchy distribution i.e. with pdf\n\\[\nf(x) = \\frac{1}{\\pi} \\frac{1}{1 + x^2} dx.\n\\]\nWe can get the distribution of \\(\\frac{1}{2}(X + Y)\\) by considering the characteristic function of the distribution, \\(e^{-|t|}\\).\nThe characteristic function of \\(\\frac{1}{2}(X + Y)\\) is\n\\[\nE(e^{it(X + Y)/2}) = E(e^{itX/2}) E(e^{itY/2}) = e^{-2|t/2|} = e^{-|t|}.\n\\]\nThis tells us that \\(\\frac{1}{2}(X + Y)\\) has the same distribution as \\(X\\) and \\(Y\\). So, when we calculate empirical means of Cauchy distribution independent variables, the result does not converge to a constant plus a narrow Gaussian error: instead, we get a random variable with the same distribution the samples, regardless of how many samples we take!"
  },
  {
    "objectID": "FCSC/ch1.html#section",
    "href": "FCSC/ch1.html#section",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.1",
    "text": "1.1\nProve proposition 1.3.\n\nFinite additivity: if two events \\(A\\) and \\(B\\) are disjoint, then \\(P(A \\cup B) = P(A) + P(B)\\)\n\nThis follows from Definition 2.3 (3) with \\(A = A_1\\), \\(B = A_2\\) and \\(A_i = \\emptyset\\) for \\(i > 2\\):\n\\[\n\\begin{align}\nP(A \\cup B) &= P (\\cup_{i} A_i) = P(A_1) + P(A_2) + \\cup_{i > 2} P(A_i) \\\\\n            &= P(A) + P(B) + \\cup_{i > 2} P(\\emptyset) \\\\\n            &= P(A) + P(B).\n\\end{align}\n\\]\n\nFor any event \\(A\\), \\(P(A^c) = 1 - P(A)\\):\n\n\\(\\Omega\\) is the disjoint union of \\(A\\) and \\(A^c\\). By (1) above \\[\n1 = P(\\Omega) = P(A \\cup A^c) = P(A) + P(A^c)\n\\] so \\[\nP(A) = 1 - P(A^c).\n\\]\n\nFor any events \\(A\\), \\(B\\), \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\):\n\nExpress \\(A \\cup B = (A\\setminus B) \\cup B\\) where the union is disjoint. Using (1)\n\\[\nP(A \\cup B) = P(A\\setminus B) + P(B).\n\\] Now, \\[\nP(A\\setminus B) + P(A\\cap B) = P(A)\n\\] and so \\[\nP(A\\setminus B) = P(A) - P(A\\cap B).\n\\]\nIt follows that\n\\[\nP(A \\cup B) = P(A \\setminus B) + P(B) = P(A) + P(B) - P(A \\cap B).\n\\]\n\nMonotonicity: If \\(A \\subseteq B\\), then \\(P(A) \\leq P(B)\\).\n\nIf \\(A \\subseteq B\\), then \\(B = A \\cup (B \\setminus A)\\) where the union is disjoint. It follows that\n\\[\nP(B) = P(A) + P(B \\setminus A) \\geq P(A).\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#equiprobability",
    "href": "FCSC/ch1.html#equiprobability",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.2 Equiprobability",
    "text": "1.2 Equiprobability\nLet \\(\\Omega\\) be a sample space with a finite number of outcomes. We define\n\\[\nP(A) = \\#A/\\#\\Omega\n\\] for \\(A \\subseteq \\Omega\\).\n\\(P\\) is a probability on \\(\\Omega\\).\nProof:\n\nSince counts are positive, \\(P >= 0\\). Since \\(\\#A \\leq \\#\\Omega\\), \\(P \\leq 1\\) and so \\(P(A) \\in [0, 1]\\) for \\(A \\subseteq \\Omega\\).\nThe empty set \\(\\emptyset\\) has no elements, so \\(P(\\emptyset) = 0\\). It is easy to see that \\[\nP(\\Omega) = \\frac{\\# \\Omega}{ \\# \\Omega} =1.\n\\]\nAdditivity: for any infinite, mutually disjoint sequence of events \\(A_1, A_2, \\ldots\\) there exists \\(N\\) such that \\(A_n = \\emptyset\\) for all \\(n \\geq N\\). In fact, \\(N\\) must be less than \\(\\# \\Omega\\).\n\nThen\n\\[\n\\begin{align}\nP(\\cup_{i=1}^{\\infty} A_n) &= P(\\cup_{i=1}^{N} A_n)\\\\\n&= \\frac{\\sum_{i=1}^N \\# A_n}{\\# \\Omega} \\\\\n&= \\sum_{i=1}^N P(A_n) \\\\\n&= \\sum_{i=1}^{\\infty} P(A_n).\n\\end{align}\n\\]."
  },
  {
    "objectID": "FCSC/ch1.html#distribution-as-a-probability-on-mathbbr",
    "href": "FCSC/ch1.html#distribution-as-a-probability-on-mathbbr",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.3 Distribution as a Probability on \\(\\mathbb{R}\\)",
    "text": "1.3 Distribution as a Probability on \\(\\mathbb{R}\\)\nLet \\(\\rho_X\\) be the distribution of random variables \\(X\\) on some probability space \\((\\Omega, \\mathcal{F}, P)\\). \\(\\rho_X\\) has the properties of a probability on \\(\\mathbb{R}\\).\nProof:\nLet \\(\\mathcal{F}_X\\) be the \\(\\sigma\\)-field of set in \\(\\mathbb{R}\\) such that \\(A \\in \\mathcal{F} \\iff \\{\\omega \\in \\Omega: X(\\omega) \\in A\\} \\in \\mathcal{F}\\).\nWe define \\(P_X\\) on \\(\\mathcal{F}_X\\) by\n\\[\nP_X(A) = P(\\{\\omega \\in \\Omega: X(\\omega) \\in A\\}).\n\\]\nWe note that \\(P_X\\) extends \\(\\rho_X\\).\nFor notational simplicity, we write\n\\[\nX^{-1}(A) = \\{\\omega \\in \\Omega: X(\\omega) \\in A\\}.\n\\]\nClearly, for any \\(A \\in \\mathcal{F}_X\\), \\(P_X(A) = P(X^{-1}(A)) \\in [0,1]\\), so satisfies (1) of Definition 1.2.\nThe pre-image of \\(\\emptyset\\), \\(X^{-1}(\\emptyset)\\) must be itself empty. Therefore,\n\\[\nP_X(\\emptyset) = P(\\emptyset) = 0.\n\\]\nSimilarly, the pre-image of \\(\\mathbb{R}\\) must be all of \\(\\Omega\\) and so\n\\[\nP_X(\\mathbb{R}) = P(\\Omega) = 1.\n\\]\nThis shows that \\(P_X\\) satisfies (2) of Definition 2.1.\nLet \\(A_1, A_2, \\ldots\\) be an infinite sequence of events in \\(\\mathcal{F}_X\\) that are mutually disjoint. Note that the sequence of pre-images \\(X^{-1}(A_1), X^{-1}(A_2), \\ldots\\) are also mutually disjoint. Since \\(P\\) is a probability we can use its additivity to prove the additivity of \\(P_X\\):\n\\[\nP_X(\\cup_{i=1}^{\\infty} A_i) = P(\\cup_{i=1}^{\\infty} X^{-1}(A_i)) = \\sum_{i=1}^{\\infty} P(X^{-1}(A_i)) = \\sum_{i=1}^{\\infty} P_X(A_i).\n\\]\nThis shows that \\(P_X\\) satisfies (3) of Definition 2.1."
  },
  {
    "objectID": "FCSC/ch1.html#distribution-of-an-indicator-function",
    "href": "FCSC/ch1.html#distribution-of-an-indicator-function",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.4 Distribution of an Indicator Function",
    "text": "1.4 Distribution of an Indicator Function\nLet \\((\\Omega, \\mathcal{F}, P)\\) and \\(A \\in \\mathcal{F}\\) with \\(0 < P(A) < 1\\). What is the distribution of \\(1_A\\)?\nObserve that \\(P(1_A \\leq x) = 0\\) when \\(x < 0\\) because the indicator is a non-negative function. When \\(0 \\leq x < 1\\), \\(1_A(\\omega) > x\\) for all \\(\\omega \\in A\\) but \\(1_A(\\omega) = 0 <= x\\) for \\(\\omega \\in A^c\\). It follows that \\[P(1_A \\leq x) = P(\\{\\omega \\in \\Omega : 1_A(\\omega) \\leq x\\}) =P(\\{\\omega \\in \\Omega : \\omega \\in A^c\\}) = P(A^c).\\] For \\(x \\geq 1\\), \\(1_A \\leq x\\) is true for all values of \\(\\omega \\in \\Omega\\) because the maximum value of the indicator function is \\(1\\). Therefore, with \\(F\\) denoting the CDF of \\(1_A\\): \\[\nF(x) = P(1_A \\leq x) = \\begin{cases}\n0 & \\text{if } x < 0,\\\\\nP(A^c) & \\text{if } 0 \\leq x < 1,\\\\\n1 & \\text{if } x \\geq 1.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#events-of-probability-one",
    "href": "FCSC/ch1.html#events-of-probability-one",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.5 Events of Probability One",
    "text": "1.5 Events of Probability One\nLet \\((\\Omega, \\mathcal{F}, P)\\) be a probability space and \\(A_1, A_2, \\ldots\\) be a sequence of events in \\(\\mathcal{F}\\) such that \\(P(A_n) = 1\\) for all \\(n \\geq 1\\). We show that\n\\[\nP(\\cap_{i\\geq 1} A_n) = 1.\n\\]\nDefine \\(B_n = A_n^c\\) for all \\(n \\geq 1\\). We note that\n\\[\nP(B_n) = 1 - P(A_n) = 0\n\\] for all \\(n \\geq 0\\).\nDefine a sequence of events \\(C_n = \\cup_{i =1}^n B_i\\) and note that the sequence is increasing. Continuity of probability gives\n\\[\n\\lim_{n \\to \\infty} P(C_n) = P(\\cup_{i=1}^{\\infty} B_i).\n\\]\nUsing \\(P(A \\cup B) \\leq P(A) + P(B)\\), we see that\n\\[\nP(C_n) \\leq \\sum_{i = 1}^n P(B_i) = 0\n\\]\nand so \\(P(C_n) = 0\\) and \\[\\lim_{n \\to \\infty} P(C_n) = P(\\cup_{i=1}^{\\infty} B_i) = 0\\].\nTo finish the proof, we note that\n\\[\\begin{align}\nP(\\cap_{i=1}^{\\infty} A_i) &= 1 - P((\\cap_{i=1}^{\\infty} A_i)^c)\\\\\n                           &= 1 - P( \\cup_{i =1}^{\\infty} A_i^c)\\\\\n                           &= P(\\cup_{i=1}^{\\infty} B_i) = 0.\n\\end{align}\\]"
  },
  {
    "objectID": "FCSC/ch1.html#constructing-a-random-variable-from-another",
    "href": "FCSC/ch1.html#constructing-a-random-variable-from-another",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.6 Constructing a Random Variable from Another",
    "text": "1.6 Constructing a Random Variable from Another\nLet \\(X\\) be a random variable on \\((\\Omega, \\mathcal{F}, P)\\) this is uniformly distributed on \\([-1, 1]\\). Define \\(Y = X^2\\).\n\nFind the CDF of Y and plot its graph.\n\nFirst, the CDF:\nLet \\(F\\) denote the CDF of \\(Y\\) and \\(F_X\\) denote the CDF of X.\nThen \\[\nG(x) = P(Y \\leq x) = P(X^2 \\leq x) = P(X \\leq \\sqrt{x}) = F(\\sqrt{x}).\n\\]\nNow,\n\\[\nF(x) =\n\\begin{cases}\n0 & \\text{if } x \\leq 0, \\\\\nx & \\text{if } 0 < x < 1, \\\\\n1 & \\text{if } x \\geq 1.\n\\end{cases}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nI’ve taken \\(F\\) to be different to that in the book (the first case in the book uses \\(x < 0\\)) so that the resulting \\(G\\) has a well-defined derivative at zero.\n\n\n\nand so\n\\[\nG(x) =\n\\begin{cases}\n0 & \\text{if } x <= 0, \\\\\n\\sqrt{x} & \\text{if } 0 < x < 1, \\\\\n1 & \\text{if } x \\geq 1.\n\\end{cases}\n\\]\nWe plot this below:\n\ndef G(x):\n    if x <= 0:\n        return 0\n    elif x > 0 and x < 1:\n        return np.sqrt(x)\n    return 1\n\nxticks = np.linspace(-1, 1.5, 100)\nplt.plot(xticks, [G(x) for x in xticks])\n\n\n\n\n\nthe PDF of Y is given by\n\n\\[\np(y) = \\frac{dG}{dy}(y) = \\begin{cases}\n0 & \\text{if } x \\leq 0, \\\\\n\\frac{1}{2\\sqrt{x}} & \\text{if } 0 < x < 1, \\\\\n0 & \\text{if } 0 \\geq 1.\n\\end{cases}\n\\]\nThe plot is below\n\n\nCode\ndef p(x):\n    if x <= 0:\n        return 0\n    elif x > 0 and x < 1:\n        return (1/( 2 * np.sqrt(x)))\n    return 1\n\nxticks = np.linspace(-1, 0, 50)\nplt.plot(xticks, [p(x) for x in xticks])\nxticks = np.linspace(0.01, 0.99, 50)\nplt.plot(xticks, [p(x) for x in xticks])\nxticks = np.linspace(1, 2, 50)\nplt.plot(xticks, [p(x) for x in xticks])\nplt.show()"
  },
  {
    "objectID": "FCSC/ch1.html#sum-of-integrable-variables",
    "href": "FCSC/ch1.html#sum-of-integrable-variables",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.7 Sum of Integrable Variables",
    "text": "1.7 Sum of Integrable Variables\n\\(X\\) and \\(Y\\) are two integrable random variables on the same probability space. Then \\(aX + bY\\) is also an integrable random variable for any \\(a, b \\in \\mathbb{R}\\).\nProof:\nWe assert that \\(aX + b Y\\) is a random variable and are left to show that\n\\[\nE(\\left|aX + bY\\right|) < \\infty.\n\\]\nBy the triangle inequality,\n\\[\n\\left| aX + bY \\right| \\leq \\left| a \\right| \\left| X \\right| + \\left| b \\right| \\left| Y \\right|\n\\] and so we can conclude that\n\\[\nE(\\left|aX + bY\\right|) < \\infty.\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#jumps-and-probabilities",
    "href": "FCSC/ch1.html#jumps-and-probabilities",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.8 Jumps and Probabilities",
    "text": "1.8 Jumps and Probabilities\nLet \\(X\\) be a random variable and \\(F_X\\) be its CDF. Then\n\\[\nP(X = a) = F_X(a) - \\lim_{x \\to a-} F_X(x) = F_X(a) - F_X(a-).\n\\]\nProof:\nDefine a decreasing sequence of events \\(A_n = \\{ X \\in (a - 1/n, a]\\}\\) and note that \\(\\cap_{i=1}^{\\infty} A_n = \\{ X = a\\}\\). By continuity of probability\n\\[\n\\lim_{n \\to \\infty} P(A_n) = P(X = a).\n\\]\nNow,\n\\[\\begin{align}\nP(X = a) &= \\lim_{n \\to \\infty} P(A_n)\\\\\n         &= \\lim_{n \\to \\infty} (F_X(a) - F_X(a - 1/n))\\\\\n         &= F_X(a) - \\lim_{n \\to \\infty} (F_X(a - 1/n)) = F_X(a) - F_X(a-).\n\\end{align}\\]"
  },
  {
    "objectID": "FCSC/ch1.html#memory-loss-property",
    "href": "FCSC/ch1.html#memory-loss-property",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.9 Memory Loss Property",
    "text": "1.9 Memory Loss Property\nLet \\(Y\\) be an exponential random variable with parameter \\(\\lambda\\). The for any \\(s, t > 0\\)\n\\[\nP(Y > t + s | Y > s) = P(Y > t).\n\\]\nProof:\nThe CDF of the exponential distribution is\n\\[\nF(t) = 1 - e^{-\\lambda t}.\n\\]\nTherefore,\n\\[\nP(Y > t) = 1 - F(t) = e^{-\\lambda t}.\n\\]\nNow\n\\[\\begin{align}\nP(Y > t + s | Y > s) & =  \\frac{P(Y > t + s \\cap Y > s)}{P(Y > s)} \\\\\n                     & =  \\frac{P(Y > t + s)}{P(Y > s)}  \\\\\n                     & =  \\frac{e^{-\\lambda(t + s)}}{e^{-\\lambda s}} \\\\\n                     & =  e^{-\\lambda t} \\\\\n                     & =  P(Y > t).\n\\end{align}\\]\nNote that \\(P(Y > t + s \\cap Y > s) = P(Y > t + s)\\) because \\(\\{ \\omega \\in \\Omega | Y(\\omega) > t + s \\} \\subseteq \\{ \\omega \\in \\Omega | Y(\\omega) > t \\}\\) and so \\(\\{ \\omega \\in \\Omega | Y(\\omega) > t + s \\} \\cap \\{ \\omega \\in \\Omega | Y(\\omega) > t \\} = \\{ \\omega \\in \\Omega | Y(\\omega) > t + s\\}\\)."
  },
  {
    "objectID": "FCSC/ch1.html#gaussian-integration-by-parts",
    "href": "FCSC/ch1.html#gaussian-integration-by-parts",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.10 Gaussian Integration by Parts",
    "text": "1.10 Gaussian Integration by Parts\n\nLet \\(Z\\) be a standard Gaussian random variable. Then\n\n\\[\nE(Zg(Z)) = E(g'(Z))\n\\]\nwhen both expectations are well-defined.\nProof:\nWe can use LOTUS and integration by parts:\n\\[\\begin{align}\nE(Z g(Z)) = \\int_{-\\infty}^{\\infty} z g(z) p(z) dz  &=  \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} z g(z) e^{-z^2/2} dz \\\\\n&= \\int_{-\\infty}^{\\infty} g(z) (-\\frac{dp}{dz}) dz \\\\\n&= -g(z) p(z) \\rvert_{-\\infty}^{\\infty} + \\int_{-\\infty}^{\\infty} g'(z) p(z) dz \\\\\n&= E(g'(Z)).\n\\end{align}\\]\nNote that\n\\[\n-g(z) p(z) \\rvert_{-\\infty}^{\\infty} = 0\n\\]\nfollows from \\(zg(z) p(z)\\) being integrable.\n\nIn particular, if \\(g(z) = z^{n + 1}\\), then \\(g'(z) = (n +1) z^{n}\\) so\n\n\\[\nE( Z g(Z)) = E(Z^{n+2}) = E((n + 1) Z^{n}).\n\\]\nWe see that\n\\[\n\\begin{align}\nE(Z^{2n}) &= (2n -1) E(Z^{2n -2})\\\\\n          &= (2n -1) (2n -3) E(Z^{2n - 4})\\\\\n          &= (2n - 1) (2n -3) \\ldots 1 E(Z^2)\\\\\n          &= (2n -1) (2n -3) \\ldots 1.\n\\end{align}\n\\]\nSimilarly,\n\\[\n\\begin{align}\nE(Z^{2n + 1}) &= (2n) E(Z^{2n -1})\\\\\n          &= (2n) (2n -2) E(Z^{2n - 3})\\\\\n          &= (2n) (2n -2) \\ldots 1 E(Z)\\\\\n          &= 0.\n\\end{align}\n\\]\nSetting \\(X = \\sigma Z\\), we find that\n\\[\nE(X^{2n}) = \\sigma^{2n} (2n -1)(2n -3) \\ldots 1.\n\\]\nWe can’t have a mean different from zero: without symmetry about zero the special structure of odd and even functions would be lost."
  },
  {
    "objectID": "FCSC/ch1.html#mgf-of-exponential-random-variables",
    "href": "FCSC/ch1.html#mgf-of-exponential-random-variables",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.11 MGF of Exponential Random Variables",
    "text": "1.11 MGF of Exponential Random Variables\nShow that for a random variable \\(X \\sim exp(\\lambda)\\)\n\\[\nE(e^{t X}) = \\frac{ \\lambda}{\\lambda - t }, t < \\lambda.\n\\]\nUsing LOTUS and choosing \\(t < \\lambda\\)\n\\[\\begin{align}\nE(e^{tX}) &= \\int_{0}^{\\infty} e^{tx} \\lambda e^{-\\lambda x} dx \\\\\n          &= \\int_0^{\\infty} e^{(t - \\lambda) x} dx \\label{exp:integral} \\tag{*} \\\\\n          &= \\frac{1}{t - \\lambda} e^{(t - \\lambda) x} \\rvert_{0}^{\\infty} \\\\\n          &= \\frac{ \\lambda}{\\lambda - t }.\n\\end{align}\\]\nNote that if \\(t \\geq \\lambda\\), then the integral \\(\\eqref{exp:integral}\\) is not well-defined.\nWe can calculate \\(E(X)\\):\n\\[\nE(X) = \\frac{d}{dt} E(e^{tX}) \\rvert_{t=0} = \\frac{\\lambda}{(\\lambda -t)^2}\\rvert_{t=0} = \\frac{1}{\\lambda}.\n\\]\nWe can also calculate \\(Var(X)\\):\n\\[\nE(X^2) = \\frac{d^2}{dt^2} E(e^{tX}) \\rvert_{t=0} = \\frac{2\\lambda}{(\\lambda -t)^3} \\rvert_{t=0} = \\frac{2}{\\lambda^2}.\n\\]\nand so\n\\[\nVar(X) = E(X^2) - E(X)^2 = \\frac{2}{\\lambda^2} - \\frac{1}{\\lambda^2} =\\frac{1}{\\lambda^2}.\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#gaussian-tail",
    "href": "FCSC/ch1.html#gaussian-tail",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.12 Gaussian Tail",
    "text": "1.12 Gaussian Tail\nConsider a random variable \\(X\\) with finite MGF such that\n\\[\\begin{equation}\nE(e^{\\lambda X}) \\leq e^{\\lambda^2/2}\n\\label{gtail} \\tag{1}\n\\end{equation}\\]\nfor all \\(\\lambda \\in \\mathbb{R}\\).\nProve that for \\(a > 0\\)\n\\[\nP(X > a) \\leq e^{-a^2/2}.\n\\]\nFor \\(\\lambda > 0\\) \\[\nP(X > a) \\leq P(e^{\\lambda X} > e^{\\lambda a})\n\\] by monotonicity of the exponential. By Markov’s inequality and \\(\\eqref{gtail}\\) \\[\nP(e^{\\lambda X} > e^{\\lambda a}) \\leq \\frac{E(e^{\\lambda X})}{e^{\\lambda a}} \\leq e^{\\lambda^2/2 - \\lambda a}.\n\\]\nLet \\(f(\\lambda) = e^{\\lambda^2/2 - \\lambda a}\\). The minimum for \\(f\\) is found by differentiation:\n\\[\nf'(\\lambda) = (\\lambda - a) e^{\\lambda^2/2 - \\lambda a}\n\\]\nand \\(f'(\\lambda) = 0\\) is solved for \\(\\lambda = a\\). Therefore,\n\\[\nP(X > a) \\leq e^{a^2/2 - a^2} = e^{-a^2/2}.\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#expectation-from-cdf",
    "href": "FCSC/ch1.html#expectation-from-cdf",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.13 Expectation from CDF",
    "text": "1.13 Expectation from CDF\nLet \\(X\\) be a random variable such that \\(X >= 0\\). Then\n\\[\nE(X) = \\int_0^{\\infty} P(X > x) dx.\n\\]\nProof:\n\\[\n\\int_0^{\\infty} P(X > x) dx = \\int_0^{\\infty} (1 - F(x)) dx\n\\]\nwhere \\(F(x) = P(X <= x)\\). We can write\n\\[\n1 - F(x) = \\lim_{x \\to \\infty} F(x) - F(x) = \\int_x^{\\infty} dF(t)\n\\]\nwhere the integral is understood in the Lebesgue sense.\nNow,\n\\[\n\\int_0^{\\infty} P(X > x) dx = \\int_0^{\\infty} \\int_x^{\\infty} dF(t) dx\n\\]\nand by changing the order of integration (and appealing to Fubini’s Theorem)\n\\[\n\\int_0^{\\infty} P(X > x) dx = \\int_0^{\\infty} \\int_0^t dx dF(t) = \\int_0^{\\infty} t dF(t) = E(X).\n\\]\nSubtle point: we’re using the fact that X >= 0 to arrive at zero for the lower limit of the inner integral.\n\n\n\n\n\n\nConsequence: LOTUS (Law Of The Unconcious Statistician)\n\n\n\n\n\nLet \\(g: \\mathbb{R} \\mapsto \\mathbb{R}\\) be measurable. Then \\(E(g(X)) = \\int_{-\\infty}^{\\infty} g(x) dF(x)\\).\nFirst suppose that \\(g >= 0\\). Then\n\\[\nE(g(X)) = \\int_0^{\\infty} P(g(X) > x) dx\n\\] by the result above.\nNow,\n\\[\n\\int_0^{\\infty} P(g(X) > x) dx = \\int_0^{\\infty} \\int_{\\{z: g(z) > x\\}} dF(z) dx.\n\\]\nChanging the order of integration, we see get\n\\[\n\\int_{-\\infty}^{\\infty} \\int_0^{g(z)} dx dF(z) = \\int_{-\\infty}^{\\infty} g(x) dF(x).\n\\]\nNow suppose we have general \\(g\\). Split \\(g\\) into the sum of non-negative and negative components\n\\[\ng = g_+ - g_{-}\n\\]\n\\[\n\\begin{align}\nE(g(X)) &= E(g_+(X)) - E(g_{-}(X)) \\\\\n&= \\int_{-\\infty}^{\\infty} g_+(x) dF(x) - \\int_{-\\infty}^{\\infty} g_{-}(x) dF(x) \\\\\n&= \\int_{-\\infty}^{\\infty} g(x) dF(x).\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\n\nConsequence: Limit of xP(X>x)\n\n\n\n\n\nIf \\(E(X_+) < \\infty\\), then \\(\\lim_{x \\to \\infty} x P(X > x) = 0\\).\nWe prove this by contradiction. Suppose that there exists \\(c > 0\\) such that \\(lim_{x \\to \\infty} xP(X >x) \\geq c\\). Then for some \\(x(c)\\), \\(xP(X>x) \\geq c\\) for all \\(x > x(c)\\) and so\n\\[\nE(X+) = \\int_0^{\\infty} P(X > x) dx \\geq \\int_{x(c)}^{\\infty} P(X > x) dx \\geq \\int_{x(c)}^{\\infty} \\frac{c}{x} dx = \\infty.\n\\]\nThis contradicts \\(E(X_+) < \\infty\\).\nContrast this with the Markov inequality which states that\n\\[\nP(X > x) <= \\frac{E(X)}{x}\n\\]\nwhich puts a bound on \\(x P(X > x)\\):\n\\[\nx P(X > x) <= E(X).\n\\]\n\n\n\nTake a random variable \\(X\\) such the \\(E(|X|) < \\infty\\). Prove that\n\\[\nE(X) = \\int_0^{\\infty} P(X > x) dx - \\int_{-\\infty}^0 P(X \\leq x) dx.\n\\]\nDefine \\(X_+ = X 1_{X \\geq 0}\\) and \\(X_{-} = X 1_{X < 0}\\) and note that \\(X = X_+ + X_{-}\\). Then\n\\[\nE(X) = E(X_+) + E (X_{-})\n\\] by linearity of expectation. From above,\n\\[\nE(X_+) = \\int_0^{\\infty} P(X_+ > x) dx = \\int_0 ^{\\infty} P(X > x) dx.\n\\]\nSet \\(Y = -X_{-}\\). Then \\(Y > 0\\) and\n\\[\nE(Y) = \\int_0^{\\infty} P(Y > y) dy.\n\\]\nNow,\n\\[\\begin{align}\nE(X 1_{X < 0}) &= - E(- X_{-}) \\\\\n               &= - E(Y) \\\\\n               &= -\\int_0^{\\infty} P(-X_{-} >y) dy \\\\\n               &= \\int_{0}^{-\\infty} P(X_{-} < x) dx \\\\\n               &= \\int_0^{-\\infty} P(X < x) dx\n\\end{align}\\]\nThen\n\\[\nE(X) = \\int_0^{\\infty} P(X > x) dx - \\int_{-\\infty}^0 P(X < x) dx.\n\\]\n\n\n\n\n\n\nThe result we have to prove is not generally true\n\n\n\n\\[\n\\int (P(X <= x) -P(X<x)) dx = \\int P(X = x) dx = 0\n\\]\nwhen \\(X\\) has a PDF (the CDF is at least continuous). In this case, we can state\n\\[\nE(X) = \\int_0^{\\infty} P(X > x) dx - \\int_{-\\infty}^0 P(X \\leq x) dx.\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#characteristic-function",
    "href": "FCSC/ch1.html#characteristic-function",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.14 Characteristic Function",
    "text": "1.14 Characteristic Function\n\nNote that the expectation of a complex-valued random variable (or indeed the complex-valued random variable) is defined in Chapter 1.\n\nA good definition is\n\\[\nE(Z) = E(\\Re(Z)) + i E(\\Im(Z)).\n\\]\nNote that if \\(E(|Z|) < \\infty\\), then the real and imaginary parts of \\(Z\\) are also integrable.\nWe can extend LOTUS to complex valued functions. Suppose that \\(g: \\mathbb{R} \\to \\mathbb{C}\\) and \\(E(|g(X)|) < \\infty\\). We can decompose \\(g\\) as\n\\[\ng = g_1 + i g_2.\n\\]\nNote that \\(g_1(X)\\) and \\(g_2(X)\\) are integrable.\nwhere \\(g_1, g_2 : \\mathbb{R} \\to \\mathbb{R}\\). Then by linearity of expectation\n\\[\\begin{align}\nE(g(X)) &= E(g_1(X)) + i E(g_2(X))\\\\\n        &= \\int_{-\\infty}^{\\infty} g_1(x) dF(x) + i \\int_{-\\infty}^{\\infty} g_2(x) dF(x)\\\\\n        &= \\int_{-\\infty}^{\\infty} (g_1(x) + i g_2(x)) dF(x)\\\\\n        &= \\int_{-\\infty}^{\\infty} g(x) dF(x).\n\\end{align}\\]\nUsing this result, we see that\n\\[\nE(e^{itX}) = E(\\cos(tX)) + i E(\\sin(tX))\n\\]\nfrom the familiar Euler identity \\(e^{itx} = \\cos(tx) + i \\sin(tx)\\).\nThe same result can be argued using the Taylor series:\n\\[\\begin{align}\nE(e^{itX}) &= \\sum_{n=0}^{\\infty} E( \\frac{(itX)^n}{n!})\\\\\n           &= \\sum_{n=0}^{\\infty} E( \\frac{((-1)^{n} t^{2n} X^{2n}}{(2n)!}) + i \\sum_{i=0}^{\\infty} E( \\frac{((-1)^{n} t^{2n +1} X^{2n + 1}}{(2n + 1)!})\\\\\n           &= E(\\cos(tX)) + iE(\\sin(tX).\n\\end{align}\\]\n\nLet \\(X \\sim \\mathcal{N}(0, 1)\\). Then\n\n\\[\nE(e^{itX}) = \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} e^{itx} e^{-\\frac{1}{2}x^2} dx.\n\\]\nDefine \\(g(t) = E(e^{itX})\\) and try to build a differential equation we can solve which is hopefully equal to the desired result.\nUsing the Dominated Convergence Theorem, we can take differentiation inside the expectation integral (the derivative of the integrand is dominated by \\(e^{-\\frac{1}{2}x^2}\\) which is integrable).\nWe get\n\\[\\begin{align}\ng'(t) &= \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} i x e^{itx} e^{-\\frac{1}{2}x^2} dx.\n\\end{align}\\]\nUse integration by parts:\nSet \\(u = ie^{itx}\\) so \\(du = -t e^{itx}\\) and\n\\[\\begin{align}\ndv &= \\frac{1}{\\sqrt{2 \\pi}} x e^{-\\frac{1}{2}x^2}\\\\\n   &= -\\frac{1}{\\sqrt{2 \\pi}} \\frac{d}{dx}(e^{-\\frac{1}{2}x^2}).\n\\end{align}\\]\nPerforming the integration by parts we see that \\[\n\\begin{align}\ng'(t) &= \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} i x e^{itx} e^{-\\frac{1}{2}x^2} dx \\\\\n      &= -\\frac{1}{\\sqrt{2 \\pi}} ie^{itx} e^{-\\frac{1}{2}x^2} \\rvert_{-\\infty}^{\\infty} -  \\frac{1}{\\sqrt{2 \\pi}} \\int_{-\\infty}^{\\infty} te^{itx}  e^{-\\frac{1}{2}x^2} dx \\\\\n      &= 0 + iE(e^{itX})\\\\\n      &= -t g(t). \\label{characteristic:diffeqn} \\tag{*}\n\\end{align}\n\\] Moreover,\n\\[\ng(0) = E(e^{0}) = E(1) = 1.\n\\]\nThe unique solution to \\(\\eqref{characteristic:diffeqn}\\) is\n\\[\ng(t) = \\frac{1}{2}e^{-t^2/2}\n\\]\nand so\n\\[\nE(e^{itX}) = \\frac{1}{2}e^{-t^2/2}.\n\\]\nLet \\(Z = \\sigma X + \\mu\\) for \\(\\sigma > 0\\) and \\(\\mu \\in \\mathbb{R}\\). Then\n\\[\\begin{align}\nE(e^{itZ}) &= E(e^{it(\\sigma X + \\mu)}) \\\\\n           &= E(e^{\\sigma X} e^{it\\mu}) \\\\\n           &= e^{it\\mu}  E(e^{it\\sigma X})\\\\\n           &= e^{it\\mu}e^{-(t\\sigma)^2/2}\\\\\n           &= e^{it \\mu - \\sigma^2t^2/2}.\n\\end{align}\\]"
  },
  {
    "objectID": "FCSC/ch1.html#when-ex-infty",
    "href": "FCSC/ch1.html#when-ex-infty",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.15 When \\(E(X) < \\infty\\)",
    "text": "1.15 When \\(E(X) < \\infty\\)\nLet \\(X \\geq 0\\) be a random variable on \\((\\Omega, \\mathcal{F}, P)\\). If \\(E(X) < \\infty\\), then \\(P(X = \\infty) = 0\\).\nProof:\nLet \\(A_n = \\{\\omega \\in \\Omega: X(\\omega) > n \\}\\) for \\(n > 0\\).\nWe note that the sequence of events \\(A_n\\) is decreasing and so by continuity of probability\n\\[\n\\lim_{n\\to \\infty} P(A_n) = P(\\cap A_n) = P(X = \\infty).\n\\]\nThe proof is complete with an application of Markov’s inequality: \\[\nP(X = \\infty) = \\lim_{n \\to \\infty} P(A_n) \\leq \\lim_{n\\to\\infty} \\frac{1}{n} E(X) = 0.\n\\]"
  },
  {
    "objectID": "FCSC/ch1.html#when-ex-0",
    "href": "FCSC/ch1.html#when-ex-0",
    "title": "A First Course in Stochastic Calculus: Chapter One Exercises",
    "section": "1.16 When \\(E(X) = 0\\)",
    "text": "1.16 When \\(E(X) = 0\\)\nLet \\(X \\geq 0\\) be a random variable on \\((\\Omega, \\mathcal{F}, P)\\). If \\(E(X) = 0\\), then \\(P(X = 0) = 1\\).\nProof:\nBy Markov’s inequality\n\\[\nP(X > 1/n) \\leq n E(X) = 0\n\\]\nand so \\(P(X > 1/n) = 0\\) for \\(n = 1, 2, \\ldots\\). It follows that\n\\[\nP(X \\leq 1/n) = 1 - P(X > 1/n) = 1.\n\\]\nThe sequence of events \\(\\{ X \\leq 1/n \\}\\) is decreasing and\n\\[\n\\{ X = 0 \\} = \\cap \\{ X \\leq 1/n \\}.\n\\]\nBy the continuity of probability\n\\[\nP(X = 0) = \\lim_{n \\to \\infty} P(X \\leq 1/n) = 1.\n\\]"
  },
  {
    "objectID": "PML/ch2.html",
    "href": "PML/ch2.html",
    "title": "Probabilistic Machine Learning: Chapter Two Exercises",
    "section": "",
    "text": "I only cover starred exercises here\n\n\n\nFor solutions to non-starred exercises see https://probml.github.io/pml-book/solns-public.pdf.\n\n\n\nExercise 2.11\nLet’s phrase the problem in terms of a game with coins:\nI toss two fairs coins without showing you the result.\n\nYou ask if any of the coins are heads and I respond, truthfully, “yes”: what is the probability that one coin is a tail?\nI ask you to choose a coin to be revealed: you choose and it is a head. What is the probability that the other coin is a tail?\n\nLet \\(A\\) be the event that there is at least one head and \\(B\\) denote the event that one head has been revealed. When the event \\(B\\) occurs we know that there is at least one head and so \\(B\\) also occurs i.e. \\(B \\subseteq A\\). It follows that\n\\[\nP(B) \\leq P(A).\n\\]\nThe two events do not convey the same information: \\(B\\) tells you that after random sampling, the revealed coin is heads whereas \\(A\\) tells you that after looking at both coins, I reveal that at least one is heads. So before doing any calculation I’d guess that\n\\[\nP(B) < P(A).\n\\]\nLet \\(T\\) be the event of at least one tail, \\(H\\) be the event of at least one head and subscript these to indicate if a specific coin is a head or tail e.g. \\(T_1\\) is the event that coin \\(1\\) is a tail. Denote by \\(C_i\\) the event that coin \\(i\\) is chosen.\nWe can write \\[\n\\begin{align}\nP(A) &= P(T | H) \\\\\n     &= \\frac{P(T \\cap H)}{P(H)} \\\\\n     &= \\frac{P((T_1 \\cup T_2) \\cap (H_1 \\cup H_2))}{P(H_1 \\cup H_2)} \\\\\n     &= \\frac{P((T_1 \\cap H_2) \\cup (T_2 \\cap H_1))}{P(H_1 \\cup H_2)}.\n\\end{align}\n\\]\nNow,\n\\[\nP(H_1 \\cup H_2) = 3/4\n\\] because there are \\(3\\) out of \\(4\\) equally likely outcomes that have at least one head,\nand\n\\[\n\\begin{align}\nP((T_1 \\cap H_2) \\cup (T_2 \\cap H_1)) &= P(T_1 \\cap H_2) + P(T_2 \\cap H_1) \\\\\n&= P(T_1)P(H_2) + P(T_2)P(H_1) \\\\\n&= 1/4 + 1/4 \\\\\n& = 1/2.\n\\end{align}\n\\]\nTherefore, \\[\nP(A) = \\frac{1/2}{3/4} = 2/3.\n\\]\nSimilarly,\n\\[\n\\begin{align}\nP(B) &= P(T | (H_1 \\cap C_1) \\cup (H_2 \\cap C_2)) \\\\\n     &= \\frac{P(T \\cap ((H_1 \\cap C_1) \\cup (H_2 \\cap C_2)))}{P((H_1 \\cap C_1) \\cup (H_2 \\cap C_2))} \\\\\n     &= \\frac{P((H_1 \\cap T_2 \\cap C_1) \\cup (H_2 \\cap T_1 \\cap C_2))}{P((H_1 \\cap C_1) \\cup (H_2 \\cap C_2))}.\n\\end{align}\n\\]\nWe know that the events \\(C_1\\) and \\(C_2\\) are disjoint. So\n\\[\n\\begin{align}\nP((H_1 \\cap T_2 \\cap C_1) \\cup (H_2 \\cap T_1 \\cap C_2)) &= P(H_1 \\cap T_2 \\cap C_1) + P(H_2 \\cap T_1 \\cap C_2) \\\\\n&= P(C_1 | H_1 \\cap T_2)P(H_1 \\cap T_2) + P(C_2 |H_2 \\cap T_1) P(H_2 \\cap T_1) \\\\\n&= \\frac{1}{4}  (P(C_1|H_1 \\cap T_2) + P(C_2| H_2 \\cap T_1))\n\\end{align}\n\\]\nSimilarly,\n\\[\n\\begin{align}\nP((H_1 \\cap C_1) \\cup (H_2 \\cap C_2)) &= P(H_1 \\cap C_1) + P(H_2 \\cap C_2) \\\\\n&= P(C_1 | H_1)P(H_1) + P(C_2| H_2)P(H_2) \\\\\n&= \\frac{1}{2} (P(C_1 |H_1) + P(C_2| H_2)).\n\\end{align}\n\\]\nTherefore, \\[\n\\begin{equation}\nP(B) = \\frac{1}{2} \\frac{P(C_1 | H_1 \\cap T_2) + P(C_2|H_2 \\cap T_1)}{P(C_1|H_1) + P(C_2|H_2))}\n\\end{equation}\n\\tag{1}\\] Since the choice of coin is independent of the results of coin tosses (it must be because you know nothing about the results of the coin tosses)\n\\[\nP(B) = 1/2.\n\\]\n\n\n\n\n\n\nWhat happens if I pick the coins for you?\n\n\n\nThen the choice of coin is not necessarily independent: I could, for example, only show a head if both coin tosses result in a head. Then\n\\[\nP(C_1|H_1 \\cap T_2) = P(C_2|H_2 \\cap T_1) = 0\n\\] and so, by Equation 1, \\(P(B) = 0\\).\nOn the other hand, I could always show a head if it’s available and then \\[\nP(B) = 2/3\n\\] because this is essentially the same as answering the question “are there heads”.\nNow suppose that \\(0 \\leq \\alpha \\leq 1\\) and I adopt the following scheme: with probability \\(\\alpha\\) I show you a head when one is available and with probability \\((1 - \\alpha)\\) I only show you a head if both tosses were heads. Then\n\\[\nP(B) = \\frac{2 \\alpha}{3}.\n\\]\nIn summary, when I’m free to look at the coins and decide which coin to show, I can come up with a process with results in \\(P(B)\\) being any chosen value in \\([0, 2/3]\\).\n\n\nWe can use a simulation to support our conclusion and highlight the difference between the two scenarios:\n\nimport random\n\ndef head(coin):\n    return coin == 0\n\ndef tail(coin):\n    return coin == 1\n\ndef has_heads(coin):\n    return head(coin[0]) or head(coin[1])\n\ndef has_tails(coin):\n    return tail(coin[0]) or tail(coin[1])\n\niterations = 10000\n\ntails = 0\nfor i in range(0, iterations):\n    coins = []\n    while True:\n        # keep trying until we have at least one head\n        coins= [random.randint(0,1), random.randint(0,1)]\n        if has_heads(coins):\n            break\n    if has_tails(coins):\n        tails += 1\n\nprint(tails/iterations)\n\ntails = 0\n\nfor i in range(0, iterations):\n    def head_revealed():\n        while True:\n            # keep trying tosses and random coin picks until\n            # the revealed coin is a head\n            coins= [random.randint(0,1), random.randint(0,1)]\n            coin_choice = random.randint(0,1)\n            revealed_coin = coins[coin_choice]\n            remaining_coin = coins[(coin_choice+1)%2]\n            if head(revealed_coin):\n                return remaining_coin\n    if tail(head_revealed()):\n        tails +=1\n\nprint(tails/iterations)\n\n0.6645\n0.4991"
  }
]